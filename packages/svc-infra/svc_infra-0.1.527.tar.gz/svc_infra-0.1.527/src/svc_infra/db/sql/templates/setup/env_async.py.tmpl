# Alembic async env.py generated by svc-infra
from __future__ import annotations
import os
import logging
from typing import List

from alembic import context
from sqlalchemy.engine import make_url, URL
from sqlalchemy.ext.asyncio import create_async_engine

from svc_infra.db.sql.utils import (
    get_database_url_from_env,
    _ensure_ssl_default_async as _ensure_ssl_default,
)

try:
    from svc_infra.db.sql.types import GUID as _GUID  # type: ignore
except Exception:  # keep env.py robust if package unavailable at import time
    _GUID = None

def _render_item(type_, obj, autogen_context):
    if type_ == "type" and (
        (_GUID is not None and isinstance(obj, _GUID))
        or getattr(obj, "__class__", None).__name__ == "GUID"
    ):
        autogen_context.imports.add("from svc_infra.db.sql.types import GUID")
        return "GUID()"
    return False

# Logging
config = context.config
if config.config_file_name is not None:
    import logging.config
    logging.config.fileConfig(config.config_file_name)
logger = logging.getLogger(__name__)

# --- sys.path bootstrap for src-layout projects ---
import sys, pathlib, importlib.util
prepend = config.get_main_option("prepend_sys_path") or ""
if prepend:
    if prepend not in sys.path:
        sys.path.insert(0, prepend)
    src_path = pathlib.Path(prepend) / "src"
    if src_path.exists():
        s = str(src_path)
        if s not in sys.path:
            sys.path.insert(0, s)

# --- robust x-arg parsing for all Alembic versions ---
def _x_args_dict() -> dict:
    try:
        return context.get_x_argument(as_dictionary=True)  # type: ignore[arg-type]
    except TypeError:
        try:
            xs = context.get_x_argument()
        except TypeError:
            xs = []
    out = {}
    for item in xs:
        if "=" in item:
            k, v = item.split("=", 1)
            out[k] = v
        else:
            out[item] = ""
    return out

# --- Resolve effective DB URL (priority: -x -> env -> helper -> ini) ---
_x = _x_args_dict()
cli_dburl = _x.get("dburl", "").strip()
env_dburl = os.getenv("SQL_URL", "").strip()
try:
    helper_dburl = get_database_url_from_env(required=False) or ""
except Exception:
    helper_dburl = ""
ini_dburl = (config.get_main_option("sqlalchemy.url") or "").strip()

effective_url = cli_dburl or env_dburl or helper_dburl or ini_dburl
if not effective_url:
    raise RuntimeError("No database URL found (env/CLI/ini). Provide one.")

def _coerce_to_async(u: URL) -> URL:
    dn = (u.drivername or "").lower()
    if "+asyncpg" in dn or "+aiomysql" in dn or "+aiosqlite" in dn:
        return u
    backend = (u.get_backend_name() or "").lower()
    if backend in ("postgresql", "postgres"):
        return u.set(drivername="postgresql+asyncpg")
    if backend == "mysql":
        return u.set(drivername="mysql+aiomysql")
    if backend == "sqlite":
        return u.set(drivername="sqlite+aiosqlite")
    return u

u = make_url(effective_url)
u = _coerce_to_async(u)
u = _ensure_ssl_default(u)
config.set_main_option("sqlalchemy.url", u.render_as_string(hide_password=False))

# --- metadata discovery (same as sync) ---
DISCOVER_PACKAGES: List[str] = [__PACKAGES_LIST__]
ENV_DISCOVER = os.getenv("ALEMBIC_DISCOVER_PACKAGES")
if ENV_DISCOVER:
    DISCOVER_PACKAGES = [s.strip() for s in ENV_DISCOVER.split(',') if s.strip()]

def _collect_metadata() -> list[object]:
    try:
        from svc_infra.db.sql.base import ModelBase  # type: ignore
        md = getattr(ModelBase, "metadata", None)
        if md is not None and hasattr(md, "tables") and md.tables:
            return [md]
    except Exception as e:
        logger.debug("ModelBase not available or empty: %s", e)

    import importlib, pkgutil, pathlib
    found: list[object] = []

    def _maybe_add(obj: object) -> None:
        md = getattr(obj, "metadata", None) or obj
        if hasattr(md, "tables") and hasattr(md, "schema"):
            found.append(md)

    pkgs = list(DISCOVER_PACKAGES) or []
    if not pkgs:
        roots = []
        if prepend:
            roots.append(pathlib.Path(prepend))
            roots.append(pathlib.Path(prepend) / "src")
        for root in roots:
            if not root or not root.exists():
                continue
            for p in root.iterdir():
                if p.is_dir() and (p / "__init__.py").exists():
                    pkgs.append(p.name)

    for pkg_name in pkgs:
        try:
            pkg = importlib.import_module(pkg_name)
        except Exception as e:
            logger.debug("Failed to import %s: %s", pkg_name, e)
            continue

        for attr in ("metadata", "MetaData", "Base", "base"):
            obj = getattr(pkg, attr, None)
            if obj is not None:
                _maybe_add(obj)

        for subname in ("models",):
            try:
                sub = importlib.import_module(f"{pkg_name}.{subname}")
                for attr in ("metadata", "MetaData", "Base", "base"):
                    obj = getattr(sub, attr, None)
                    if obj is not None:
                        _maybe_add(obj)
            except Exception:
                pass

        mod_path = getattr(pkg, "__path__", None)
        if not mod_path:
            continue
        for _, name, ispkg in pkgutil.walk_packages(mod_path, prefix=pkg_name + "."):
            if ispkg or not any(x in name for x in (".models", ".db", ".orm", ".entities")):
                continue
            try:
                mod = importlib.import_module(name)
            except Exception:
                continue
            for attr in ("metadata", "MetaData", "Base", "base"):
                obj = getattr(mod, attr, None)
                if obj is not None:
                    _maybe_add(obj)

    # --- AUTOBIND API KEY MODEL (if a marked User model exists) ---
    try:
        from svc_infra.db.sql.apikey import try_autobind_apikey_model
        # If you prefer gating on env, pass require_env=True and set AUTH_ENABLE_API_KEYS=1
        try_autobind_apikey_model(require_env=False)
    except Exception as e:
        logger.debug("svc-infra apikey autobind skipped: %s", e)

    uniq, seen = [], set()
    for md in found:
        if id(md) not in seen:
            seen.add(id(md))
            uniq.append(md)
    return uniq

target_metadata = _collect_metadata()

def _want_include_schemas() -> bool:
    val = _x.get("include_schemas", "") or os.getenv("ALEMBIC_INCLUDE_SCHEMAS", "")
    return str(val).strip() in {"1", "true", "True", "yes"}

def _system_schemas_for(url: str) -> set[str]:
    try:
        backend = make_url(url).get_backend_name().lower()
    except Exception:
        backend = ""
    if backend in {"mysql", "mariadb"}:
        return {"mysql", "performance_schema", "information_schema", "sys"}
    if backend in {"postgresql", "postgres"}:
        return {"pg_catalog", "information_schema"}
    if backend in {"mssql"}:
        return {"INFORMATION_SCHEMA", "sys"}
    if backend in {"snowflake"}:
        return {"INFORMATION_SCHEMA"}
    return set()

def _include_object_factory(url: str):
    sys_schemas = _system_schemas_for(url)
    def _include_object(obj, name, type_, reflected, compare_to):
        schema = getattr(obj, "schema", None)
        if schema and str(schema) in sys_schemas:
            return False
        if type_ == "table" and name == (context.get_x_argument(as_dictionary=True).get("version_table") or "alembic_version"):
            return True
        return True
    return _include_object

def _do_run_migrations(connection):
    url = config.get_main_option("sqlalchemy.url")
    context.configure(
        connection=connection,
        target_metadata=target_metadata,
        compare_type=True,
        compare_server_default=True,
        include_schemas=_want_include_schemas(),
        include_object=_include_object_factory(url),
        version_table=os.getenv("ALEMBIC_VERSION_TABLE", "alembic_version"),
        version_table_schema=os.getenv("ALEMBIC_VERSION_SCHEMA") or None,
        render_item=_render_item,
    )
    with context.begin_transaction():
        context.run_migrations()

async def run_migrations_online() -> None:
    url = config.get_main_option("sqlalchemy.url")
    engine = create_async_engine(url)
    async with engine.connect() as connection:
        await connection.run_sync(_do_run_migrations)
    await engine.dispose()

if context.is_offline_mode():
    raise SystemExit("Run offline migrations with a sync env.py or set offline to False.")
else:
    import asyncio as _asyncio
    _asyncio.run(run_migrations_online())
