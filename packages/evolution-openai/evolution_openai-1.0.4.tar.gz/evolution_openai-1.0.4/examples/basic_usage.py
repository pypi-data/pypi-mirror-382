#!/usr/bin/env python3
"""
Ğ‘Ğ°Ğ·Ğ¾Ğ²Ñ‹Ğµ Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€Ñ‹ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Evolution OpenAI
"""

import os

from evolution_openai import EvolutionOpenAI, create_client

# Cloud.ru Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ endpoint (Ğ·Ğ°Ğ¼ĞµĞ½Ğ¸Ñ‚Ğµ Ğ½Ğ° Ğ²Ğ°Ñˆ)
BASE_URL = os.getenv("EVOLUTION_BASE_URL", "https://your-endpoint.cloud.ru/v1")


def check_credentials():
    """ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµÑ‚ Ğ½Ğ°Ğ»Ğ¸Ñ‡Ğ¸Ğµ ÑƒÑ‡ĞµÑ‚Ğ½Ñ‹Ñ… Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…"""
    key_id = os.getenv("EVOLUTION_KEY_ID", "your_key_id")
    secret = os.getenv("EVOLUTION_SECRET", "your_secret")

    if (
        key_id == "your_key_id"
        or secret == "your_secret"
        or not key_id
        or not secret
    ):
        return None, None
    return key_id, secret


def get_available_model(client):
    """ĞŸĞ¾Ğ»ÑƒÑ‡Ğ°ĞµÑ‚ Ğ¿ĞµÑ€Ğ²ÑƒÑ Ğ´Ğ¾ÑÑ‚ÑƒĞ¿Ğ½ÑƒÑ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ Ğ¸Ğ· API"""
    try:
        models = client.models.list()
        if models and models.data and len(models.data) > 0:
            model_name = models.data[0].id
            print(f"ğŸ”§ Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµĞ¼ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ: {model_name}")
            return model_name
        else:
            print("âš ï¸ ĞĞµÑ‚ Ğ´Ğ¾ÑÑ‚ÑƒĞ¿Ğ½Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ Ğ² /v1/models, Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµĞ¼ 'default'")
            return "default"
    except Exception as e:
        print(f"âš ï¸ ĞÑˆĞ¸Ğ±ĞºĞ° Ğ¿Ğ¾Ğ»ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ ({e}), Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµĞ¼ 'default'")
        return "default"


def basic_chat_example():
    """Ğ‘Ğ°Ğ·Ğ¾Ğ²Ñ‹Ğ¹ Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€ Chat Completions"""
    print("=== Ğ‘Ğ°Ğ·Ğ¾Ğ²Ñ‹Ğ¹ Chat Completions ===\n")

    key_id, secret = check_credentials()
    if not key_id or not secret:
        print("Ğ£ÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ¸Ñ‚Ğµ Ğ¿ĞµÑ€ĞµĞ¼ĞµĞ½Ğ½Ñ‹Ğµ Ğ¾ĞºÑ€ÑƒĞ¶ĞµĞ½Ğ¸Ñ:")
        print("export EVOLUTION_KEY_ID='Ğ²Ğ°Ñˆ_key_id'")
        print("export EVOLUTION_SECRET='Ğ²Ğ°Ñˆ_secret'")
        return None  # ĞŸÑ€Ğ¾Ğ¿ÑƒÑĞºĞ°ĞµĞ¼, ÑÑ‚Ğ¾ Ğ½Ğµ Ğ¾ÑˆĞ¸Ğ±ĞºĞ°

    try:
        # Ğ¡Ğ¾Ğ·Ğ´Ğ°ĞµĞ¼ client Ñ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸ĞµĞ¼ ĞºĞ¾Ğ½Ñ‚ĞµĞºÑÑ‚Ğ½Ğ¾Ğ³Ğ¾ Ğ¼ĞµĞ½ĞµĞ´Ğ¶ĞµÑ€Ğ°
        with EvolutionOpenAI(
            key_id=key_id, secret=secret, base_url=BASE_URL
        ) as client:
            # ĞŸĞ¾Ğ»ÑƒÑ‡Ğ°ĞµĞ¼ Ğ´Ğ¾ÑÑ‚ÑƒĞ¿Ğ½ÑƒÑ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ
            model_name = get_available_model(client)

            # ĞŸÑ€Ğ¾ÑÑ‚Ğ¾Ğ¹ Ğ·Ğ°Ğ¿Ñ€Ğ¾Ñ
            response = client.chat.completions.create(
                model=model_name,
                messages=[
                    {
                        "role": "system",
                        "content": "You are a helpful assistant.",
                    },
                    {
                        "role": "user",
                        "content": "Ğ§Ñ‚Ğ¾ Ñ‚Ğ°ĞºĞ¾Ğµ Ğ¸ÑĞºÑƒÑÑÑ‚Ğ²ĞµĞ½Ğ½Ñ‹Ğ¹ Ğ¸Ğ½Ñ‚ĞµĞ»Ğ»ĞµĞºÑ‚?",
                    },
                ],
                max_tokens=16,
            )

            print(f"ĞÑ‚Ğ²ĞµÑ‚: {response.choices[0].message.content}")
            print(f"ĞœĞ¾Ğ´ĞµĞ»ÑŒ: {response.model}")
            print(f"Ğ¢Ğ¾ĞºĞµĞ½Ğ¾Ğ² Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¾: {response.usage.total_tokens}")
            return True

    except Exception as e:
        print(f"ĞÑˆĞ¸Ğ±ĞºĞ°: {e}")
        return False


def streaming_example():
    """ĞŸÑ€Ğ¸Ğ¼ĞµÑ€ Streaming Ğ¾Ñ‚Ğ²ĞµÑ‚Ğ¾Ğ²"""
    print("\n=== Streaming Example ===\n")

    key_id = os.getenv("EVOLUTION_KEY_ID", "your_key_id")
    secret = os.getenv("EVOLUTION_SECRET", "your_secret")

    if key_id == "your_key_id" or secret == "your_secret":
        print("Ğ£ÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ¸Ñ‚Ğµ Ğ¿ĞµÑ€ĞµĞ¼ĞµĞ½Ğ½Ñ‹Ğµ Ğ¾ĞºÑ€ÑƒĞ¶ĞµĞ½Ğ¸Ñ Ğ´Ğ»Ñ streaming")
        return None

    try:
        with EvolutionOpenAI(
            key_id=key_id, secret=secret, base_url=BASE_URL
        ) as client:
            # ĞŸĞ¾Ğ»ÑƒÑ‡Ğ°ĞµĞ¼ Ğ´Ğ¾ÑÑ‚ÑƒĞ¿Ğ½ÑƒÑ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ
            model_name = get_available_model(client)

            print("Streaming Ğ¾Ñ‚Ğ²ĞµÑ‚:")
            stream = client.chat.completions.create(
                model=model_name,
                messages=[
                    {
                        "role": "user",
                        "content": "Ğ Ğ°ÑÑĞºĞ°Ğ¶Ğ¸ ĞºĞ¾Ñ€Ğ¾Ñ‚ĞºÑƒÑ Ğ¸ÑÑ‚Ğ¾Ñ€Ğ¸Ñ Ğ¿Ñ€Ğ¾ Ñ€Ğ¾Ğ±Ğ¾Ñ‚Ğ°",
                    }
                ],
                stream=True,
                max_tokens=16,
            )

            for chunk in stream:
                if chunk.choices[0].delta.content:
                    print(chunk.choices[0].delta.content, end="", flush=True)
            print("\n")
            return True

    except Exception as e:
        print(f"Streaming Ğ¾ÑˆĞ¸Ğ±ĞºĞ°: {e}")
        return False


def helper_function_example():
    """ĞŸÑ€Ğ¸Ğ¼ĞµÑ€ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ helper Ñ„ÑƒĞ½ĞºÑ†Ğ¸Ğ¹"""
    print("\n=== Helper Functions Example ===\n")

    key_id = os.getenv("EVOLUTION_KEY_ID", "your_key_id")
    secret = os.getenv("EVOLUTION_SECRET", "your_secret")

    if key_id == "your_key_id" or secret == "your_secret":
        print("Ğ£ÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ¸Ñ‚Ğµ Ğ¿ĞµÑ€ĞµĞ¼ĞµĞ½Ğ½Ñ‹Ğµ Ğ¾ĞºÑ€ÑƒĞ¶ĞµĞ½Ğ¸Ñ Ğ´Ğ»Ñ helper Ñ„ÑƒĞ½ĞºÑ†Ğ¸Ğ¹")
        return None

    try:
        # Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµĞ¼ create_client helper Ñ ĞºĞ¾Ğ½Ñ‚ĞµĞºÑÑ‚Ğ½Ñ‹Ğ¼ Ğ¼ĞµĞ½ĞµĞ´Ğ¶ĞµÑ€Ğ¾Ğ¼
        with create_client(
            key_id=key_id,
            secret=secret,
            base_url=BASE_URL,
            timeout=30.0,
            max_retries=3,
        ) as client:
            # ĞŸĞ¾Ğ»ÑƒÑ‡Ğ°ĞµĞ¼ Ğ´Ğ¾ÑÑ‚ÑƒĞ¿Ğ½ÑƒÑ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ
            model_name = get_available_model(client)

            response = client.chat.completions.create(
                model=model_name,
                messages=[{"role": "user", "content": "ĞŸÑ€Ğ¸Ğ²ĞµÑ‚! ĞšĞ°Ğº Ğ´ĞµĞ»Ğ°?"}],
                max_tokens=16,
            )

            print(
                f"Helper client Ğ¾Ñ‚Ğ²ĞµÑ‚: {response.choices[0].message.content}"
            )

            # Ğ˜Ğ½Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ğ¸Ñ Ğ¾ Ñ‚Ğ¾ĞºĞµĞ½Ğµ
            token_info = client.get_token_info()
            print(f"Ğ¡Ñ‚Ğ°Ñ‚ÑƒÑ Ñ‚Ğ¾ĞºĞµĞ½Ğ°: {token_info}")
            return True

    except Exception as e:
        print(f"Helper Ğ¾ÑˆĞ¸Ğ±ĞºĞ°: {e}")
        return False


def advanced_features_example():
    """ĞŸÑ€Ğ¸Ğ¼ĞµÑ€ Ğ¿Ñ€Ğ¾Ğ´Ğ²Ğ¸Ğ½ÑƒÑ‚Ñ‹Ñ… Ğ²Ğ¾Ğ·Ğ¼Ğ¾Ğ¶Ğ½Ğ¾ÑÑ‚ĞµĞ¹"""
    print("\n=== Advanced Features Example ===\n")

    key_id = os.getenv("EVOLUTION_KEY_ID", "your_key_id")
    secret = os.getenv("EVOLUTION_SECRET", "your_secret")

    if key_id == "your_key_id" or secret == "your_secret":
        print("Ğ£ÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ¸Ñ‚Ğµ Ğ¿ĞµÑ€ĞµĞ¼ĞµĞ½Ğ½Ñ‹Ğµ Ğ¾ĞºÑ€ÑƒĞ¶ĞµĞ½Ğ¸Ñ Ğ´Ğ»Ñ advanced Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€Ğ¾Ğ²")
        return None

    try:
        with EvolutionOpenAI(
            key_id=key_id, secret=secret, base_url=BASE_URL
        ) as client:
            # ĞŸĞ¾Ğ»ÑƒÑ‡Ğ°ĞµĞ¼ Ğ´Ğ¾ÑÑ‚ÑƒĞ¿Ğ½ÑƒÑ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ
            model_name = get_available_model(client)

            # Per-request options
            print("1. Per-request options:")
            response = client.with_options(
                timeout=60.0
            ).chat.completions.create(
                model=model_name,
                messages=[{"role": "user", "content": "Quick test"}],
                max_tokens=16,
            )
            print(f"   ĞÑ‚Ğ²ĞµÑ‚: {response.choices[0].message.content}")

            # Raw response
            print("\n2. Raw response access:")
            raw_response = client.chat.completions.with_raw_response.create(
                model=model_name,
                messages=[{"role": "user", "content": "Raw test"}],
                max_tokens=16,
            )
            print(f"   Status: {raw_response.status_code}")
            parsed = raw_response.parse()
            print(f"   Content: {parsed.choices[0].message.content}")

            # Token management
            print("\n3. Token management:")
            current_token = client.current_token
            print(f"   Ğ¢ĞµĞºÑƒÑ‰Ğ¸Ğ¹ Ñ‚Ğ¾ĞºĞµĞ½: {current_token[:20]}...")

            # Refresh token
            new_token = client.refresh_token()
            print(f"   ĞĞ±Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ½Ñ‹Ğ¹ Ñ‚Ğ¾ĞºĞµĞ½: {new_token[:20]}...")
            return True

    except Exception as e:
        print(f"Advanced Ğ¾ÑˆĞ¸Ğ±ĞºĞ°: {e}")
        return False


def main():
    """ĞÑĞ½Ğ¾Ğ²Ğ½Ğ°Ñ Ñ„ÑƒĞ½ĞºÑ†Ğ¸Ñ Ñ Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€Ğ°Ğ¼Ğ¸"""
    print("ğŸš€ Evolution OpenAI - ĞŸÑ€Ğ¸Ğ¼ĞµÑ€Ñ‹ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ\n")

    results = []
    results.append(basic_chat_example())
    results.append(streaming_example())
    results.append(helper_function_example())
    results.append(advanced_features_example())

    # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ‹
    success_count = sum(1 for r in results if r is True)
    total_count = len([r for r in results if r is not None])

    print("\nâœ… Ğ’ÑĞµ Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€Ñ‹ Ğ²Ñ‹Ğ¿Ğ¾Ğ»Ğ½ĞµĞ½Ñ‹!")
    print("\nğŸ’¡ ĞŸĞ¾Ğ´ÑĞºĞ°Ğ·ĞºĞ¸:")
    print("- Ğ£ÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ¸Ñ‚Ğµ Ğ¿ĞµÑ€ĞµĞ¼ĞµĞ½Ğ½Ñ‹Ğµ Ğ¾ĞºÑ€ÑƒĞ¶ĞµĞ½Ğ¸Ñ Ğ´Ğ»Ñ Ñ‚ĞµÑÑ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ")
    print("- Ğ—Ğ°Ğ¼ĞµĞ½Ğ¸Ñ‚Ğµ BASE_URL Ğ½Ğ° Ğ²Ğ°Ñˆ endpoint")
    print("- ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑŒÑ‚Ğµ Ğ´Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚Ğ°Ñ†Ğ¸Ñ Ğ´Ğ»Ñ Ğ´Ğ¾Ğ¿Ğ¾Ğ»Ğ½Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ñ… Ğ²Ğ¾Ğ·Ğ¼Ğ¾Ğ¶Ğ½Ğ¾ÑÑ‚ĞµĞ¹")

    # Ğ’Ğ¾Ğ·Ğ²Ñ€Ğ°Ñ‰Ğ°ĞµĞ¼ False ĞµÑĞ»Ğ¸ Ğ±Ñ‹Ğ»Ğ¸ Ñ€ĞµĞ°Ğ»ÑŒĞ½Ñ‹Ğµ Ğ¾ÑˆĞ¸Ğ±ĞºĞ¸ API
    if total_count > 0 and success_count < total_count:
        return False
    return True


if __name__ == "__main__":
    import sys

    success = main()
    sys.exit(0 if success else 1)
