<p align="center">
  <img src="midia/Pymandua.png" alt="Pymandua Logo">
</p>

# Pymandua: Web Scraper para todos os websites 
## Convers√£o de HTML para Markdown para pr√©-processamento de LLMs

Este projeto √© uma biblioteca Python que realiza Web Scraping inteligente com l√≥gica fuzzy e converte p√°ginas HTML e conte√∫dos relacionados (como subp√°ginas e conte√∫dos renderizados com JS) em um Markdown simplificado, ideal para Large Language Models (LLMs) e an√°lises posteriores.

---

## üöÄ Funcionalidades

- Web scraping automatizado com Selenium e suporte a p√°ginas din√¢micas
- Convers√£o precisa de HTML para Markdown limpo com suporte a:
  - T√≠tulos, par√°grafos, listas, links, tabelas, blocos de c√≥digo, entre outros
- L√≥gica de busca fuzzy para identificar se o conte√∫do da p√°gina e p√°ginas ao seu redor est√° relacionado √†s palavras-chave desejadas
- Mecanismo de retorno autom√°tico de p√°ginas visitadas
- Pode ser utilizado como biblioteca ou como script principal

---

## üß† Como Funciona

### üîç Web Scraping com Selenium

O m√≥dulo utiliza o `undetected-chromedriver` e `selenium-stealth` com o ``selenium`` para navegar por p√°ginas web, extrair conte√∫dos e retroceder ap√≥s a coleta. O conte√∫do das p√°ginas √© tratado pelo `BeautifulSoup` e convertido em Markdown por um parser customizado.

### üß™ L√≥gica Fuzzy

A compara√ß√£o entre o conte√∫do da p√°gina e as palavras-chave fornecidas √© feita com `RapidFuzz`, utilizando similaridade textual (ex: token_sort_ratio). Isso permite validar se a p√°gina realmente trata do tema buscado, mesmo que o texto n√£o seja exatamente igual, ou se existe alguns conte√∫dos ao seu redor (subp√°ginas e conte√∫dos criados a partir de reatividade com JavaScript) para capturar e consolidar em um √∫nico lugar.

---

## üñºÔ∏è Fluxo do Processo


<p align="center">
  <img src="midia/flowchart.png" alt="Fluxograma do Processo" style="background: white; padding: 8px; border-radius: 8px;">
</p>


### üß™ Instala√ß√£o

**Com pip**
```bash
pip install pymandua
```


**Ou alternativamente**
1. **Clone o reposit√≥rio:**
```bash
git clone https://github.com/Mark-Campanella/pymandua.git
cd pymandua
```

2. **Crie um ambiente virtual e ative:**
```bash
python -m venv env
source env/bin/activate  # Linux/macOS
env\Scripts\activate     # Windows
```

3. **Instale as depend√™ncias:**
``` bash
pip install -r requirements.txt
```


### üîß Uso como script
```python
from pymandua import to_mkd

result = to_mkd(
    urls="https://pt.wikipedia.org/wiki/Lu√≠s_XIV_de_Fran√ßa",
    keywords=["Lu√≠s XIV", "Fran√ßa", "Rei Sol"],
    output_path=r"projeto/output",
    wait=2,
    threshold=90
)
print(result)

```

**Uso como CLI**
```bash
to-mkd --urls "https://exemplo.com" --keywords "palavra1,palavra2" --output "saida.md" --wait 2 --threshold 95
```

### üß© Estrutura do Projeto
```
‚îú‚îÄ‚îÄ pymandua/              # M√≥dulo principal
‚îÇ   ‚îú‚îÄ‚îÄ interface.py       # Interface principal do conversor
‚îÇ   ‚îú‚îÄ‚îÄ converter.py       # Conversor de HTML para Markdown
‚îÇ   ‚îú‚îÄ‚îÄ gatherer.py        # Web scraper e parser de conte√∫do
‚îÇ   ‚îú‚îÄ‚îÄ driver.py          # Inicializador de driver para o selenium
‚îÇ   ‚îú‚îÄ‚îÄ crawler.py         # Web crawler e parser de conte√∫do
‚îÇ   ‚îú‚îÄ‚îÄ treater.py         # Prepara para o cleaner
‚îÇ   ‚îú‚îÄ‚îÄ aggregator.py      # Agrega os diversos HTMLs resultantes em um para ser convertido
‚îÇ   ‚îú‚îÄ‚îÄ cleaner.py         # Parser e limpador de conte√∫do n√£o necess√°rio
‚îú‚îÄ‚îÄ output/                # Arquivos .mkd gerados
‚îú‚îÄ‚îÄ requirements.txt       # Depend√™ncias
‚îú‚îÄ‚îÄ main.py                # Exemplo de uso
```

**üìö Refer√™ncias**
- [Selenium Docs](https://selenium-python.readthedocs.io)
- [BeautifulSoup Docs](https://www.crummy.com/software/BeautifulSoup/bs4/doc/)
- [RapidFuzz Docs](maxbachmann.github.io/RapidFuzz/)
- [RapidFuzz Examples](https://github.com/rapidfuzz/RapidFuzz#examples)

----------

### üß† RAG Pipeline (An√°lise com IA)
Este projeto estende sua funcionalidade principal com um pipeline de An√°lise de Conte√∫do usando `Retrieval-Augmented Generation (RAG)`. Ele permite que voc√™ use os arquivos Markdown gerados para consultas inteligentes, respondendo perguntas e gerando tabelas estruturadas sobre o conte√∫do.

### üöÄ Funcionalidades Chave do RAG
- Modularidade "Plug & Play": Alterne facilmente entre diferentes provedores de LLM (``Ollama, OpenAI, Gemini``) e bancos de dados vetoriais (``ChromaDB, Pinecone``) com a simples altera√ß√£o de um par√¢metro.

- Interface Web (UI): Uma interface interativa e amig√°vel, criada com ``Gradio``, que se abre automaticamente no navegador para uma experi√™ncia de uso otimizada.

- Gera√ß√£o de Tabelas: Pe√ßa ao LLM para extrair dados espec√≠ficos e format√°-los em uma tabela Markdown com cabe√ßalhos personalizados, ideal para an√°lise.

### üîß Uso do Pipeline RAG
O pipeline RAG √© um processo separado da convers√£o de HTML para Markdown, permitindo que voc√™ use a biblioteca de forma modular.

#### Passo 1: Gerar os Arquivos Markdown

Primeiro, use a fun√ß√£o ``to_mkd`` para gerar os arquivos Markdown no diret√≥rio de sa√≠da (configurado em ``config.yaml``). Seus arquivos .mkd servir√£o como a base de conhecimento para o sistema RAG.

```python
from pymandua import to_mkd

# This will generate the .mkd files in the 'output' directory
to_mkd(
    urls=["https://pt.wikipedia.org/wiki/Lu√≠s_XIV_de_Fran√ßa"],
    keywords=["Lu√≠s XIV"],
    wait=2,
    threshold=90
)
```
### Passo 2: Iniciar o Pipeline RAG

Em seguida, use a nova fun√ß√£o ``start_rag_pipeline`` para processar os arquivos Markdown existentes e iniciar a interface de usu√°rio. Voc√™ pode usar as configura√ß√µes padr√£o do ``config.yaml`` ou sobrescrev√™-las com par√¢metros diretos para maior flexibilidade.

```python
from pymandua import start_rag_pipeline

# Example 1: Use default settings from config.yaml
start_rag_pipeline()


# Example 2: Override models and providers via code
start_rag_pipeline(
    llm_model="llama3-chatqa:8b",
    embedding_model="nomic-embed-text",
    active_provider="ollama",
    persist_directory="./my-rag-db"
)

```

### üñºÔ∏è Fluxo de Processo Completo
O diagrama de fluxo do seu projeto agora √© expandido para incluir o pipeline RAG, ilustrando o processo completo da web at√© a an√°lise com IA.

```mermaid
graph TD
    subgraph Web Scraping & Conversion
        User[User] --> to_mkd(to_mkd);
        to_mkd --> Output[output/];
    end

    subgraph RAG Pipeline
        Output --> start_rag_pipeline(start_rag_pipeline);
        start_rag_pipeline --> Ingest(Ingestion: Embeddings & Storage);
        Ingest --> VectorDB[Vector Database ] ;
        VectorDB --> Gradio[Gradio UI];
        Gradio --> LLM(LLM);
        Gradio --> VectorDB;
    end

    LLM --> Answers[Answers & Tables];
```