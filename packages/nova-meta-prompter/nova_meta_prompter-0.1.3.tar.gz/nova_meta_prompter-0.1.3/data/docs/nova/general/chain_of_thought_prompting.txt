<chain_of_thought_prompting>

<introduction>
You can improve the problem solving skills of Amazon Nova by breaking down complex issues into simpler, more manageable tasks or intermediate thoughts. Amazon Nova models work better in reasoning if they are given time to think through the problem and then arrive at the answer. This process of guiding the model to think step-by-step and make attempts at reasoning before arriving at an answer is called chain-of-thought (CoT) prompting.

By guiding Amazon Nova through a step-by-step reasoning process, CoT prompting ensures clearer logic and improves the coherence and accuracy of the output. For example, in tackling a mathematical word problem, the model can first identify the relevant variables, then construct equations based on the given information, and finally solve those equations to reach the solution. This strategy not only minimizes errors but also makes the reasoning process more transparent and easier to follow, thereby enhancing the quality of Amazon Nova output.
</introduction>

<benefits>
Chain of thought is recommended for several reasons:
- Improves the Accuracy: Giving Model chance to first do the thinking before responding, helps model land at a better answer, as compared to asking model directly to think.
- Improves Debugging Process: Sometimes chain of thought reasoning helps debug where and why model made some errors. This feedback is essential to understand how to iterate on prompt to improve the flaws in models reasoning.
</benefits>

<limitations>
Chain of thought is not always necessary, and can induce some additional overhead. Consider not using CoT in the following scenarios:
- Increased Latency and Output Tokens: Chain of Thought can increase the latency as the model is thinking before answering, the increase latency and output tokens can also make the overall inference expensive
- Simpler tasks don't need COT: Not all tasks require deep chain of thought, it is generally recommended to use chain of thought in tasks such as multi-step analysis, math problems, complex reasoning tasks.
</limitations>

<prompt_templates>
Template 1:
{{User query}} Think step-by-step.

Template 2:
{{User query}} Please follow these steps:
1. {{Step 1}}
2. {{Step 2}}
...

Template 3:
{{User query}}
Think step by step first and then answer. Follow below format when responding
Response Schema:
<thinking>
( your thinking goes here )
</thinking>
<answer>
( your answer goes here )
</answer>
</prompt_templates>

<examples>
<example1>
Adding "think step by step" at the end of prompts helps prime the model to begin with additional thinking before jumping to the answer.

Original prompt:
"I'm considering two investment opportunities and would appreciate your guidance to make the best decision. Option A is a low-risk bond fund with an expected annual return of 3%, while Option B is a moderately-risky stock portfolio with an expected annual return of 7%. Given my financial goals and risk tolerance, which option would you recommend?"

Optimized prompt:
"I'm considering two investment opportunities and would appreciate your guidance to make the best decision. Option A is a low-risk bond fund with an expected annual return of 3%, while Option B is a moderately-risky stock portfolio with an expected annual return of 7%. Given my financial goals and risk tolerance, which option would you recommend? Think step-by-step."
</example1>

<example2>
Adding step-by-step guiding cues helps the model be more structured in its thinking before arriving at the final solution.

Original prompt:
"You are a project manager for a small software development team tasked with launching a new app feature. You want to streamline the development process and ensure timely delivery."

Optimized prompt:
"You are a project manager for a small software development team tasked with launching a new app feature. You want to streamline the development process and ensure timely delivery. Please follow these steps:
1. Define Requirements
2. Breakdown into Tasks
3. Set Deadlines
4. Monitor Progress and Optimize"
</example2>
</examples>

</chain_of_thought_prompting>