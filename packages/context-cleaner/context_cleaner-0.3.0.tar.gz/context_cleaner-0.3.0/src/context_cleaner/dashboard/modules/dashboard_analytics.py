"""
Dashboard Analytics and Chart Generation

Phase 2.5 Extraction: Advanced analytics processing and Plotly chart generation
Extracted from analytics-related methods in comprehensive_health_dashboard.py
Implements sophisticated session analytics and visualization capabilities

Contains:
- Plotly chart generation engine with professional styling
- Session analytics processing with JSONL parsing
- Advanced analytics charts (trends, distributions, patterns)
- Session timeline visualization with Gantt-style charts
- Analytics API endpoint coordination
- Cache-optimized session data processing
"""

import asyncio
import json
import logging
from datetime import datetime, timedelta
from pathlib import Path
from typing import Dict, Any, Optional, List

import plotly.graph_objects as go
from plotly.utils import PlotlyJSONEncoder

from context_cleaner.api.models import (
    create_no_data_error, create_unsupported_error, create_error_response,
    AnalyticsChartResponse, AnalyticsSummaryResponse
)

logger = logging.getLogger(__name__)


class AnalyticsChartGenerator:
    """
    Advanced chart generation engine using Plotly
    Extracted from chart generation methods in comprehensive dashboard
    Implements professional styling and interactive visualizations
    """

    def __init__(self, performance_history: List[Dict[str, Any]] = None):
        self.performance_history = performance_history or []

    def generate_plotly_chart(self, chart_type: str) -> Dict[str, Any]:
        """Generate Plotly chart data for various chart types."""
        try:
            if chart_type == "health_trends":
                if not self.performance_history:
                    raise create_no_data_error("health")

                # Extract trend data
                timestamps = [h["timestamp"] for h in self.performance_history[-50:]]
                overall_scores = [
                    h.get("overall_health_score", 0.5)
                    for h in self.performance_history[-50:]
                ]
                focus_scores = [
                    h.get("focus_score", 0.5) for h in self.performance_history[-50:]
                ]

                fig = go.Figure()

                fig.add_trace(
                    go.Scatter(
                        x=timestamps,
                        y=overall_scores,
                        mode="lines+markers",
                        name="Overall Health",
                        line=dict(color="#27AE60", width=3),
                    )
                )

                fig.add_trace(
                    go.Scatter(
                        x=timestamps,
                        y=focus_scores,
                        mode="lines",
                        name="Focus Score",
                        line=dict(color="#3498DB", width=2, dash="dash"),
                    )
                )

                fig.update_layout(
                    title="Context Health Trends Over Time",
                    xaxis_title="Time",
                    yaxis_title="Health Score",
                    yaxis=dict(range=[0, 1]),
                    hovermode="x unified",
                    template="plotly_white",
                )

                return json.loads(json.dumps(fig, cls=PlotlyJSONEncoder))

            elif chart_type == "productivity_overview":
                # Create productivity overview chart (requires data sources integration)
                categories = ["Focus Time", "Efficiency", "Sessions", "Active Days"]
                values = [75, 85, 60, 90]  # Mock data for extraction phase

                fig = go.Figure(
                    data=go.Bar(
                        x=categories,
                        y=values,
                        marker_color=["#3498DB", "#27AE60", "#F39C12", "#E74C3C"],
                    )
                )

                fig.update_layout(
                    title="Productivity Overview",
                    yaxis_title="Score (%)",
                    template="plotly_white",
                )

                return json.loads(json.dumps(fig, cls=PlotlyJSONEncoder))

            else:
                raise create_unsupported_error("Chart type", chart_type)

        except Exception as e:
            logger.error(f"Chart generation failed: {e}")
            raise create_error_response(str(e), "ANALYTICS_ERROR")

    def update_performance_history(self, history: List[Dict[str, Any]]) -> None:
        """Update performance history for chart generation"""
        self.performance_history = history


class SessionAnalyticsProcessor:
    """
    Session analytics processing with JSONL parsing and cache integration
    Extracted from session analytics methods in comprehensive dashboard
    Implements cache-optimized session data processing with discovery services
    """

    def __init__(self, dashboard_cache=None):
        self.dashboard_cache = dashboard_cache

    def get_recent_sessions_analytics(self, days: int = 30) -> List[Dict[str, Any]]:
        """Get recent session data using real-time cache discovery and JSONL parsing."""
        # Phase 2.3: Check unified cache first for performance optimization
        if self.dashboard_cache:
            cached_data = self.dashboard_cache.get_session_analytics_cache()
            if cached_data is not None:
                logger.debug(f"Returning cached session analytics ({len(cached_data)} sessions)")
                return cached_data

        logger.info(f"Retrieving recent sessions for analytics dashboard ({days} days)")
        try:
            # Use real-time cache discovery system to find JSONL session files
            from context_cleaner.analysis.discovery import CacheDiscoveryService
            from context_cleaner.analysis.session_parser import SessionCacheParser

            discovery_service = CacheDiscoveryService()

            # Discover cache locations first
            locations = discovery_service.discover_cache_locations()
            logger.info(f"Discovered {len(locations)} cache locations")

            # Get current project cache location
            current_project = discovery_service.get_current_project_cache()
            if not current_project or not current_project.is_accessible:
                logger.warning(
                    "No accessible current project cache found - returning empty session data"
                )
                return []

            logger.info(f"Loading sessions from: {current_project.path}")
            logger.info(
                f"Found {current_project.session_count} sessions ({current_project.size_mb:.1f}MB)"
            )

            # Parse JSONL session files directly
            dashboard_sessions = []

            # Get all JSONL files from the current project
            project_path = Path(current_project.path)
            jsonl_files = list(project_path.glob("*.jsonl"))

            # Get cutoff date for filtering recent sessions
            cutoff_date = datetime.now() - timedelta(days=days)

            for jsonl_file in jsonl_files:
                try:
                    file_modified = datetime.fromtimestamp(jsonl_file.stat().st_mtime)
                    if file_modified < cutoff_date:
                        continue  # Skip old files

                    with open(jsonl_file, "r", encoding="utf-8") as f:
                        session_data = []
                        for line_num, line in enumerate(f):
                            line = line.strip()
                            if line:
                                try:
                                    entry = json.loads(line)
                                    session_data.append(entry)
                                except json.JSONDecodeError as e:
                                    logger.debug(
                                        f"Skipping invalid JSON line {line_num} in {jsonl_file.name}: {e}"
                                    )
                                    continue

                        if session_data:
                            # Create dashboard session from JSONL data
                            dashboard_session = {
                                "session_id": jsonl_file.stem,
                                "start_time": file_modified.isoformat(),
                                "end_time": file_modified.isoformat(),
                                "duration_minutes": len(session_data)
                                * 2,  # Estimate based on entries
                                "productivity_score": min(
                                    100.0, 50.0 + (len(session_data) * 0.5)
                                ),  # Score based on activity
                                "health_score": min(
                                    100.0, 60.0 + (len(session_data) * 0.3)
                                ),
                                "context_size": sum(
                                    len(str(entry)) for entry in session_data
                                ),
                                "optimization_applied": any(
                                    "tool_result" in str(entry)
                                    for entry in session_data
                                ),
                                "context_type": "development",
                                "strategy_type": "INTERACTIVE",
                                "operations_approved": sum(
                                    1
                                    for entry in session_data
                                    if "tool_result" in str(entry)
                                ),
                                "operations_rejected": 0,
                                "size_reduction_percentage": min(
                                    50.0, len(session_data) * 0.1
                                ),
                                "entry_count": len(session_data),
                                "file_size_mb": jsonl_file.stat().st_size
                                / (1024 * 1024),
                                "focus_time_minutes": len(session_data)
                                * 1.5,  # Estimate focus time
                                "complexity_score": min(
                                    100, len(session_data) * 2
                                ),  # Complexity based on entries
                            }
                            dashboard_sessions.append(dashboard_session)

                except Exception as e:
                    logger.warning(f"Failed to parse {jsonl_file.name}: {e}")
                    continue

            # Sort by start time (most recent first)
            dashboard_sessions.sort(key=lambda x: x["start_time"], reverse=True)

            logger.info(
                f"Retrieved {len(dashboard_sessions)} sessions from JSONL files"
            )
            # Phase 2.3: Cache the results using unified cache management
            result = dashboard_sessions[:100]  # Limit to 100 most recent sessions
            if self.dashboard_cache:
                self.dashboard_cache.set_session_analytics_cache(result)
            return result

        except Exception as e:
            logger.error(f"Session analytics retrieval failed: {e}")
            # Cache empty result to avoid repeated failures
            result = []
            if self.dashboard_cache:
                self.dashboard_cache.set_session_analytics_cache(result)
            return result


class AdvancedAnalyticsCharts:
    """
    Advanced analytics chart generation with multiple chart types
    Extracted from generate_analytics_charts method in comprehensive dashboard
    Implements sophisticated time-based aggregations and trend analysis
    """

    def generate_analytics_charts(
        self, sessions: List[Dict[str, Any]], chart_type: str = "productivity_trend"
    ) -> Dict[str, Any]:
        """Generate advanced analytics charts using Plotly."""
        try:
            if not sessions:
                raise create_no_data_error("session")

            if chart_type == "productivity_trend":
                # Productivity trend over time
                dates = []
                productivity_scores = []

                for session in sorted(sessions, key=lambda x: x.get("start_time", "")):
                    date = datetime.fromisoformat(session.get("start_time", "")).date()
                    score = session.get("productivity_score", 0)

                    if score > 0:
                        dates.append(date.isoformat())
                        productivity_scores.append(score)

                # Create Plotly chart
                fig = go.Figure()

                fig.add_trace(
                    go.Scatter(
                        x=dates,
                        y=productivity_scores,
                        mode="lines+markers",
                        name="Productivity Score",
                        line=dict(color="#2E86C1", width=3),
                        marker=dict(size=6),
                    )
                )

                # Add trend line if enough data
                if len(productivity_scores) > 3:
                    # Simple moving average
                    window_size = min(5, len(productivity_scores) // 2)
                    moving_avg = []
                    for i in range(len(productivity_scores)):
                        start_idx = max(0, i - window_size // 2)
                        end_idx = min(
                            len(productivity_scores), i + window_size // 2 + 1
                        )
                        moving_avg.append(
                            sum(productivity_scores[start_idx:end_idx])
                            / (end_idx - start_idx)
                        )

                    fig.add_trace(
                        go.Scatter(
                            x=dates,
                            y=moving_avg,
                            mode="lines",
                            name="Trend",
                            line=dict(color="#E74C3C", width=2, dash="dash"),
                        )
                    )

                fig.update_layout(
                    title="Productivity Trend Over Time",
                    xaxis_title="Date",
                    yaxis_title="Productivity Score",
                    yaxis=dict(range=[0, 100]),
                    hovermode="x unified",
                    template="plotly_white",
                )

                return json.loads(json.dumps(fig, cls=PlotlyJSONEncoder))

            elif chart_type == "session_distribution":
                # Session duration distribution
                durations = [
                    s.get("duration_minutes", 0)
                    for s in sessions
                    if s.get("duration_minutes", 0) > 0
                ]

                # Categorize durations
                short = sum(1 for d in durations if d < 30)
                medium = sum(1 for d in durations if 30 <= d <= 120)
                long = sum(1 for d in durations if d > 120)

                fig = go.Figure(
                    data=go.Pie(
                        labels=[
                            "Short (<30min)",
                            "Medium (30-120min)",
                            "Long (>120min)",
                        ],
                        values=[short, medium, long],
                        marker_colors=["#3498DB", "#27AE60", "#E74C3C"],
                    )
                )

                fig.update_layout(
                    title="Session Duration Distribution",
                    template="plotly_white",
                )

                return json.loads(json.dumps(fig, cls=PlotlyJSONEncoder))

            elif chart_type == "daily_productivity_pattern":
                # Daily productivity pattern
                hourly_data = {}
                for session in sessions:
                    start_time = datetime.fromisoformat(session.get("start_time", ""))
                    hour = start_time.hour
                    productivity = session.get("productivity_score", 0)

                    if productivity > 0:
                        if hour not in hourly_data:
                            hourly_data[hour] = []
                        hourly_data[hour].append(productivity)

                # Calculate averages
                hours = sorted(hourly_data.keys())
                avg_productivity = [
                    sum(hourly_data[hour]) / len(hourly_data[hour]) for hour in hours
                ]

                fig = go.Figure()

                fig.add_trace(
                    go.Bar(
                        x=[f"{h:02d}:00" for h in hours],
                        y=avg_productivity,
                        name="Average Productivity by Hour",
                        marker_color="#3498DB",
                    )
                )

                fig.update_layout(
                    title="Daily Productivity Pattern",
                    xaxis_title="Hour of Day",
                    yaxis_title="Average Productivity Score",
                    template="plotly_white",
                )

                return json.loads(json.dumps(fig, cls=PlotlyJSONEncoder))

            else:
                raise create_unsupported_error("Chart type", chart_type)

        except Exception as e:
            logger.error(f"Analytics chart generation failed: {e}")
            raise create_error_response(str(e), "ANALYTICS_ERROR")


class SessionTimelineVisualizer:
    """
    Session timeline visualization with Gantt-style charts
    Extracted from generate_session_timeline method in comprehensive dashboard
    Implements color-coded productivity scoring and interactive timelines
    """

    def __init__(self, session_processor: SessionAnalyticsProcessor):
        self.session_processor = session_processor

    def generate_session_timeline(self, days: int = 7) -> Dict[str, Any]:
        """Generate session timeline visualization."""
        try:
            sessions = self.session_processor.get_recent_sessions_analytics(days)

            if not sessions:
                raise create_no_data_error("session")

            # Prepare timeline data
            timeline_data = []

            for session in sessions:
                start_time = datetime.fromisoformat(session.get("start_time", ""))
                duration = session.get("duration_minutes", 0)
                end_time = start_time + timedelta(minutes=duration)

                timeline_data.append(
                    {
                        "session_id": session.get("session_id", "unknown"),
                        "start": start_time.isoformat(),
                        "end": end_time.isoformat(),
                        "duration_minutes": duration,
                        "productivity_score": session.get("productivity_score", 0),
                        "context_size": session.get("context_size", 0),
                        "focus_time_minutes": session.get("focus_time_minutes", 0),
                    }
                )

            # Create Gantt-style chart
            fig = go.Figure()

            for i, session in enumerate(timeline_data):
                fig.add_trace(
                    go.Scatter(
                        x=[session["start"], session["end"]],
                        y=[i, i],
                        mode="lines",
                        line=dict(
                            width=10,
                            color=f'rgb({min(255, session["productivity_score"]*2.55)}, {255-min(255, session["productivity_score"]*2.55)}, 100)',
                        ),
                        name=f"Session {i+1}",
                        hovertemplate=f"<b>Session {i+1}</b><br>"
                        + f'Duration: {session["duration_minutes"]} min<br>'
                        + f'Productivity: {session["productivity_score"]}<br>'
                        + f'Context Size: {session["context_size"]} tokens<br>'
                        + "<extra></extra>",
                    )
                )

            fig.update_layout(
                title="Session Timeline",
                xaxis_title="Time",
                yaxis_title="Sessions",
                yaxis=dict(tickmode="linear", tick0=0, dtick=1),
                hovermode="closest",
                template="plotly_white",
                showlegend=False,
            )

            return json.loads(json.dumps(fig, cls=PlotlyJSONEncoder))

        except Exception as e:
            logger.error(f"Session timeline generation failed: {e}")
            raise create_error_response(str(e), "ANALYTICS_ERROR")


class DashboardAnalytics:
    """
    Unified analytics coordinator for all dashboard analytics functionality
    WebSocket-first: Integrates with dashboard_realtime for real-time updates
    Cache-optimized: Leverages dashboard_cache for performance
    """

    def __init__(self, dashboard_cache=None, realtime_manager=None):
        self.dashboard_cache = dashboard_cache
        self.realtime_manager = realtime_manager

        # Initialize analytics components
        self.chart_generator = AnalyticsChartGenerator()
        self.session_processor = SessionAnalyticsProcessor(dashboard_cache)
        self.advanced_charts = AdvancedAnalyticsCharts()
        self.timeline_visualizer = SessionTimelineVisualizer(self.session_processor)

    def generate_plotly_chart(self, chart_type: str) -> Dict[str, Any]:
        """Generate Plotly charts with performance history integration"""
        return self.chart_generator.generate_plotly_chart(chart_type)

    def get_recent_sessions_analytics(self, days: int = 30) -> List[Dict[str, Any]]:
        """Get recent session analytics with cache optimization"""
        return self.session_processor.get_recent_sessions_analytics(days)

    def generate_analytics_charts(
        self, sessions: List[Dict[str, Any]], chart_type: str = "productivity_trend"
    ) -> Dict[str, Any]:
        """Generate advanced analytics charts"""
        result = self.advanced_charts.generate_analytics_charts(sessions, chart_type)

        # WebSocket-first: Broadcast updates if real-time manager available
        if self.realtime_manager:
            self.realtime_manager.broadcast_widget_update("analytics_chart", {
                "chart_type": chart_type,
                "chart_data": result
            })

        return result

    def generate_session_timeline(self, days: int = 7) -> Dict[str, Any]:
        """Generate session timeline visualization"""
        result = self.timeline_visualizer.generate_session_timeline(days)

        # WebSocket-first: Broadcast timeline updates
        if self.realtime_manager:
            self.realtime_manager.broadcast_widget_update("session_timeline", {
                "days": days,
                "timeline_data": result
            })

        return result

    def update_performance_history(self, history: List[Dict[str, Any]]) -> None:
        """Update performance history for chart generation"""
        self.chart_generator.update_performance_history(history)

    def get_analytics_summary(self, days: int = 30) -> Dict[str, Any]:
        """Get comprehensive analytics summary"""
        try:
            sessions = self.get_recent_sessions_analytics(days)

            if not sessions:
                raise create_no_data_error("session")

            # Calculate summary statistics
            total_sessions = len(sessions)
            avg_duration = sum(s.get("duration_minutes", 0) for s in sessions) / total_sessions
            avg_productivity = sum(s.get("productivity_score", 0) for s in sessions) / total_sessions
            total_focus_time = sum(s.get("focus_time_minutes", 0) for s in sessions)

            summary = {
                "period_days": days,
                "total_sessions": total_sessions,
                "avg_duration_minutes": round(avg_duration, 2),
                "avg_productivity_score": round(avg_productivity, 2),
                "total_focus_time_hours": round(total_focus_time / 60, 2),
                "sessions_per_day": round(total_sessions / days, 2),
                "peak_productivity_score": max(s.get("productivity_score", 0) for s in sessions),
                "total_context_size": sum(s.get("context_size", 0) for s in sessions),
            }

            # WebSocket-first: Broadcast summary updates
            if self.realtime_manager:
                self.realtime_manager.broadcast_widget_update("analytics_summary", summary)

            return summary

        except Exception as e:
            logger.error(f"Analytics summary generation failed: {e}")
            raise create_error_response(str(e), "ANALYTICS_ERROR")


class AnalyticsCoordinator:
    """
    Coordinates analytics functionality across dashboard components
    WebSocket-first with intelligent cache coordination
    """

    def __init__(self, analytics_manager: DashboardAnalytics):
        self.analytics = analytics_manager

    def setup_analytics_infrastructure(self) -> None:
        """Setup complete analytics infrastructure"""
        logger.info("ðŸš€ Analytics infrastructure established")

    def get_analytics_endpoints_summary(self) -> Dict[str, Any]:
        """Get summary of analytics endpoints and capabilities"""
        return {
            "endpoints": [
                "/api/analytics/recent-sessions/<int:days>",
                "/api/analytics/chart/<chart_type>",
                "/api/analytics/timeline/<int:days>",
                "/api/session-timeline"
            ],
            "chart_types": [
                "health_trends",
                "productivity_overview",
                "productivity_trend",
                "session_distribution",
                "daily_productivity_pattern"
            ],
            "features": [
                "Real-time session analytics",
                "Plotly chart generation",
                "Cache-optimized processing",
                "WebSocket broadcasting",
                "Timeline visualization"
            ]
        }


class ModuleStatus:
    """Track module extraction status"""
    EXTRACTION_STATUS = "extracted"
    ORIGINAL_LINES = 450  # Analytics, chart generation, and session processing
    TARGET_LINES = 450
    REDUCTION_TARGET = "WebSocket-first analytics with sophisticated Plotly charts"


logger.info(f"dashboard_analytics module extracted - Status: {ModuleStatus.EXTRACTION_STATUS}")