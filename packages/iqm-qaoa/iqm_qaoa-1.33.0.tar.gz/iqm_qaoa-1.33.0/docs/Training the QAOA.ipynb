{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5ddf8812",
   "metadata": {},
   "source": [
    "# Training the QAOA\n",
    "\n",
    "In this notebook we showcase (and compare) various strategies of training the QAOA, that is finding the optimal values for the variational parameters (also known as QAOA *angles*)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc5d2c5b",
   "metadata": {},
   "source": [
    "We start by generating a quasi-random instance of the maxcut problem (with 10 nodes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e27fb71a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from iqm.applications.maxcut import maxcut_generator\n",
    "\n",
    "maxcut = next(maxcut_generator(n=10, n_instances=1, graph_family=\"erdos-renyi\", p=0.5, seed=420))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d306411",
   "metadata": {},
   "source": [
    "Generate a QAOA instance from the problem instance. We use the ``TreeQAOA`` class, which is identical to the ``QUBOQAOA`` class, but it contains one extra way to \"train\" the QAOA parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb21f452",
   "metadata": {},
   "outputs": [],
   "source": [
    "from iqm.qaoa.tree_qaoa import TreeQAOA\n",
    "\n",
    "# Using the standard notation for QAOA angles, the ``initial_angles`` are [gamma, beta] respectively.\n",
    "qaoa = TreeQAOA(problem=maxcut, num_layers=1, initial_angles=[0.1, 0.1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "353db254",
   "metadata": {},
   "source": [
    "For training the QAOA, we will use various *estimators*. An estimator is a function (technically a class with a method) which takes a QAOA object and calculates/estimates the expectation value of the Hamiltonian. Similarly, a *sampler* takes a QAOA object and generates samples (measurement results) of possible solutions.\n",
    "\n",
    "Here we also set up a variable ``results`` to store the results of our experiments, for comparison. It's a dictionary of dictionaries, keyed first by the training method and then by the QAOA number of layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e43e7014",
   "metadata": {},
   "outputs": [],
   "source": [
    "from iqm.qaoa.backends import (\n",
    "    EstimatorFromSampler,\n",
    "    EstimatorSingleLayer,\n",
    "    EstimatorStateVector,\n",
    "    SamplerResonance,\n",
    "    SamplerSimulation,\n",
    ")\n",
    "\n",
    "results: dict[str, dict[int, float]] = (\n",
    "    {}\n",
    ")  # A dictionary for storing the results (to make comparison easier at the end).\n",
    "results[\"sl\"] = {}  # Single-layer estimator.\n",
    "results[\"sv\"] = {}  # Statevector estimator.\n",
    "results[\"sim\"] = {}  # Estimator from sampler, samples obtained by simulation.\n",
    "results[\"sim_cvar\"] = {}  # Estimator from sampler, samples obtained by simulation, using CVaR instead of mean.\n",
    "results[\"res\"] = {}  # Estimator from sampler, samples obtained from Resonance.\n",
    "results[\"tree\"] = {}  # Angles set by the tree schedule (no real training)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9fa9a1d",
   "metadata": {},
   "source": [
    "We start with ``EstimatorSingleLayer``. For single-layer QAOA, the expectation values of 1- and 2-qubit operators can be calculated analytically. This estimator does the calculation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc58d2fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator_single_layer = EstimatorSingleLayer()\n",
    "\n",
    "qaoa.train(estimator=estimator_single_layer)  # Here the QAOA is trained.\n",
    "results[\"sl\"][1] = estimator_single_layer.estimate(qaoa)\n",
    "print(\"Expected value of the Hamiltonian after training with ``EstimatorSingleLayer``:\", results[\"sl\"][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7ddeada",
   "metadata": {},
   "source": [
    "Next, we train using ``EstimatorStateVector``. This estimator runs the statevector simulation of the QAOA circuit to calculate the expectation value of the Hamiltonian."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3371e025",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator_statevector = EstimatorStateVector()\n",
    "\n",
    "qaoa.angles = [0.1, 0.1]  # Reset the QAOA angles (to make comparison of training methods fair).\n",
    "qaoa.train(estimator=estimator_statevector)  # Here the QAOA is trained.\n",
    "results[\"sv\"][1] = estimator_statevector.estimate(qaoa)\n",
    "print(\"Expected value of the Hamiltonian after training with ``EstimatorStateVector``:\", results[\"sv\"][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81a3734b",
   "metadata": {},
   "source": [
    "Next, we train using ``EstimatorFromSampler`` together with ``SamplerSimulation``. This estimator calls a given sampler and uses the obtained samples to estimate the expectation value (by calculating the energy of each of the samples and averaging them out). The ``SamplerSimulation`` runs the simulation of the QAOA circuit, including the measurements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2cc827f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler_from_simulation = SamplerSimulation()  # By default, it initializes with AerSimulator(method=\"statevector\")\n",
    "estimator_from_simulation = EstimatorFromSampler(sampler=sampler_from_simulation, shots=20000)\n",
    "\n",
    "qaoa.angles = [0.1, 0.1]  # Reset the QAOA angles (to make comparison of training methods fair).\n",
    "qaoa.train(estimator=estimator_from_simulation)  # Here the QAOA is trained.\n",
    "results[\"sim\"][1] = estimator_from_simulation.estimate(qaoa)\n",
    "print(\"Expected value using ``EstimatorFromSampler`` with ``SamplerSimulation``:\", results[\"sim\"][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec12b7a5",
   "metadata": {},
   "source": [
    "Next, we again use ``EstimatorFromSampler`` together with ``SamplerSimulation``. But this time we calculate not the *expectation value*, but the *conditional value at risk* at ``0.1`` level. We use this value in training the QAOA, possibly changing the performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c9d33e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator_from_simulation_cvar = EstimatorFromSampler(sampler=sampler_from_simulation, shots=20000, cvar=0.1)\n",
    "\n",
    "qaoa.angles = [0.1, 0.1]  # Reset the QAOA angles (to make comparison of training methods fair).\n",
    "qaoa.train(estimator=estimator_from_simulation_cvar)  # Here the QAOA is trained.\n",
    "results[\"sim_cvar\"][1] = estimator_from_simulation_cvar.estimate(qaoa)\n",
    "print(\n",
    "    \"Conditional value at risk at 0.1 level using ``EstimatorFromSampler`` with ``SamplerSimulation``:\",\n",
    "    results[\"sim_cvar\"][1],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e4843e6",
   "metadata": {},
   "source": [
    "Next, we train using ``EstimatorFromSampler`` again, but this time together with ``SamplerResonance``. This sampler actually runs the circuit via Resonance, IQM's cloud quantum computing platform.\n",
    "\n",
    "**WARNING**\n",
    "\n",
    "When running training using this estimator, Resonance is used for every training cycle, potentially taking a lot of time (even when using a mock QC)!\n",
    "\n",
    "The ``if`` clause surrounding the cell makes sure that it's skipped during testing (because it's too slow)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "861149d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os  # Needed to get the Resonance token from the environmental variable.\n",
    "\n",
    "if \"END_TO_END_TESTING\" not in os.environ:\n",
    "    sampler_from_resonance = SamplerResonance(\n",
    "        token=os.environ.get(\"IQM_RESONANCE_API_TOKEN\"),\n",
    "        # Remove the ':mock' part to run on real QC.\n",
    "        server_url=os.environ.get(\"IQM_RESONANCE_URL_CRYSTAL\", \"https://cocos.resonance.meetiqm.com/garnet:mock\"),\n",
    "        transpiler=\"SparseTranspiler\",\n",
    "    )\n",
    "    estimator_from_resonance = EstimatorFromSampler(sampler=sampler_from_resonance, shots=20000)\n",
    "\n",
    "    qaoa.angles = [0.1, 0.1]  # Reset the QAOA angles (to make comparison of training methods fair).\n",
    "    qaoa.train(estimator=estimator_from_resonance)  # Here the QAOA is trained.\n",
    "    results[\"res\"][1] = estimator_from_resonance.estimate(qaoa)\n",
    "    print(\"Expected value using ``EstimatorFromSampler`` with ``SamplerResonance``:\", results[\"res\"][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6269987",
   "metadata": {},
   "source": [
    "Now we \"train\" the angles by setting them to the *Tree QAOA* angles. The Tree QAOA angles are the optimal angles for problems on regular infinite random graphs, where the neighborhood of each node is a tree graph. These angles are pre-calculated for various values of graph regularity and parameters of the Hamiltonian. The method ``set_tree_angles`` looks at the parameters of our problem and sets the QAOA angles to the corresponding Tree QAOA angles.\n",
    "\n",
    "While these angles aren't likely the most optimal angles for our problem, they are likely to produce good results and it allows us to skip conventional QAOA training completely.\n",
    "\n",
    "[More reading on Tree QAOA](https://arxiv.org/abs/2406.14618)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "084248f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "qaoa.angles = [0.1, 0.1]  # Reset the QAOA angles (to make comparison of training methods fair).\n",
    "qaoa.set_tree_angles()  # The method gets all the necessary info from the ``qaoa`` object.\n",
    "results[\"tree\"][1] = estimator_single_layer.estimate(qaoa)\n",
    "print(\n",
    "    \"Expected value using ``EstimatorSingleLayer`` after setting the angles with ``set_tree_angles``:\",\n",
    "    results[\"tree\"][1],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d70a8ce6",
   "metadata": {},
   "source": [
    "For comparison we now repeat all of the above (except for ``EstimatorSingleLayer``) for QAOA with 2 layers and summarize the data in a table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab5629e",
   "metadata": {},
   "outputs": [],
   "source": [
    "qaoa.num_layers = 2  # The extra QAOA parameters will be padded with zeros.\n",
    "\n",
    "# After increasing the number of layers, the QAOA angles are [gamma1, beta1, bamma2, beta2].\n",
    "# The same pattern holds for more layers. They can also be set separately using ``qaoa.betas = [beta1, beta2]``\n",
    "\n",
    "qaoa.angles = [0.1, 0.1, 0.1, 0.1]  # Reset the QAOA angles (to make comparison of training methods fair).\n",
    "qaoa.train(estimator=estimator_statevector)  # Here the QAOA is trained.\n",
    "results[\"sv\"][2] = estimator_statevector.estimate(qaoa)\n",
    "\n",
    "qaoa.angles = [0.1, 0.1, 0.1, 0.1]  # Reset the QAOA angles (to make comparison of training methods fair).\n",
    "qaoa.train(estimator=estimator_from_simulation)  # Here the QAOA is trained.\n",
    "results[\"sim\"][2] = estimator_from_simulation.estimate(qaoa)\n",
    "\n",
    "qaoa.angles = [0.1, 0.1, 0.1, 0.1]  # Reset the QAOA angles (to make comparison of training methods fair).\n",
    "qaoa.train(estimator=estimator_from_simulation_cvar)  # Here the QAOA is trained.\n",
    "results[\"sim_cvar\"][2] = estimator_from_simulation_cvar.estimate(qaoa)\n",
    "\n",
    "if \"END_TO_END_TESTING\" not in os.environ:  # Again, skip this if we're testing.\n",
    "    qaoa.angles = [0.1, 0.1, 0.1, 0.1]  # Reset the QAOA angles (to make comparison of training methods fair).\n",
    "    qaoa.train(estimator=estimator_from_resonance)  # Here the QAOA is trained.\n",
    "    results[\"res\"][2] = estimator_from_resonance.estimate(qaoa)\n",
    "\n",
    "qaoa.angles = [0.1, 0.1, 0.1, 0.1]  # Reset the QAOA angles (to make comparison of training methods fair).\n",
    "qaoa.set_tree_angles()\n",
    "results[\"tree\"][2] = estimator_statevector.estimate(\n",
    "    qaoa\n",
    ")  # The statevector estimator is the most accurate one, so it's used here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "971b249f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML, display\n",
    "\n",
    "# Row labels and column labels\n",
    "methods = sorted(results.keys())\n",
    "# For each method, there is an inner dict of the format p:exp_val\n",
    "ps = sorted({p for inner_dict in results.values() for p in inner_dict})\n",
    "\n",
    "# Build the table\n",
    "html = \"<table border='1' style='border-collapse: collapse;'>\"\n",
    "html += \"<tr><th>Training Method</th>\" + \"\".join(f\"<th>p = {p}</th>\" for p in ps) + \"</tr>\"\n",
    "\n",
    "method_names = {\n",
    "    \"sv\": \"Statevector\",\n",
    "    \"sl\": \"Single Layer\",\n",
    "    \"sim\": \"Simulated Samples\",\n",
    "    \"sim_cvar\": \"Simulated Samples, CVaR\",\n",
    "    \"res\": \"Resonance Samples\",\n",
    "    \"tree\": \"Tree Schedule\",\n",
    "}  # Just longer names for the methods, for a nicer table.\n",
    "\n",
    "for method in methods:\n",
    "    html += f\"<tr><th>{method_names[method]}</th>\"\n",
    "    for p in ps:\n",
    "        exp_val = results[method].get(p)\n",
    "        exp_val_str = f\"{exp_val:.4f}\" if exp_val is not None else \"N/A\"\n",
    "        html += f\"<td>{exp_val_str}</td>\"\n",
    "    html += \"</tr>\"\n",
    "\n",
    "html += \"</table>\"\n",
    "\n",
    "display(HTML(html))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3edce91a",
   "metadata": {},
   "source": [
    "We expect the `Statevector`, `Simulated Samples` and the `Single Layer` methods to perform the best (although none of them is scalable).\n",
    "\n",
    "Using `CVaR` instead of the mean gives better results, but this is expected, given that we're looking at a tail of a distribution. Whether it actually helps in training the QAOA is not clear.\n",
    "\n",
    "We expect all methods to improve with increasing ``p``."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
