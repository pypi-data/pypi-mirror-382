######################################################
#########   EMBEDDING GENERATION SETTINGS ############
######################################################

# specify your device, if unsure use 'cpu', if you are working on a 
# gpu computer use 'cuda'
device: 'cpu'

# fixed path, model checkpoints are/should be stored here
# this is also where bacpipe will look for existing checkpoints
model_base_path: bacpipe/model_checkpoints

# If you have an annotations.csv file in the format specified in the 
# ReadMe file, you can choose to only create embeddings for the segments
# corresponding to the annotations. For model's that require input segments
# longer than an annotation, the audio will be padded according to the 
# padding specified below (see `padding`).
only_embed_annotations: False

# batch size for embedding generation, modify if you have memory issues
# or if you want to speed up the process and have enough memory available
global_batch_size: 16


# supported formats of audio files
audio_suffixes: ['.wav', '.WAV', '.aif', '.mp3', '.MP3', '.flac', '.ogg']


# To avoid creating embeddings when configurations are still being tested, this is set to True. 
# Set to False if you want to keep embeddings even if the process is interrupted.
rm_embedding_on_keyboard_interrupt: True

# Specify the padding strategy for the models. This will be used
# both if only annotated segments are embedded or if audio get's 
# imported and windowed and the last frame might end up not being 
# long enough to fit a full context window, as a result the frame 
# get's padded. Specify how it should get padded.
# Choose values from the np.pad function documentation
# (https://numpy.org/devdocs/reference/generated/numpy.pad.html).
padding: 'minimum'

# To increase performance when running inference on a GPU, bacpipe will use threads
# to load audio data in one thread and compute embeddings in another. That way audio 
# loading can happen while embeddings are being calculated. This is especially 
# effective for datasets with a lot of small files and can separate the cpu and gpu 
# tasks nicely. If you happen to have problems with this, you can set the following
# to true and thereby it will always revert to a sequential operation, also on gpu's.
avoid_pipelined_gpu_inference: False

######################################################
###############   EVALUATION SETTINGS ################
######################################################

# For evaluation using classification it is necessary to have a minimum number 
# of embeddings for each label. The remaining embeddings will be marked as noise.
# Change this value at will, but be aware that classification might fail if it's too low. 
# Default = 150.
min_label_occurrences: 50

# If you want to visualize the embeddings by ground truth with no minimum
# number of occurances, set this to False.
bool_filter_labels: True

# kinds of default labels that are created for the embeddings
default_label_keys: [
  "time_of_day",
  "day_of_year",
  "continuous_timestamp",
  "parent_directory",
  "audio_file_name"
  ]

# key corresponding to the label in the annotation.csv file, if labeled data exists
# by default this is species, but change if needed
label_column: 'species'

## CLASSIFICATION SETTINGS ##

# if the model has a classifier that ships with the model, by default 
# it will be used, to provide another option to colorcode embeddings
# and visualize differences between embeddings. 
run_pretrained_classifier: True
classifier_threshold: 0.5


class_configs:
  config_1:
    bool: True
    name: "linear"
    learning_rate: 0.001
    batch_size: 64
    num_epochs: 10
    dataset_csv_path: classification_dataframe.csv
    shuffle: False
  config_2:
    bool: True
    name: "knn"
    n_neighbors: 15
    dataset_csv_path: classification_dataframe.csv


## CLUSTERING SETTINGS ##

# specify if you want to use the silhouette score to evaluate 
# the clustering results. Can be very slow for large datasets
# and is not recommended for datasets with a large number of clusters.
evaluate_with_silhouette: False

clust_configs: 
  config_1: 
    bool: True
    name: "kmeans"
    # number of clusters is set to a default value of 18
    # this is the default value can be adjusted as needed
    params:
      n_clusters: 18
  config_2:
    bool: False
    name: "hdbscan"
    params:
      min_cluster_size: 10
      min_samples: 5
      metric: "euclidean"
    

## DISTANCE EVALUATION ## 

distance_configs:
  config_1: 
    bool: False
    name: "euclidean"
    method: "intra_vs_inter"



######################################################
##################   PATH SETTINGS ###################
######################################################

# fixed path, embeddings will be stored here, advised not to change
# because this is also where bacpipe will look for existing embeddings
### IMPORTANT! WINODWS USERS DON'T USE QUOTATIONS HERE
main_results_dir :      bacpipe_results
embed_parent_dir :      embeddings
dim_reduc_parent_dir :  dim_reduced_embeddings
evaluations_dir :       evaluations

# If set to true bacpipe will always use the same test files and save it in a 
# directory other than the results directory. Results will also be deleted at 
# of the computation.
testing: False