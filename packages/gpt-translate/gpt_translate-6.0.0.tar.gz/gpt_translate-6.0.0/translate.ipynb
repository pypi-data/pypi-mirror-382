{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# autoreload\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load our quickstart and translate to spanish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_folder = Path(\"configs\")\n",
    "md_file = Path(\"docs/quickstart.md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gpt_translate.translate import Translator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model args: {'model': 'gpt-3.5-turbo', 'temperature': 0.7}\n"
     ]
    }
   ],
   "source": [
    "t = Translator(config_folder, language=\"es\", max_chunk_tokens=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# es_quickstart = t.translate_file(md_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Api Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gpt_translate.translate import translate_splitted_md\n",
    "from gpt_translate.loader import split_markdown, remove_markdown_comments, MDPage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(md_file, \"r\") as f:\n",
    "    md_content = f.read()\n",
    "\n",
    "model_args = dict(\n",
    "    model=\"gpt-4\",\n",
    "    temperature= 0.7,\n",
    "    )\n",
    "\n",
    "prompt_template = t.prompt_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "md_content = remove_markdown_comments(md_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "md_page = MDPage.create(\"quickstart\", md_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "---\n",
       "description: W&B Quickstart.\n",
       "displayed_sidebar: default\n",
       "---\n",
       "import Tabs from '@theme/Tabs';\n",
       "import TabItem from '@theme/TabItem';"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "md_page.header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks = split_markdown(md_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"---\\ndescription: W&B Quickstart.\\ndisplayed_sidebar: default\\n---\\n\\nimport Tabs from '@theme/Tabs';\\nimport TabItem from '@theme/TabItem';\",\n",
       " '# Quickstart\\n\\nInstall W&B and start tracking your machine learning experiments in minutes.',\n",
       " '## 1. Create an account and install W&B\\nBefore you get started, make sure you create an account and install W&B:\\n\\n1. [Sign up](https://wandb.ai/site) for a free account at [https://wandb.ai/site](https://wandb.ai/site) and then login to your wandb account.  \\n2. Install the wandb library on your machine in a Python 3 environment using [`pip`](https://pypi.org/project/wandb/).  \\n\\n\\nThe following code snippets demonstrate how to install and log into W&B using the W&B CLI and Python Library:\\n\\n<Tabs\\n  defaultValue=\"notebook\"\\n  values={[\\n    {label: \\'Notebook\\', value: \\'notebook\\'},\\n    {label: \\'Command Line\\', value: \\'cli\\'},\\n  ]}>\\n  <TabItem value=\"cli\">\\n\\nInstall the CLI and Python library for interacting with the Weights and Biases API:\\n\\n```\\npip install wandb\\n```\\n\\n  </TabItem>\\n  <TabItem value=\"notebook\">\\n\\nInstall the CLI and Python library for interacting with the Weights and Biases API:\\n\\n```python\\n!pip install wandb\\n```\\n\\n\\n  </TabItem>\\n</Tabs>',\n",
       " '## 2. Log in to W&B\\n\\n\\n<Tabs\\n  defaultValue=\"notebook\"\\n  values={[\\n    {label: \\'Notebook\\', value: \\'notebook\\'},\\n    {label: \\'Command Line\\', value: \\'cli\\'},\\n  ]}>\\n  <TabItem value=\"cli\">\\n\\nNext, log in to W&B:\\n\\n```\\nwandb login\\n```\\n\\nOr if you are using [W&B Server:](./guides/hosting)\\n\\n```\\nwandb login --host=http://wandb.your-shared-local-host.com\\n```\\n\\nProvide [your API key](https://wandb.ai/authorize) when prompted.\\n\\n  </TabItem>\\n  <TabItem value=\"notebook\">\\n\\nNext, import the W&B Python SDK and log in:\\n\\n```python\\nwandb.login()\\n```\\n\\nProvide [your API key](https://wandb.ai/authorize) when prompted.\\n  </TabItem>\\n</Tabs>',\n",
       " '## 3. Start a  run and track hyperparameters\\n\\nInitialize a W&B Run object in your Python script or notebook with [`wandb.init()`](./ref/python/run.md) and pass a dictionary to the `config` parameter with key-value pairs of hyperparameter names and values:\\n\\n```python\\nrun = wandb.init(\\n    # Set the project where this run will be logged\\n    project=\"my-awesome-project\",\\n    # Track hyperparameters and run metadata\\n    config={\\n        \"learning_rate\": 0.01,\\n        \"epochs\": 10,\\n    })\\n```\\n\\n\\n\\n\\nA [run](./guides/runs) is the basic building block of W&B. You will use them often to [track metrics](./guides/track), [create logs](./guides/artifacts), [create jobs](./guides/launch), and more.',\n",
       " '## Putting it all together\\n\\nPutting it all together, your training script might look similar to the following code example. The highlighted code shows W&B-specific code. \\nNote that we added code that mimics machine learning training.\\n\\n```python\\n# train.py\\nimport wandb\\nimport random # for demo script\\n\\n# highlight-next-line\\nwandb.login()\\n\\nepochs=10\\nlr=0.01\\n\\n# highlight-start\\nrun = wandb.init(\\n    # Set the project where this run will be logged\\n    project=\"my-awesome-project\",\\n    # Track hyperparameters and run metadata\\n    config={\\n        \"learning_rate\": lr,\\n        \"epochs\": epochs,\\n    })\\n# highlight-end    \\n\\noffset = random.random() / 5\\nprint(f\"lr: {lr}\")\\n\\n# simulating a training run\\nfor epoch in range(2, epochs):\\n    acc = 1 - 2 ** -epoch - random.random() / epoch - offset\\n    loss = 2 ** -epoch + random.random() / epoch + offset\\n    print(f\"epoch={epoch}, accuracy={acc}, loss={loss}\")\\n    # highlight-next-line\\n    wandb.log({\"accuracy\": acc, \"loss\": loss})\\n\\n# run.log_code()\\n```\\n\\nThat\\'s it! Navigate to the W&B App at [https://wandb.ai/home](https://wandb.ai/home) to view how the metrics we logged with W&B (accuracy and loss) improved during each training step.\\n\\n![Shows the loss and accuracy that was tracked from each time we ran the script above. ](/images/quickstart/quickstart_image.png)\\n\\nThe image above (click to expand) shows the loss and accuracy that was tracked from each time we ran the script above.  Each run object that was created is show within the **Runs** column. Each run name is randomly generated.',\n",
       " \"## What's next?\\n\\n\\nExplore the rest of the W&B ecosystem.\\n\\n1. Check out [W&B Integrations](guides/integrations) to learn how to integrate W&B with your ML framework such as PyTorch, ML library such as Hugging Face, or ML service such as SageMaker. \\n2. Organize runs, embed and automate visualizations, describe your findings, and share updates with collaborators with [W&B Reports](./guides/reports).\\n2. Create [W&B Artifacts](./guides/artifacts) to track datasets, models, dependencies, and results through each step of your machine learning pipeline.\\n3. Automate hyperparameter search and explore the space of possible models with [W&B Sweeps](./guides/sweeps).\\n4. Understand your datasets, visualize model predictions, and share insights in a [central dashboard](./guides/data-vis).\\n\\n\\n![](/images/quickstart/wandb_demo_experiments.gif)\",\n",
       " \"## Common Questions\\n\\n**Where do I find my API key?**\\nOnce you've signed in to www.wandb.ai, the API key will be on the [Authorize page](https://wandb.ai/authorize).\\n\\n**How do I use W&B in an automated environment?**\\nIf you are training models in an automated environment where it's inconvenient to run shell commands, such as Google's CloudML, you should look at our guide to configuration with [Environment Variables](guides/track/environment-variables).\\n\\n**Do you offer local, on-prem installs?**\\nYes, you can [privately host W&B](guides/hosting/) locally on your own machines or in a private cloud, try [this quick tutorial notebook](http://wandb.me/intro) to see how. Note, to login to wandb local server you can [set the host flag](guides/hosting/how-to-guides/basic-setup) to the address of the local instance.  \\n\\n**How do I turn off wandb logging temporarily?**\\nIf are testing code and want to disable wandb syncing, set the environment variable [`WANDB_MODE=offline`](./guides/track/environment-variables).\"]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "description: W&B Quickstart.\n",
      "displayed_sidebar: default\n",
      "---\n",
      "\n",
      "import Tabs from '@theme/Tabs';\n",
      "import TabItem from '@theme/TabItem';\n"
     ]
    }
   ],
   "source": [
    "print(chunks[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Calling OpenAI with {'model': 'gpt-4', 'temperature': 0.7}\n",
      "Translating chunk: \n",
      "\n",
      "---\n",
      "description: W&B Quickstart.\n",
      "displayed_sidebar: default\n",
      "---\n",
      "\n",
      "import Tabs from '@theme/Tabs';\n",
      "i...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Packing chunk 0 with 33 tokens\n",
      "Packing chunk 1 with 17 tokens\n",
      "Packing chunk 2 with 251 tokens\n",
      "Packing chunk 3 with 190 tokens\n",
      "Packing chunk 4 with 178 tokens\n",
      "Packing chunk 5 with 380 tokens\n",
      "Packing chunk 6 with 199 tokens\n",
      "Packing chunk 7 with 244 tokens\n",
      ">> Translating 1492 tokens (last chunk)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:OpenAI response: ---\n",
      "description: Inicio rápido de W&B.\n",
      "displayed_sidebar: default\n",
      "---\n",
      "\n",
      "import Tabs from '@theme/Tabs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function translate_splitted_md took 198.1675 seconds to execute.\n"
     ]
    }
   ],
   "source": [
    "translated_file = translate_splitted_md(chunks,\n",
    "                                        prompt_template,\n",
    "                                        max_chunk_tokens=2000, \n",
    "                                        **model_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "translated_md_page = MDPage.create(\"quickstart_es\", translated_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
