Metadata-Version: 2.4
Name: ai-news-collector-lib
Version: 0.1.0
Summary: A Python library for collecting AI-related news from multiple sources
Home-page: https://github.com/ai-news-collector/ai-news-collector-lib
Author: AI News Collector Team
Author-email: AI News Collector Team <support@ai-news-collector.com>
Maintainer-email: AI News Collector Team <support@ai-news-collector.com>
License: MIT
Project-URL: Homepage, https://github.com/ai-news-collector/ai-news-collector-lib
Project-URL: Documentation, https://ai-news-collector-lib.readthedocs.io/
Project-URL: Repository, https://github.com/ai-news-collector/ai-news-collector-lib.git
Project-URL: Bug Tracker, https://github.com/ai-news-collector/ai-news-collector-lib/issues
Keywords: ai,news,collector,search,web scraping,machine learning,artificial intelligence
Classifier: Development Status :: 4 - Beta
Classifier: Intended Audience :: Developers
Classifier: License :: OSI Approved :: MIT License
Classifier: Operating System :: OS Independent
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.8
Classifier: Programming Language :: Python :: 3.9
Classifier: Programming Language :: Python :: 3.10
Classifier: Programming Language :: Python :: 3.11
Classifier: Topic :: Software Development :: Libraries :: Python Modules
Classifier: Topic :: Internet :: WWW/HTTP :: Indexing/Search
Classifier: Topic :: Scientific/Engineering :: Artificial Intelligence
Requires-Python: >=3.8
Description-Content-Type: text/markdown
License-File: LICENSE
Requires-Dist: requests>=2.28.0
Requires-Dist: beautifulsoup4>=4.11.0
Requires-Dist: feedparser>=6.0.0
Requires-Dist: python-dotenv>=0.19.0
Provides-Extra: advanced
Requires-Dist: aiohttp>=3.8.0; extra == "advanced"
Requires-Dist: redis>=4.0.0; extra == "advanced"
Requires-Dist: schedule>=1.2.0; extra == "advanced"
Requires-Dist: apscheduler>=3.9.0; extra == "advanced"
Provides-Extra: nlp
Requires-Dist: nltk>=3.8; extra == "nlp"
Requires-Dist: spacy>=3.4.0; extra == "nlp"
Requires-Dist: textblob>=0.17.0; extra == "nlp"
Provides-Extra: web
Requires-Dist: fastapi>=0.80.0; extra == "web"
Requires-Dist: uvicorn>=0.18.0; extra == "web"
Requires-Dist: streamlit>=1.20.0; extra == "web"
Provides-Extra: dev
Requires-Dist: pytest>=7.0.0; extra == "dev"
Requires-Dist: pytest-asyncio>=0.20.0; extra == "dev"
Requires-Dist: black>=22.0.0; extra == "dev"
Requires-Dist: flake8>=5.0.0; extra == "dev"
Requires-Dist: mypy>=0.950; extra == "dev"
Dynamic: author
Dynamic: home-page
Dynamic: license-file
Dynamic: requires-python

# AI News Collector Library

一个用于收集AI相关新闻的Python库，支持多种搜索源和高级功能。

## 🚀 特性

- **多源搜索**: 支持HackerNews、ArXiv、DuckDuckGo、NewsAPI等
- **内容提取**: 自动提取网页内容
- **关键词分析**: 智能提取关键词
- **结果缓存**: 支持结果缓存，提高效率
- **定时任务**: 支持定时自动收集
- **报告生成**: 生成多种格式的报告
- **易于集成**: 简单的API接口

## 📦 安装

### 基础安装

```bash
pip install ai-news-collector-lib
```

### 高级功能安装

```bash
pip install ai-news-collector-lib[advanced]
```

### 开发安装

```bash
git clone https://github.com/ai-news-collector/ai-news-collector-lib.git
cd ai-news-collector-lib
pip install -e .
```

## 🔧 快速开始

### 基础使用

```python
import asyncio
from ai_news_collector_lib import AINewsCollector, SearchConfig

# 创建配置
config = SearchConfig(
    enable_hackernews=True,
    enable_arxiv=True,
    enable_duckduckgo=True,
    max_articles_per_source=10
)

# 创建搜集器
collector = AINewsCollector(config)

# 收集新闻
async def main():
    result = await collector.collect_news("artificial intelligence")
    print(f"收集到 {result.total_articles} 篇文章")
    return result.articles

# 运行
articles = asyncio.run(main())
```

### 高级使用

```python
from ai_news_collector_lib import AdvancedAINewsCollector, AdvancedSearchConfig

# 创建高级配置
config = AdvancedSearchConfig(
    enable_hackernews=True,
    enable_arxiv=True,
    enable_duckduckgo=True,
    enable_content_extraction=True,
    enable_keyword_extraction=True,
    cache_results=True
)

# 创建高级搜集器
collector = AdvancedAINewsCollector(config)

# 收集增强新闻
async def main():
    result = await collector.collect_news_advanced("machine learning")
    
    # 分析结果
    total_words = sum(article['word_count'] for article in result['articles'])
    print(f"总字数: {total_words}")
    
    return result

# 运行
enhanced_result = asyncio.run(main())
```

## 📊 支持的搜索源

### 免费源

- 🔥 **HackerNews** - 技术社区讨论
- 📚 **ArXiv** - 学术论文和预印本
- 🦆 **DuckDuckGo** - 隐私保护的网页搜索

### 付费源 (需要API密钥)

- 📡 **NewsAPI** - 多源新闻聚合
- 🔍 **Tavily** - AI驱动的搜索API
- 🌐 **Google Search** - Google自定义搜索API
- 🔵 **Bing Search** - 微软Bing搜索API
- ⚡ **Serper** - 快速Google搜索API
- 🦁 **Brave Search** - 独立隐私搜索API
- 🔬 **MetaSota Search** - 基于MCP协议的智能搜索服务

## ⚙️ 配置

### 环境变量

```bash
# API密钥
NEWS_API_KEY=your_newsapi_key
TAVILY_API_KEY=your_tavily_key
GOOGLE_SEARCH_API_KEY=your_google_key
GOOGLE_SEARCH_ENGINE_ID=your_engine_id
BING_SEARCH_API_KEY=your_bing_key
SERPER_API_KEY=your_serper_key
BRAVE_SEARCH_API_KEY=your_brave_key
METASOSEARCH_API_KEY=your_metasota_key
```

### 配置文件

```python
from ai_news_collector_lib import SearchConfig

config = SearchConfig(
    # 传统源
    enable_hackernews=True,
    enable_arxiv=True,
    enable_newsapi=False,
    enable_rss_feeds=True,
    
    # 搜索引擎源
    enable_duckduckgo=True,
    enable_tavily=False,
    enable_google_search=False,
    enable_bing_search=False,
    enable_serper=False,
    enable_brave_search=False,
    enable_metasota_search=False,
    
    # 搜索参数
    max_articles_per_source=10,
    days_back=7,
    similarity_threshold=0.85
)
```

## 🛠️ 高级功能

### 定时任务

```python
from ai_news_collector_lib import DailyScheduler

# 创建调度器
scheduler = DailyScheduler(
    collector_func=collect_news,
    schedule_time="09:00",
    timezone="Asia/Shanghai"
)

# 启动调度器
scheduler.start()
```

### 缓存管理

```python
from ai_news_collector_lib import CacheManager

# 创建缓存管理器
cache = CacheManager(cache_dir="./cache", default_ttl_hours=24)

# 检查缓存
cache_key = cache.get_cache_key("ai news", ["hackernews", "arxiv"])
cached_result = cache.get_cached_result(cache_key)

if cached_result:
    print("使用缓存结果")
else:
    # 执行搜索并缓存结果
    result = await collector.collect_news("ai news")
    cache.cache_result(cache_key, result)
```

### 报告生成

```python
from ai_news_collector_lib import ReportGenerator

# 创建报告生成器
reporter = ReportGenerator(output_dir="./reports")

# 生成报告
report = reporter.generate_daily_report(result, format="markdown")
reporter.save_report(result, filename="daily_report.md")
```

## 📈 使用示例

### 每日收集脚本

```python
#!/usr/bin/env python3
import asyncio
from ai_news_collector_lib import AdvancedAINewsCollector, AdvancedSearchConfig

async def daily_collection():
    # 配置
    config = AdvancedSearchConfig(
        enable_hackernews=True,
        enable_arxiv=True,
        enable_duckduckgo=True,
        enable_content_extraction=True,
        cache_results=True
    )
    
    # 创建搜集器
    collector = AdvancedAINewsCollector(config)
    
    # 收集多个主题
    topics = ["artificial intelligence", "machine learning", "deep learning"]
    result = await collector.collect_multiple_topics(topics)
    
    print(f"收集完成: {result['unique_articles']} 篇独特文章")
    return result

if __name__ == "__main__":
    asyncio.run(daily_collection())
```

### Web API集成

```python
from fastapi import FastAPI
from ai_news_collector_lib import AINewsCollector, SearchConfig

app = FastAPI()
collector = AINewsCollector(SearchConfig())

@app.get("/ai-news")
async def get_ai_news(query: str = "artificial intelligence"):
    result = await collector.collect_news(query)
    return {
        "total": result.total_articles,
        "unique": result.unique_articles,
        "articles": [article.to_dict() for article in result.articles]
    }
```

## 🧪 测试

```bash
# 运行测试
pytest

# 运行异步测试
pytest -v

# 运行特定测试
pytest tests/test_collector.py
```

## 📚 文档

- [完整文档](https://ai-news-collector-lib.readthedocs.io/)
- [API参考](https://ai-news-collector-lib.readthedocs.io/api/)
- [示例代码](https://github.com/ai-news-collector/ai-news-collector-lib/tree/main/examples)

## 🤝 贡献

欢迎贡献代码！请查看 [贡献指南](CONTRIBUTING.md) 了解详细信息。

## 📄 许可证

本项目采用 MIT 许可证。查看 [LICENSE](LICENSE) 文件了解详细信息。

## 🆘 支持

- [问题报告](https://github.com/ai-news-collector/ai-news-collector-lib/issues)
- [讨论区](https://github.com/ai-news-collector/ai-news-collector-lib/discussions)
- [邮件支持](mailto:support@ai-news-collector.com)

## 🔄 更新日志

### v0.1.0 (2025-10-07)

- 初始预发布版本
- 支持基础搜索功能
- 支持多种搜索源
- 支持高级功能（内容提取、关键词分析、缓存等）
- ⚠️ 注意：这是预发布版本，功能可能不稳定

---

**祝你使用愉快！** 🎉
