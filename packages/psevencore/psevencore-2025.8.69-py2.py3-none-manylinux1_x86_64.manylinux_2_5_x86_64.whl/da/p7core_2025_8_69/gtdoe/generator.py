#
# coding: utf-8
# Copyright (C) pSeven SAS, 2010-present
#

import sys as _sys
from pprint import pformat
import ctypes as _ctypes
import contextlib as _contextlib
import numpy as _numpy

from ..six import string_types, next
from ..six.moves import xrange

from .. import shared as _shared
from .. import options as _options
from .. import license as _license
from .. import exceptions as _ex
from .. import status as _status
from ..gtopt.problem import ProblemGeneric as _ProblemGeneric
from ..gtopt.problem import ProblemUnconstrained as _ProblemUnconstrained
from ..gtopt.problem import ProblemConstrained as _ProblemConstrained
from ..gtopt.problem import ProblemCSP as _ProblemCSP
from ..gtopt.problem import ProblemMeanVariance as _ProblemMeanVariance
from ..gtopt.problem import _limited_evaluations

from .fractional_factorial import _generate_fractional_factorial
from .orthogonal_array import _generate_orthogonal_array
from .adaptive_lhs import _generate_adaptive_lhs

from .. import __version__
from ..utils import buildinfo
from ..utils import designs as _designs
from ..result import Result as _Result
from ..result import _evaluate_sparse_data, _postprocess_solution_samples, _read_objectives_type

from . import adaptive_fill as _adaptive_fill
from .api import _Backend

import weakref as _weakref
from ..utils import bbconverter as _bbconverter

#problem aliases live here until we move ProblemGeneric to top level
ProblemGeneric = _ProblemGeneric
ProblemUnconstrained = _ProblemUnconstrained
ProblemConstrained = _ProblemConstrained
ProblemCSP = _ProblemCSP
ProblemMeanVariance = _ProblemMeanVariance

def _get_technique_official_name(technique):
  official_names = {
    "adaptive": "Adaptive",
    "adaptivedesign": "AdaptiveDesign",
    "auto": "Auto",
    "boxbehnken": "BoxBehnken",
    "faureseq": "FaureSeq",
    "fractionalfactorial": "FractionalFactorial",
    "fullfactorial": "FullFactorial",
    "haltonseq": "HaltonSeq",
    "lhs": "LHS",
    "olhs": "OLHS",
    "optimaldesign": "OptimalDesign",
    "orthogonalarray": "OrthogonalArray",
    "parametricstudy": "ParametricStudy",
    "randomseq": "RandomSeq",
    "sobolseq": "SobolSeq",
    "ise": "ISE",
    "diagonal": "Diagonal",
  }
  return official_names[technique.lower()]

DESIGN_SIZE_INFINITY = 1000000 # The maximum automatically selected target size.

class Result(object):
  """Generator result.

  An object of this class is only returned by :meth:`~da.p7core.gtdoe.Generator.generate()`,
  and the class should never be instantiated by user.

  Different attributes are available depending on the mode of :meth:`~da.p7core.gtdoe.Generator.generate()` call
  that returned the result:

  * Sequential space-filling: :meth:`take()` only.
  * Batch space-filling: :attr:`points` and :meth:`take()`.
  * Adaptive (both blackbox- and sample-based): :attr:`points`, :attr:`responses` and :meth:`take()`.

  Also provides DoE generation info and the generator finish status.
  """

  def __init__(self, info, points, pointsY, status, model=None):
    self._info = _shared.parse_json_deep(info, dict) if isinstance(info, string_types) else dict(info)
    self._is_finite = _shared.is_numpy_array(points)
    self._status = status
    self._model = model
    if self._is_finite:
      self._points = points
      self._pointsY = pointsY
      self._point_gen = iter(self._points)
    else:
      self._point_gen = points


  @property
  def model(self):
    """Internal model trained by the Adaptive Design of Experiments technique.

    :type: :class:`.gtapprox.Model`

    This attribute is ``None`` in results generated by any GTDoE technique
    other than the Adaptive Design of Experiments.
    May also be ``None`` in an Adaptive Design of Experiments result,
    if the internal model never reached the minimum accuracy specified by the
    :ref:`GTDoE/Adaptive/InitialModelQualityLevel <GTDoE/Adaptive/InitialModelQualityLevel>`
    option.

    """
    return self._model


  @property
  def info(self):
    """Result info.

    :type: ``dict``

    """
    return self._info

  @property
  def status(self):
    """Finish status.

    :type: :class:`~da.p7core.status.Status`

    .. versionchanged // this is just a comment needed to grep the notice below, do not remove it; Sphinx cannot properly render a real versionchanged directive when the version number contains spaces

    *Changed in version 3.0 Beta 2:* attribute type is :class:`~da.p7core.status.Status`.

    For details, see section :ref:`gen_status`.

    """
    return self._status

  @property
  def points(self):
    """All generated points.

    :type: ``ndarray``, 2D
    :raise: :exc:`~da.p7core.GTException` if the result was returned from sequential :meth:`~da.p7core.gtdoe.Generator.generate()`

    .. versionchanged // this is just a comment needed to grep the notice below, do not remove it; Sphinx cannot properly render a real versionchanged directive when the version number contains spaces

    *Changed in version 3.0 Release Candidate 1:* attribute type is ``ndarray``.

    This attribute is not available from a result of a sequential space-filling generator.
    """
    if not self._is_finite:
      raise _ex.GTException('Unable to get all points from infinite generator')
    return self._points

  @property
  def responses(self):
    """All blackbox responses for generated points.

    :type: ``ndarray``, 2D
    :raise: :exc:`~da.p7core.GTException` if the result was returned from sequential :meth:`~da.p7core.gtdoe.Generator.generate()`

    .. versionchanged // this is just a comment needed to grep the notice below, do not remove it; Sphinx cannot properly render a real versionchanged directive when the version number contains spaces

    *Changed in version 3.0 Release Candidate 1:* attribute type is ``ndarray``.

    If the result was obtained from a generator working in adaptive mode, contains all responses
    that the generator got from calls to blackbox used in the adaptive DoE process
    (that is, the blackbox evaluations for generated points and the points of the initial sample).
    This attribute is empty in the case of a batch space-filling generator, and not available from a result
    of a sequential space-filling generator.

    """
    if not self._is_finite:
      raise _ex.GTException('Unable to get all points from infinite generator')
    return self._pointsY

  def take(self, count):
    """Get generated points.

    :param count: the number of points
    :type count: ``int``
    :return: sample
    :rtype: ``ndarray``, 2D

    .. versionchanged // this is just a comment needed to grep the notice below, do not remove it; Sphinx cannot properly render a real versionchanged directive when the version number contains spaces

    *Changed in version 3.0 Release Candidate 1:* returns ``ndarray``.

    Returns an array of *count* points. If the result was obtained from a batch :meth:`~da.p7core.gtdoe.Generator.generate()`
    and contains less points that *count*, :meth:`~da.p7core.gtdoe.Result.take()` returns all available points.
    """
    if not self._is_finite:
      return _numpy.asarray([next(self._point_gen) for _ in xrange(count)])
    p = []
    try:
      for i in xrange(count):
        p.append(next(self._point_gen))
    except StopIteration:
      pass
    return _numpy.asarray(p)

  def __iter__(self):
    if self._is_finite:
      return iter(self._points)
    return self._point_gen

  def __len__(self):
    if self._is_finite:
      return len(self._points)
    return _sys.maxint

  def __str__(self):
    return pformat(self._info)

class Generator(object):
  """DoE generator."""

  def __init__(self, backend=None):
    self._logger = None
    self._watcher = None
    self._backend = _Backend() if backend is None else backend

  def set_logger(self, logger):
    """Set logger.

    :param logger: logger object
    :return: ``None``

    Used to set up a logger for the DoE generation process. See section :ref:`gen_loggers` for details.
    """
    self._logger = _shared.wrap_with_exc_handler(logger, _ex.LoggerException)
    self._backend.set_logger(self._logger)

  def set_watcher(self, watcher):
    """Set watcher.

    :param watcher: watcher object
    :return: ``None``

    Used to set up a watcher for the DoE generation process. See section :ref:`gen_watchers` for details.
    """
    self._set_watcher(_shared.wrap_with_exc_handler(watcher, _ex.WatcherException))

  def _set_watcher(self, watcher):
    old_watcher = self._watcher
    self._watcher = watcher
    self._backend.set_watcher(self._watcher)
    return old_watcher

  def _get_watcher(self):
    return self._watcher

  def __generate_doe_with_python(self, bounds, count, init_x, validation_mode=False):
    """
    Generate a DoE with Python.

    :param bounds: design space bounds
    :type bounds: ``tuple(list(float), list(float))``
    :param count: number of points to generate
    :type count: ``int``, ``long``
    """
    sift_logger = _shared.Logger(self._logger, self.options._get('GTDoE/LogLevel').lower())

    technique = self.options._get('GTDoE/Technique').lower()
    categorical_variables = list(_shared.parse_json(self.options._get('GTDoE/CategoricalVariables')))
    if technique == 'fractionalfactorial':
      main_factors = list(_shared.parse_json(self.options._get('GTDoE/FractionalFactorial/MainFactors')))
      generating_string = self.options._get('GTDoE/FractionalFactorial/GeneratingString')
      info, points = _generate_fractional_factorial(bounds, count, categorical_variables,
                                                    generating_string, main_factors, sift_logger,
                                                    validation_mode=validation_mode)
      if validation_mode:
        return info, points, None, _status.SUCCESS, None
      info["Generator"]["Options"] = {"GTDoE/Technique": "FractionalFactorial"}
      if len(main_factors):
        info["Generator"]["Options"]["GTDoE/FractionalFactorial/MainFactors"] = _shared.write_json(main_factors)
      if generating_string != "":
        info["Generator"]["Options"]["GTDoE/FractionalFactorial/GeneratingString"] = generating_string
      status = 0
      pointsY = None
    elif technique == 'orthogonalarray':
      if validation_mode:
        self._report_no_validation(_get_technique_official_name(technique))
      seed = self.options._get('GTDoE/Seed')
      deterministic = _shared.parse_bool(self.options._get('GTDoE/Deterministic'))
      max_iterations = self.options._get('/GTDoE/OrthogonalArray/MaxIterations')
      levels_number = self.options._get('GTDoE/OrthogonalArray/LevelsNumber')
      multistart_iterations = self.options._get('GTDoE/OrthogonalArray/MultistartIterations')
      info, points = _generate_orthogonal_array(bounds, count, categorical_variables,
                                                levels_number, int(max_iterations),
                                                int(multistart_iterations), int(seed) if deterministic else None, sift_logger)
      info["Generator"]["Options"] = {"GTDoE/Technique": "OrthogonalArray"}
      info["Generator"]["Options"]['GTDoE/OrthogonalArray/LevelsNumber'] = levels_number
      info["Generator"]["Options"]['GTDoE/OrthogonalArray/MultistartIterations'] = multistart_iterations
      info["Generator"]["Options"]['/GTDoE/OrthogonalArray/MaxIterations'] = max_iterations
      info["Generator"]["Options"]['GTDoE/Deterministic'] = deterministic
      info["Generator"]["Options"]['GTDoE/Seed'] = seed
      status = 0
      pointsY = None
    elif technique in ('lhs', 'olhs'):
      seed = self.options._get('GTDoE/Seed')
      deterministic = _shared.parse_bool(self.options._get('GTDoE/Deterministic'))
      iterations_number = int(self.options._get('GTDoE/OLHS/Iterations')) if technique == 'olhs' else 1
      integer_variables = [i for i, kind in enumerate(_shared.parse_json(self.options._get('/GTDoE/VariablesType'))) if kind.lower() == "integer"]
      info, points = _generate_adaptive_lhs(bounds=bounds, points_number=count, categorical_variables=categorical_variables,
                                            integer_variables=integer_variables, initial_points=init_x, iterations_number=iterations_number,
                                            seed=(int(seed) if deterministic else None), sift_logger=sift_logger,
                                            quality_measure=self.options._get("/GTDoE/OLHS/Criterion"),
                                            smooth=_shared.parse_auto_bool(self.options._get("/GTDoE/LHS/smooth"), (technique != 'olhs')),
                                            validation_mode=validation_mode)
      if validation_mode:
        return info, points, None, _status.SUCCESS, None
      info["Generator"]["Options"] = {"GTDoE/Technique": technique}
      if technique == 'olhs':
        info["Generator"]["Options"]['GTDoE/OLHS/Iterations'] = iterations_number
      info["Generator"]["Options"]['GTDoE/Deterministic'] = deterministic
      info["Generator"]["Options"]['GTDoE/Seed'] = seed
      status = 0
      pointsY = None
    else:
      sift_logger.error('GTDoE/Technique: ' + self.options._get('GTDoE/Technique') +
                        ' is not a member of Python-implemented techniques' + '\n')
      return None, None, None, None, None
    if len(categorical_variables):
      info["Generator"]["Options"]["GTDoE/CategoricalVariables"] = _shared.write_json(categorical_variables)
    info["Generator"]["Technique"] = self.options._get('GTDoE/Technique')
    info["Generator"]["Number of variables"] = len(bounds[0])
    info["Generator"]["Number of points"] = count
    info["Generator"]["Number of new points"] = len(points)
    info["Generator"]["Mode"] = "Batch"
    info["Generator"]["BuildStamp"] = buildinfo.buildinfo().get("Build", {}).get("Stamp", 'version=' + str(__version__) + ';')
    return info, points, pointsY, _Backend._convert_status(status), None

  @property
  def options(self):
    """Generator options.

    :type: :class:`~da.p7core.Options`

    General options interface for the generator. See section :ref:`gen_options` for usage and the GTDoE :ref:`ug_gtdoe_options`.

    """
    return _options.Options(self._backend.options_manager, self._backend)

  @property
  def license(self):
    """Generator license.

    :type: :class:`~da.p7core.License`

    General license information interface. See section :ref:`gen_license_usage` for details.

    """
    return _license.License(self._backend.license_manager, self._backend)

  def build_doe(self, blackbox, count, sample_x=None, sample_f=None, sample_c=None, options=None):
    """
    Generate a design of experiments (DoE), containing values of variables only,
    or run a sampling study --- generate a DoE and run it, evaluating responses.

    :param blackbox: DoE blackbox, or design space bounds (lower, upper)
    :type blackbox: :class:`~da.p7core.gtdoe.ProblemGeneric` or other GTDoE problem class, :class:`~da.p7core.blackbox.Blackbox`, :class:`.gtapprox.Model`, :class:`.gtdf.Model`; or a pair of iterables containing floats
    :param count: in space-filling techniques: the target size of DoE sample, ``0`` means default size; in Adaptive Design: the target number of feasible designs, ``0`` means continue generation until reaching a response evaluation limit
    :type count: ``int``
    :param sample_x: optional initial sample containing values of variables
    :type sample_x: :term:`array-like`, 1D or 2D
    :param sample_f: optional initial sample of objective function values, requires ``sample_x``
    :type sample_f: :term:`array-like`, 1D or 2D
    :param sample_c: optional initial sample of constraint function values, requires ``sample_x``
    :type sample_c: :term:`array-like`, 1D or 2D
    :param options: study options; not required, amends the options set through the options interface
    :type options: ``dict``
    :return: study result
    :rtype: :class:`.p7core.Result`

    .. versionadded:: 6.14

    .. versionchanged:: 6.19
       :arg:`count` now sets an aim for the number of feasible DoE points to generate, not the allowed number of evaluations; to set evaluation limits, use :ref:`GTDoE/AdaptiveDesign/MaximumIterations <GTDoE/AdaptiveDesign/MaximumIterations>` and :ref:`GTDoE/AdaptiveDesign/MaximumExpensiveIterations <GTDoE/AdaptiveDesign/MaximumExpensiveIterations>`.

    .. versionchanged:: 6.20
       :arg:`blackbox` may be a :class:`.gtapprox.Model` or a :class:`.gtdf.Model`.

    .. versionchanged:: 6.26
       now supports space-filling as well as adaptive DoE techniques.

    .. versionchanged:: 6.27
       for space-filling techniques, :arg:`count` may be ``0`` to generate the default number of points if the technique supports it.

    .. versionchanged:: 6.29
       added stepped variables support.

    .. versionchanged:: 6.29
       space-filling techniques no longer raise an exception when it is not possible to generate :arg:`count` points; instead they issue a warning and return result, which contains all generated points.

    .. versionchanged:: 6.33
       space-filling techniques and Adaptive Design of Experiments now support constraints.

    .. versionchanged:: 6.33
       added categorical variables support in the Adaptive Design technique.

    .. versionchanged:: 6.35
       added the support for evaluation responses, minimization and maximization objectives --- see the :ref:`@GT/ObjectiveType <ug_gtdoe_hints_obj_type>` hint.

    .. versionchanged:: 6.35
       DoE techniques now evaluate responses in all resulting DoE points (previously, only in feasible points).

    .. versionchanged:: 6.35
       to freeze a variable, you can now use the :ref:`@GT/FixedValue <ug_gtdoe_hints_fixedvalue>` hint; methods from previous versions are also supported for compatibility, but using them is not recommended.

    .. versionchanged:: 6.36
       for compatibility with Adaptive Design, most techniques now handle categorical variables in a similar manner --- generate a DoE for each possible combination of categories, :arg:`count` and evaluation limits are split between those designs --- so generation result may be used as an initial sample in Adaptive Design without issues; only the Full Factorial, Fractional Factorial and Orthogonal Array techniques do not change their behavior from 6.35 (to revert to old behavior in other techniques, you can redefine categorical variables as discrete).

    .. versionchanged:: 6.45
       added the support for mixed designs (include continuous and discrete variables) to the Adaptive Design of Experiments technique.

    .. versionchanged:: 6.45
       Adaptive Design of Experiments can run in space-filling mode.

    .. versionchanged:: 6.45
       all techniques support ``0`` as a valid :arg:`count` value, which means generating the default number of points (DoE size).

    General DoE study method, which supports all GTDoE techniques
    and different types of variables and blackboxes,
    with certain limitations imposed by the selected technique.

    To select a technique, use the :ref:`GTDoE/Technique <GTDoE/Technique>` option.
    Technique requirements and limitations are outlined below.

    Before you run a DoE study, validate your settings with
    :meth:`~da.p7core.gtdoe.Generator.validate()`
    to avoid errors caused by incorrect study definition.

    .. rubric:: Types of variables

    GTDoE recognizes the following types of variables:

    * Continuous (default type) --- a generic continuous variable
      that can take any value within its lower and upper bounds.
    * Discrete --- a discontinuous numeric variable
      that can take any value from the predefined set of allowed values (levels).
    * Stepped --- a special kind of a continuous variable that is bound to a certain grid.
    * Categorical --- a special type of variable
      that has a finite number of possible values (categories)
      and does not assume any numerical meaning, order or metrics.
      If your design includes categorical variables, most techniques
      generate all possible combinations of categories
      and run a DoE for each of those combinations.
      Notable exceptions are the Fractional Factorial and Orthogonal Array techniques,
      which generally handle categorical variables in the same way as discrete ones.

    If :arg:`blackbox` is an instance of :class:`~da.p7core.gtdoe.ProblemGeneric`
    or another GTDoE problem class,
    specify types of variables when you add them to your problem,
    using the :ref:`@GT/VariableType <ug_gtdoe_hints_var_type>` hint
    in :meth:`~da.p7core.gtdoe.ProblemGeneric.add_variable()`.
    In this case, variable bounds or levels are specified as arguments
    to :meth:`~da.p7core.gtdoe.ProblemGeneric.add_variable()`.

    If :arg:`blackbox` is a :class:`.gtapprox.Model` or :class:`.gtdf.Model` instance,
    types of variables are defined by the model (input descriptions,
    see :ref:`ug_gtapprox_details_model_information`).

    Categorical variables and their levels may also be specified via the
    :ref:`GTDoE/CategoricalVariables <GTDoE/CategoricalVariables>` option,
    which may be useful in the following cases:

    * To define categorical variables when :arg:`blackbox` is
      a :class:`~da.p7core.blackbox.Blackbox` instance
      or an array of design space bounds.
    * With other blackbox types ---
      to change some variables of different types to categorical,
      or to narrow the set of levels for some categorical
      variable defined by the blackbox (model).
      In the latter case, :ref:`GTDoE/CategoricalVariables <GTDoE/CategoricalVariables>`
      may only select a subset from levels already defined by the blackbox (model),
      but may not add new levels.

    Note that some techniques do not support certain types of variables ---
    see section :ref:`ug_gtdoe_general_properties_types_of_variables` for details.

    .. rubric:: Constants

    A variable of any type can be frozen, giving it a constant value in the generated sample.
    To freeze a variable, use the :ref:`@GT/FixedValue <ug_gtdoe_hints_fixedvalue>` hint.
    For a continuous variable, you may specify a constant value that is out of variable bounds.
    For other types of variables, the value you specify must be a valid level for that variable.

    .. rubric:: Space-filling techniques

    Space-filling DoE techniques do not analyze blackbox responses although evaluate them, if defined.
    These techniques first generate the input DoE, then evaluate responses with that inputs.
    Constraints are recognized --- resulting designs are sorted into feasible and infeasible,
    if :arg:`blackbox` defines constraints.
    If the blackbox defines any minimization or maximization objectives
    (see the :ref:`@GT/ObjectiveType <ug_gtdoe_hints_obj_type>` hint),
    GTDoE also finds optimal points among those appearing in the result.

    For space-filling techniques, :arg:`blackbox` may be a pair of iterables ``(lower, upper)``
    containing ``float`` values that specify the lower and upper bounds for each of the design variables.
    The length of each iterable must be equal to the number of variables.
    In this case you can use the :ref:`GTDoE/CategoricalVariables <GTDoE/CategoricalVariables>` option
    to set up categorical variables by specifying their indexes and levels.
    For categorical variables, bounds are ignored, so in :arg:`blackbox` the elements
    corresponding to categorical variables may have arbitrary ``float`` values
    (they are required only for correct indexing of variables).

    With other types of blackboxes, properties of variables (types, bounds, levels) are read from the blackbox object
    or from model details, if :arg:`blackbox` is an approximation model.
    The :ref:`GTDoE/CategoricalVariables <GTDoE/CategoricalVariables>` option in this case may be used to
    change some variables of different types to categorical,
    or to narrow the set of levels for some categorical variable defined by the blackbox (model).
    Note that :ref:`GTDoE/CategoricalVariables <GTDoE/CategoricalVariables>` may only
    select a subset from levels defined by the blackbox (model), but may not add new levels.

    The :arg:`count` argument sets the number of design points to generate.
    For the space-filling techniques, ``0`` is a valid :arg:`count` value,
    which means generating a sample of the default size:

    * Full Factorial ---
      default is the minimum required to generate a sample that includes all possible combinations
      of variable levels or categories; continuous and stepped variables are assigned 2 levels ---
      their lower and upper bounds.
    * Fractional Factorial ---
      default size is defined by the generating string;
      if you do not specify the generating string or main factors,
      default is the minimum possible sample size
      for the given number of variables (dimension).
    * Parametric Study ---
      default is the minimum possible sample size
      for the given number of variables (dimension),
      that includes all possible combinations produced by categorical variables.
    * Optimal Design ---
      default is the minimum sample size suitable to train an RSM model of the target type
      (set by :ref:`GTDoE/OptimalDesign/Model <GTDoE/OptimalDesign/Model>`)
      for each possible combination produced by categorical variables.
    * Box-Behnken ---
      has a fixed DoE size determined by the number of variables (dimension),
      multiplied by the number of possible combinations produced by categorical variables.
      For this technique, using default :arg:`count` is recommended.
    * Orthogonal Array ---
      default is the minimum size of a proper orthogonal array for the given number of variables.
    * Other space-filling techniques ---
      default is an internal estimate depending on the design space dimension
      (the number of variables).

    If your design includes categorical variables, it is handled as follows:

    * If you use the Full Factorial technique, all possible combinations of categories are generated.
    * If you use the Fractional Factorial technique, combinations are generated as per the generating string
      (see :ref:`gtdoe_techniques_fractional_factorial` for details).
    * If you use the Orthogonal Array technique, it produces the minimum number of combinations required to
      generate an array of the requested type and size (see :ref:`gtdoe_techniques_oa` for details).
    * If you use any other space-filling technique, GTDoE generates all possible combinations of categories,
      then for each of those combinations generates a DoE using the technique you have specified
      and splitting :arg:`count` between those sub-runs.
      If dividing :arg:`count` by the number of combinations leaves a remainder,
      that remainder is distributed between sub-runs so that each of them gets at most 1 extra point.

    Note that in certain cases it is not possible to generate as many as :arg:`count` points ---
    for example, if all variables are discrete, a full factorial DoE has fixed size.
    In such cases, only the possible number of points are generated and included in result,
    and GTDoE issues a warning.

    .. rubric:: Adaptive Design of Experiments

    This technique analyzes blackbox responses though can also work in sample-based
    and space-filling modes, if response evaluations are not available.
    It selects the mode automatically based on the :arg:`blackbox` type,
    response properties, and availability of the initial sample.
    In the adaptive (main) mode, it analyzes behavior of adaptation objectives
    (see the :ref:`@GT/ObjectiveType <ug_gtdoe_hints_obj_type>` hint),
    and supports constraints but does not analyze them
    (treats constraints in the same way as the space-filling techniques).
    Minimization and maximization objectives are treated in the same way as in
    space-filling techniques --- GTDoE finds optimal points in the final result.
    If your design includes categorical variables,
    GTDoE generates all possible combinations of categories,
    then runs an independent Adaptive Design of Experiments study
    for each combination, splitting :arg:`count` between those sub-runs.

    In the adaptive (main) mode:

    * :arg:`blackbox` must be
      :class:`~da.p7core.gtdoe.ProblemGeneric`,
      :class:`~da.p7core.gtdoe.ProblemUnconstrained`,
      :class:`~da.p7core.blackbox.Blackbox`,
      or an approximation model (GTApprox, GTDF).
      Models with categorical inputs are supported only if all inputs are categorical.
      Models with categorical outputs are not supported.
    * If :arg:`blackbox` is a GTDoE problem instance, it must define at least 1 adaptation objective;
      if a :class:`~da.p7core.blackbox.Blackbox` instance, must define at least 1 response.
    * Properties of variables are defined by the blackbox.
      The :ref:`GTDoE/CategoricalVariables <GTDoE/CategoricalVariables>` option may be used to
      change some of the continuous variables to categorical,
      or to narrow the set of levels for some categorical variable defined by the blackbox (model).
      Note that :ref:`GTDoE/CategoricalVariables <GTDoE/CategoricalVariables>` may only
      select a subset from levels defined by the blackbox (model), but may not add new levels.
    * An initial sample is optional.
    * All adaptive DoE criteria are supported
      (see :ref:`GTDoE/Adaptive/Criterion <GTDoE/Adaptive/Criterion>`).

    In the sample-based mode:

    * This mode is used when there are no adaptation objectives,
      and you provide an initial sample.
    * The :arg:`blackbox` argument may be a pair of iterables defining
      the lower and upper bounds of variables --- for example, 2 lists of ``float`` values.
    * You can use the :ref:`GTDoE/CategoricalVariables <GTDoE/CategoricalVariables>`
      option to set up categorical variables.
      If :arg:`blackbox` is an array of bounds,
      you can set arbitrary values of bounds for categorical variables,
      since bounds for them are ignored.
    * If you provide an initial sample with response data
      (pass variable and response samples as :arg:`sample_x` and :arg:`sample_f`),
      all adaptive DoE criteria are supported
      (see :ref:`GTDoE/Adaptive/Criterion <GTDoE/Adaptive/Criterion>`).
      If you provide only :arg:`sample_x`, then only the uniform criterion is supported.

    In the space-filling mode:

    * This mode is used when there are no adaptation objectives and no initial sample.
    * The :arg:`blackbox` argument may be a pair of iterables defining
      the lower and upper bounds of variables --- for example, 2 lists of ``float`` values.
    * You can use the :ref:`GTDoE/CategoricalVariables <GTDoE/CategoricalVariables>`
      option to set up categorical variables.
      If :arg:`blackbox` is an array of bounds,
      you can set arbitrary values of bounds for categorical variables,
      since bounds for them are ignored.
    * Only the uniform criterion is supported
      (see :ref:`GTDoE/Adaptive/Criterion <GTDoE/Adaptive/Criterion>`).

    In the adaptive mode, :arg:`count` sets the number of allowed response evaluations.
    In the space-filling mode, :arg:`count` sets the number of new points to generate.
    If your design includes categorical variables, GTDoE splits :arg:`count`
    between sub-runs done for each of the possible combinations of categories.
    If dividing :arg:`count` by the number of combinations leaves a remainder,
    that remainder is distributed between sub-runs so that each of them gets at most 1 extra point.

    For Adaptive Design of Experiments, ``0`` is also a valid :arg:`count` value:
    the number of points to generate will be estimated internally,
    depending on the design space dimension (the number of variables).

    .. rubric:: Adaptive Design

    The Adaptive Design technique supports constraint and objective responses
    and analyzes behavior of adaptation objectives
    (see the :ref:`@GT/ObjectiveType <ug_gtdoe_hints_obj_type>` hint),
    generating new designs with aims as follows:

    * If the blackbox defines any constraints, aim to generate points
      that satisfy those constraints (generate points in the feasibility domain).
    * If the blackbox defines any adaptation objectives, aim to generate more points
      in the design space areas where adaptation objective functions exhibit non-trivial behavior ---
      for example, where a function is more sensitive to changes in inputs (variables).
    * If the blackbox does not define any adaptation objective, aim to distribute
      points uniformly in the feasibility domain (satisfy constraints).
    * If the blackbox defines adaptation objectives as well as constraints,
      aim to generate points in the feasibility domain but take into account
      the behavior of adaptation objectives when distributing points within that domain.
    * If the blackbox does not define any adaptation objectives or constraints,
      generate a uniformly distributed sample within the design space (variable) bounds.
    * Minimization and maximization objectives are treated in the same way as in
      space-filling techniques --- GTDoE finds optimal points in the final result.

    Internally, Adaptive Design trains approximation models of responses and
    uses them to predict response behavior when placing new points.
    If you pass an initial sample containing response data, that sample is used
    to obtain initial models, which are further updated when the Adaptive Design
    algorithm receives new response evaluations from the blackbox.

    * Requires :arg:`blackbox` to be an instance of your problem class
      inherited from :class:`~da.p7core.gtdoe.ProblemGeneric`
      or one of the simplified GTDoE problem classes,
      or an approximation model (GTApprox, GTDF).
      Models with categorical outputs are not supported.

      For a guide on how to implement your problem class,
      see descriptions of :class:`~da.p7core.gtdoe.ProblemGeneric` and other classes.
      In brief:

      * Inherit your class from :class:`~da.p7core.gtdoe.ProblemGeneric`
        or one of the simplified GTDoE problem classes.
      * Implement :meth:`~da.p7core.gtdoe.ProblemGeneric.prepare_problem()`.
      * In your :meth:`~da.p7core.gtdoe.ProblemGeneric.prepare_problem()` definition, use
        :meth:`~da.p7core.gtdoe.ProblemGeneric.add_variable()`,
        :meth:`~da.p7core.gtdoe.ProblemGeneric.add_constraint()`, and
        :meth:`~da.p7core.gtdoe.ProblemGeneric.add_objective()`
        to add variables and responses and set their properties.
      * Variables are continuous by default.
        To change type of a variable, use the :ref:`@GT/VariableType <ug_gtdoe_hints_var_type>` hint
        in :meth:`~da.p7core.gtdoe.ProblemGeneric.add_variable()`.
      * Use response hints in
        :meth:`~da.p7core.gtdoe.ProblemGeneric.add_constraint()` and
        :meth:`~da.p7core.gtdoe.ProblemGeneric.add_objective()` to specify
        their computational cost and dependency type
        (see :ref:`ug_gtdoe_hints` for details).

    * If you define categorical variables, Adaptive Design
      runs an independent subtask for each possible combination of categories.
    * If the blackbox does not define any adaptation objectives or constraints, Adaptive Design switches to
      space-filling mode where it generates a uniformly distributed sample.
      This mode may be used to update a non-uniform initial sample to a more
      uniform result sample.
    * Constraint and objective responses are processed as outlined above.
      Responses defined as computationally expensive
      (see the :ref:`@GTOpt/EvaluationCostType <ug_gtdoe_hints_resp_cost>` hint)
      are modeled internally; Adaptive Design requests evaluations of such responses
      to update and improve their internal models.
      Computationally cheap responses are always evaluated directly
      and may be evaluated an unlimited number of times by default.
      Note that responses are considered cheap by default.

    The distinction between computationally cheap and expensive responses
    is one of the key features in Adaptive Design.

    Expensive responses are always expected to have a finite evaluation limit.
    This limit is set according to the
    :ref:`GTDoE/AdaptiveDesign/MaximumExpensiveIterations <GTDoE/AdaptiveDesign/MaximumExpensiveIterations>` option value.
    If this option does not set a specific limit, GTDoE determines it automatically.
    The automatic limit is finite but can vary depending on the problem properties.
    Adaptive Design generally aims to minimize the number of expensive response evaluations.

    Cheap responses may be evaluated an unlimited number of times by default.
    Adaptive Design does not aim to limit the number of cheap response evaluations.
    This limit may be imposed manually, using the
    :ref:`GTDoE/AdaptiveDesign/MaximumIterations <GTDoE/AdaptiveDesign/MaximumIterations>`,
    although its value should be relatively high (of order `10^3` or greater).
    Setting the evaluation limit for computationally cheap responses too low
    may cause an abrupt stop in the Adaptive Design algorithm, which does not raise an error
    but often decreases the result quality significantly.
    If your design includes categorical variables, Adaptive Design
    runs an independent subtask for each possible combination of categories,
    and evaluation limits are split between those subtasks.
    If dividing some limit by the number of subtasks leaves a remainder,
    that remainder is distributed between subtasks so that each of them gets at most 1 extra evaluation.

    For the Adaptive Design technique, a non-zero :arg:`count` argument sets
    the target number of feasible points to generate.
    Feasible points are points that satisfy constraints defined by :arg:`blackbox`;
    if the blackbox defines no constraints, all generated points are considered feasible.
    The target number of feasible points cannot be greater than the evaluation limit for expensive responses
    (:ref:`GTDoE/AdaptiveDesign/MaximumExpensiveIterations <GTDoE/AdaptiveDesign/MaximumExpensiveIterations>`).
    If your design includes categorical variables, :arg:`count` sets the total target number
    of feasible points, which is split between the subtasks created by Adaptive Design.
    If dividing :arg:`count` by the number of subtasks leaves a remainder,
    that remainder is distributed between subtasks so that each of them gets at most 1 extra point.

    Evaluation limits and :arg:`count` may be used together --- for example:

    * If :arg:`count` is ``0``, the technique continues generating new designs until
      it reaches one of the evaluation limits.
      Note that the number of expensive response evaluations is always finite ---
      even if you do not set the
      :ref:`GTDoE/AdaptiveDesign/MaximumExpensiveIterations <GTDoE/AdaptiveDesign/MaximumExpensiveIterations>`
      option, GTDoE sets a finite limit automatically, based on problem properties
      (number of variables, responses, their types, and so on).
    * If you specify :arg:`count` only (greater than 0),
      the technique continues generating new designs until it finds :arg:`count` feasible points,
      aiming to minimize the number of expensive response evaluations.
    * If you specify :arg:`count` (greater than 0) and set
      :ref:`GTDoE/AdaptiveDesign/MaximumExpensiveIterations <GTDoE/AdaptiveDesign/MaximumExpensiveIterations>`,
      the technique continues generating new designs until it finds :arg:`count` feasible designs
      or reaches the expensive response evaluation limit, whichever happens first.
      It also aims to minimize the number of expensive response evaluations.

    """
    self._log_build_stamp(options=options)
    with _shared.sigint_watcher(self):
      with _shared._suppress_history(problem=blackbox):
        return self._do_build_doe(blackbox, count, sample_x, sample_f, sample_c, options)

  def validate(self, blackbox, count, sample_x=None, sample_f=None, sample_c=None, options=None):
    """
    Validate a DoE study definition.

    :param blackbox: DoE blackbox, or design space bounds (lower, upper)
    :type blackbox: :class:`~da.p7core.gtdoe.ProblemGeneric` or other GTDoE problem class, :class:`~da.p7core.blackbox.Blackbox`, :class:`.gtapprox.Model`, :class:`.gtdf.Model`; or a pair of iterables containing floats
    :param count: in space-filling techniques: sample size, ``0`` means default; in Adaptive Design: the target number of feasible designs, ``0`` means no target
    :type count: ``int``
    :param sample_x: optional initial sample of variables
    :type sample_x: :term:`array-like`, 1D or 2D
    :param sample_f: optional initial sample of objectives
    :type sample_f: :term:`array-like`, 1D or 2D
    :param sample_c: optional initial sample of constraints
    :type sample_c: :term:`array-like`, 1D or 2D
    :param options: study options
    :type options: ``dict``
    :return: validation outcome
    :rtype: :class:`.gtdoe.ValidationResult`

    .. versionadded:: 6.33

    Validates your study settings and returns
    a :class:`~da.p7core.gtdoe.ValidationResult` object providing general validation status
    (:attr:`~da.p7core.gtdoe.ValidationResult.status`, ``True`` if validation passed, ``False`` otherwise)
    and details, if any (:attr:`~da.p7core.gtdoe.ValidationResult.details`).

    Test your study definition before running :meth:`~da.p7core.gtdoe.Generator.build_doe()`
    to avoid errors caused by incorrect study settings.
    When calling :meth:`~da.p7core.gtdoe.Generator.validate()`, pass the same arguments
    as you would pass to :meth:`~da.p7core.gtdoe.Generator.build_doe()`,
    including option settings and initial samples.
    All :meth:`~da.p7core.gtdoe.Generator.validate()` parameters
    have the same meaning as :meth:`~da.p7core.gtdoe.Generator.build_doe()` parameters.
    """
    old_logger = self._logger
    try:
      issues_logger = _adaptive_fill._IssuesCollectionLogger()
      self.set_logger(issues_logger)
      # keep watcher since validation of AdaptiveDesign may take a long time

      with _shared.sigint_watcher(self):
        validation_result = self._do_build_doe(blackbox, count, sample_x=sample_x, sample_f=sample_f, sample_c=sample_c, options=options, validation_mode=True)

      validation_result.details.extend(issues_logger.issues)
      return validation_result
    except:
      exc_info = _sys.exc_info()
    finally:
      # restore logger, must not fail
      self._logger = old_logger
      self._backend.set_logger(self._logger)
    return _adaptive_fill._report_validation_failure(*exc_info)

  def _do_build_doe(self, blackbox, count, sample_x=None, sample_f=None, sample_c=None, options=None, validation_mode=False):
    _shared.check_concept_int(count, '`build_doe` argument')
    if count < 0:
      raise ValueError("The number of requested points must be greater than or equal to zero")
    if options is not None:
      _shared.check_concept_dict(options, 'options')
    else:
      options = {}

    if sample_x is not None:
      sample_x = _shared.as_matrix(sample_x, name="Initial sample containing values of variables ('sample_x' argument)")
      if not len(sample_x):
        sample_x = None

    if sample_f is not None:
      sample_f = _shared.as_matrix(_designs._preprocess_initial_objectives(blackbox, sample_f), detect_none=True,
                                   name="Initial sample of objective function values ('sample_f' argument)")
      if not len(sample_f):
        sample_f = None

    if sample_f is not None:
      if sample_x is None:
        raise ValueError("Initial sample of objective function values ('sample_f') requires initial sample containing values of variables ('sample_x')")
      elif len(sample_x) != len(sample_f):
        raise ValueError("Initial sample of objective function values ('sample_f') must have the same length as the initial sample containing values of variables ('sample_x'): %d != %d" % (len(sample_f), len(sample_x)))

    if sample_c is not None:
      sample_c = _shared.as_matrix(sample_c, detect_none=True, name="Initial sample of constraint function values ('sample_c' argument)")
      if not len(sample_c):
        sample_c = None

    if sample_c is not None:
      if sample_x is None:
        raise ValueError("Initial sample of constraint function values ('sample_c') requires initial sample containing values of variables ('sample_x')")
      elif len(sample_x) != len(sample_c):
        raise ValueError("Initial sample of constraint function values ('sample_c') must have the same length as the initial sample containing values of variables ('sample_x'): %d != %d" % (len(sample_c), len(sample_x)))

    with _shared._scoped_options(self, options):
      self.options.set({'/GTDoE/SuppressResultWarning': True})#suppress an old warning
      sift_logger = _shared.Logger(self._logger, self.options._get('GTDoE/LogLevel').lower())

      technique_name = self.options._get('GTDoE/Technique')
      technique_test = technique_name.lower()

      if technique_test == 'auto':
        count, extra_options = self._select_auto_technique(blackbox=blackbox, count=(count or 0), sample_f=sample_f, logger=sift_logger, compatibility=False)
        self.options.set(extra_options)
        technique_name = self.options._get('GTDoE/Technique')
        technique_test = technique_name.lower()
      else:
        sift_logger.info('Using the %s technique specified by the GTDoE/Technique option.' % (technique_name,))

      catvars = _shared.parse_json(self.options._get('GTDoE/CategoricalVariables'))

      if technique_test == 'adaptivedesign':
        with _bbconverter._as_problem_generic(blackbox=blackbox, catvars=catvars, location=_bbconverter._make_location('AdaptiveDesign'), logger=sift_logger, init_y=sample_f) as problem:
          problem._validate()
          if not _adaptive_fill._test_categorical_only_problem(problem):
            return _adaptive_fill._fill(self, problem, count, sample_x=sample_x, sample_f=sample_f, sample_c=sample_c, options=self.options.values, validation_mode=validation_mode)

          sift_logger.warn('Using the FullFactorial technique instead of the AdaptiveDesign technique because all problem variables are categorical or have a fixed value.')

          self.options.set('GTDoE/Technique', 'FullFactorial')
          technique_name = self.options._get('GTDoE/Technique')
          technique_test = technique_name.lower()

      if sample_c is not None:
        try:
          if sample_c.shape[1] != blackbox.size_c():
            raise ValueError("Initial sample of constraint function values must conform number of constraints: %d != %d." % (sample_c.shape[1], blackbox.size_c()))
        except AttributeError:
          exc_info = _sys.exc_info()
          _shared.reraise(_ex.UnsupportedProblemError, "Initial sample of constraint function values requires constrained problem", exc_info[2])

      with _bbconverter._as_problem_generic(blackbox=blackbox, catvars=catvars, location=_bbconverter._make_location(technique_name), logger=sift_logger, init_y=sample_f) as problem:
        self._validate_initial_sample(problem, sample_x=sample_x, sample_f=sample_f, sample_c=sample_c)

      self.report_ignore_ig(problem=blackbox, technique=technique_name, logger=sift_logger)

      configuration = self._read_limited_evaluations_configuration(options={})
      with _limited_evaluations(problem=blackbox, watcher_ref=self._get_watcher, configuration=configuration) as blackbox:
        solution_snapshot_watcher = None
        try:
          solution_snapshot_watcher = self._create_snapshot_watcher(problem=blackbox, validation_mode=validation_mode)
          solution_snapshot_watcher.initial_sample(sample_x=sample_x, sample_f=sample_f, sample_c=sample_c, sample_nf=None, sample_nc=None) # we can call it once because we don't reconstruct linear responses
          original_watcher = self._set_watcher(solution_snapshot_watcher.watcher)

          result_blackbox = None

          if technique_test == 'ise':
            # Note we force validation mode so we leave all evaluations for the final stage
            info, points_x, points_y, status, model = self._initial_sample_evaluation(blackbox=blackbox, sample_x=sample_x, sample_f=sample_f, validation_mode=True, sift_logger=sift_logger)
            try:
              custom_status_id = int(self.options.get('/GTDoE/ISECustomStatus'))
              status = _Backend._convert_status(custom_status_id, status)
              sift_logger.debug("Setting custom status `%s` for ISE" % status)
            except:
              sift_logger.debug("Setting default status `%s` for ISE" % status)
          else:
            params = {}

            if technique_test == 'adaptive':
              adaptive_blackbox, bounds, catvars, warns, var_types = _bbconverter._make_blackbox(blackbox, count, catvars, _bbconverter._make_location('Adaptive'))
              if adaptive_blackbox is not None:
                params.update({'blackbox': adaptive_blackbox, 'budget': count})
              else:
                params.update({'count': count})
            else: # non-adaptive techniques
              bounds, catvars, warns, var_types = _bbconverter._make_bounds(blackbox, catvars, technique_name)
              params.update({'count': count})

            for msg in (warns or []):
              sift_logger.warn(msg)

            self.options.set('GTDoE/CategoricalVariables', catvars)
            self.options.set('/GTDoE/VariablesType', var_types)

            sample_x, valid_initial_points, result_blackbox = self._preprocess_initial_sample(blackbox, catvars, technique_name, sample_x, sample_f)
            self._assign_initial_sample_params(params=params, init_x=sample_x, init_y=sample_f, valid_points=valid_initial_points)

            categorical_results = []
            variables_names = result_blackbox.variables_names() if result_blackbox else [("x"+str(i)) for i in range(len(bounds[0]))]
            for local_bounds, local_params, local_options, categorical_signature in self._enumerate_categorical_combinations(catvars, bounds, params, variables_names, technique_name):
              with _shared._scoped_options(self, local_options, keep_options=None):
                categorical_results.append(self._gen(local_bounds, legacy=False, options=None, validation_mode=validation_mode, **local_params) + (categorical_signature,))

            info, points_x, points_y, status, model = self._combine_categorical_combinations(categorical_results, catvars)

          if validation_mode:
            return _adaptive_fill._report_validation_succeeded((len(points_x) if points_x is not None else None), (len(sample_x) if sample_x is not None else None), info, status)

          assert(points_x is not None)
          if points_y is not None and not points_y.size:
            points_y = None

          result_blackbox = _bbconverter._make_result_compatible((result_blackbox or blackbox), catvars, location=_bbconverter._make_location(technique_name),
                                                                size_f=(points_y.shape[1] if points_y is not None else sample_f.shape[1] if sample_f is not None else 0))
          solutions_table, fields = self._collect_solutions_table(points_x, points_y, result_blackbox, sample_x, sample_f, sample_c)
          solutions_table = self._remove_dups_from_solutions_table(solutions_table, count, None)
          solutions_table, fields, constraints_tol = self._prepare_new_result_data(result_blackbox, solutions_table, fields, None)

          designs, solutions_subsets, result_options = None, None, None
          try:
            result_options = _adaptive_fill._translate_general_options(self)
            if technique_test == 'ise':
              result_options['/GTOpt/EvaluateResultSubset'] = 'All' # force evaluation of all points (note intentional gtopt prefix)

            initial_sample, initial_fields = self._postprocess_initial_sample(result_blackbox, solutions_table, fields, sample_x, sample_f, sample_c)
            designs = _designs._solutions_to_designs(result_blackbox, solutions_table, fields, _slice_or_none(initial_sample, initial_fields, "x"),
                                                    _slice_or_none(initial_sample, initial_fields, "f"), _slice_or_none(initial_sample, initial_fields, "c"),
                                                    constraints_tol)
            solutions_table, fields, solutions_subsets = _postprocess_solution_samples(default_solution=solutions_table, default_fields=dict(fields),
                                                                                       initial_sample=initial_sample, initial_fields=initial_fields,
                                                                                       problem=result_blackbox)
          except:
            pass # any exception here is ignorable

          result = _Result(status, info, solutions_table, dict(fields),
                            (_weakref.ref(result_blackbox) if result_blackbox is not None else None),
                            model=model, designs=designs, solutions_subsets=solutions_subsets, finalize=False)
          result._finalize(problem=result_blackbox, auto_objective_type=('Adaptive' if technique_test == 'adaptive' else 'Evaluate'), options=result_options, logger=sift_logger)

          solution_snapshot_watcher.proceed(result)
          return result
        finally:
          if solution_snapshot_watcher:
            solution_snapshot_watcher.reset()
            self._set_watcher(original_watcher)

  def _combine_categorical_combinations(self, categorical_results, catvars):
    assert categorical_results

    if len(categorical_results) == 1:
      return categorical_results[0][:-1] # the last one is excessive categorical signature

    total_points_x = []
    total_points_y = []
    all_models = []
    size_y = 0

    final_status = _status.IN_PROGRESS # this status has the less priority
    final_info = {}

    for info, points_x, points_y, status, model, combination_name in categorical_results:
      try:
        info = _shared.parse_json(info)
      except:
        pass # do nothing, use info as-is

      try:
        final_info[combination_name] = info
      except:
        pass

      if _status._select_status(status, final_status):
        final_status = status

      if model is not None:
        all_models.append(model)

      if points_x is not None:
        if points_y is not None:
          if not size_y:
            size_y = points_y.shape[1]
            total_points_y = [_shared._filled_array((x.shape[0], size_y), _shared._NONE) for x in total_points_x]
          total_points_y.append(points_y)
        elif size_y:
          total_points_y.append(_shared._filled_array((points_x.shape[0], size_y), _shared._NONE))
        total_points_x.append(points_x) # must be post total_points_y

    points_x = _numpy.vstack(total_points_x) if total_points_x else None
    points_y = _numpy.vstack(total_points_y) if total_points_y else None

    final_model = self._join_categorical_models(all_models, catvars[::2], points_x, points_y) if all_models else None

    return {'Generator': {"Submodels": final_info}}, points_x, points_y, final_status, final_model

  def _join_categorical_models(self, models_list, catvars_index, points_x, points_y):
    try:
      from ..gtapprox import utilities as _gta_utils
      return _gta_utils.Utilities.join_categorical_models(models=models_list, catvars=catvars_index,
                                                          sample={"x": points_x, "f": points_y}, comment="",
                                                          initial_options={}, logger=self._logger)
    except:
      exc_info = _sys.exc_info()
      if self._logger:
        _shared.Logger(self._logger, self.options._get('GTDoE/LogLevel').lower()).warn("Failed to join models for different combinations of categorical variables: " + str(exc_info[1]))
    return None

  def _enumerate_categorical_combinations(self, catvars, bounds, params, variables_name, technique_name):
    if not catvars or str(technique_name).lower() in ("fullfactorial", "fractionalfactorial", "orthogonalarray"):
      yield bounds, params, self.options.values, ""
      return

    # Note all variables with finite number of levels may be mapped to categorical option.
    # So, if var_types are specified then we enumerate only "true categorical" variables,
    # otherwise we enumerate all variables in catvars
    var_types = [_.lower() for _ in _shared.parse_json(self.options.get('/GTDoE/VariablesType'))] or ["categorical",]*len(bounds[0])
    true_catvars = []
    catvars_map = {}

    categorical_cardinality = 1
    max_categorical_cardinality = _numpy.iinfo(int).max
    for k, (i, levels) in enumerate(zip(catvars[::2], catvars[1::2])):
      n_levels = len(levels)
      # So, we check type if we can
      if var_types[i] != "categorical" or n_levels == 1:
        continue

      catvars_map[i] = 2*k+1 # get index of values list position
      true_catvars += [i, levels]
      if max_categorical_cardinality // categorical_cardinality > n_levels:
        categorical_cardinality *= n_levels
      else:
        categorical_cardinality = max_categorical_cardinality

    if categorical_cardinality == max_categorical_cardinality:
      raise _ex.InvalidProblemError("The cardinality of the cartesian product of categorical variables %s is too large" % (", ".join(variables_name[i] for i in true_catvars[::2]),))

    if categorical_cardinality == 1:
      yield bounds, params, self.options.values, ""
      return

    point_count = params.get('count', params.get('budget', 0))
    if point_count and categorical_cardinality > point_count:
      raise _ex.InvalidProblemError("The cardinality of the cartesian product of categorical variables %s is greater than the target number of feasible designs: %d > %d" % (", ".join(variables_name[i] for i in true_catvars[::2]), categorical_cardinality, point_count))

    init_x = params.get("init_x")
    init_y = params.get("init_y")
    adaptive_blackbox = params.get("blackbox")

    active_points = None if init_x is None else _numpy.zeros((len(init_x),), dtype=bool)

    sift_logger = _shared.Logger(self._logger, self.options._get('GTDoE/LogLevel').lower())

    oa_levels = _shared.parse_json(self.options._get("GTDOE/OrthogonalArray/LevelsNumber"))
    if oa_levels:
      # reset the number of levels for a newborn constants
      for i in true_catvars[::2]:
        oa_levels[i] = 0
      self.options.set("GTDOE/OrthogonalArray/LevelsNumber", oa_levels)

    local_catvars = [_ for _ in catvars] # make a copy

    watcher = self._get_watcher()
    for combination_index in xrange(categorical_cardinality):
      if watcher is not None and not watcher():
        return

      bounds_lower, bounds_upper = bounds
      local_params = {}

      combination_code = combination_index
      combination_name = []
      for catvar_index, catvar_levels in zip(true_catvars[::2], true_catvars[1::2]):
        combination_code, level_index = divmod(combination_code, len(catvar_levels))
        local_catvars[catvars_map[catvar_index]] = [catvar_levels[level_index],]
        bounds_lower[catvar_index] = bounds_upper[catvar_index] = catvar_levels[level_index]
        combination_name.append("%s=%s" % (variables_name[catvar_index], catvar_levels[level_index]))

      self.options.set("GTDoE/CategoricalVariables", local_catvars)

      if active_points is not None:
        active_points.fill(True)
        for catvar_index, catvar_levels in zip(local_catvars[::2], local_catvars[1::2]):
          active_points = _numpy.logical_and(active_points, init_x[:, catvar_index] == catvar_levels[0])
        if active_points.any():
          local_params["init_x"] = init_x[active_points]
          if init_y is not None:
            local_params["init_y"] = init_y[active_points]

      combination_point_count = point_count // (categorical_cardinality - combination_index)
      if adaptive_blackbox is not None:
        local_params["blackbox"] = adaptive_blackbox
        local_params["budget"] = combination_point_count
      else:
        local_params["count"] = combination_point_count

      point_count -= combination_point_count

      subproblem_name = "subproblem #%d/%d [%s]" % (combination_index + 1, categorical_cardinality, ", ".join(combination_name),)
      sift_logger.info("\nStarting %s design of subproblem %s\n" % (technique_name, subproblem_name,))

      yield (bounds_lower, bounds_upper), local_params, self.options.values, ", ".join(combination_name)

  def generate(self, bounds, **kwargs):
    """
    Generate a DoE.

    :keyword blackbox: adaptive DoE blackbox, optional
    :type blackbox: :class:`~da.p7core.blackbox.Blackbox`, :class:`.gtapprox.Model`, or :class:`.gtdf.Model`
    :param bounds: design space bounds (lower, upper)
    :type bounds: pair of iterables containing ``float`` values
    :keyword budget: blackbox budget (only for the blackbox-based adaptive DoE)
    :type budget: ``int``, ``long``
    :keyword count: the number of points to generate (not for the blackbox-based adaptive DoE; use *budget*), ``0`` means default
    :type count: ``int``, ``long``
    :keyword init_x: optional initial sample for the adaptive DoE, input part (values of variables)
    :type init_x: :term:`array-like`, 1D or 2D
    :keyword init_y: optional initial sample for the adaptive DoE, response part (function values)
    :type init_y: :term:`array-like`, 1D or 2D
    :keyword compatibility: keeps behavior compatible with versions 6.35 and below (*added in 6.36*)
    :type compatibility: ``bool``
    :return: DoE sample or sequential generator
    :rtype: :class:`.gtdoe.Result` by default, or :class:`.p7core.Result` if :arg:`compatibility` is ``False``

    .. versionadded:: 2.0
       sample-based adaptive DoE generation.

    .. versionadded:: 3.1
       the support for functions with multidimensional output in adaptive DoE.

    .. versionadded:: 3.1
       adaptive DoE can now handle NaN values in :arg:`init_y` and in :arg:`blackbox` output.

    .. versionadded:: 6.2
       sample-based adaptive DoE can now work in property-preservation mode.

    .. versionchanged:: 6.20
       :arg:`blackbox` may be a :class:`.gtapprox.Model` or a :class:`.gtdf.Model`.

    .. versionchanged:: 6.27
       in batch space-filling mode, :arg:`count` may be ``0`` to generate the default number of points if the used technique supports it.

    .. versionchanged:: 6.29
       space-filling techniques no longer raise an exception when it is not possible to generate :arg:`count` points; instead they issue a warning and return result, which contains all generated points.

    .. versionchanged:: 6.36
       added the :arg:`compatibility` parameter used to switch between two modes: ``True`` (default) keeps behavior from prior versions (6.35 and earlier), ``False`` reproduces :meth:`~da.p7core.gtdoe.Generator.build_doe()` behavior regarding categorical variables and changes return type to :class:`.p7core.Result`.

    .. deprecated:: 6.38
       kept for compatibility only and may be removed in future versions; use :meth:`~da.p7core.gtdoe.Generator.build_doe()` instead.

    Generates a DoE sample within :arg:`bounds` or
    creates an infinite sequential generator which works in the domain specified by :arg:`bounds`.
    The :arg:`bounds` argument also implicitly specifies the DoE dimension:
    it is equal to ``len(bounds[0])`` (naturally, ``len(bounds[0]) == len(bounds[1])``).

    This method has four call modes:

    #. sequential space-filling DoE,
    #. batch space-filling DoE,
    #. blackbox-based adaptive DoE, and
    #. sample-based adaptive DoE.

    The optional :arg:`compatibility` argument added in 6.36 changes behavior as follows:

    * If :arg:`compatibility` is ``True``, reproduces behavior of :meth:`~da.p7core.gtdoe.Generator.generate()` from versions 6.35 and below:

      * Returns a :class:`.gtdoe.Result` instance.
      * DoE techniques that support categorical variables generate certain combinations of such variables,
        that depend on :arg:`count` and the technique you use.
      * The Parametric Study, Box-Behnken, and low-discrepancy sequence (Sobol, Halton, Faure) techniques
        cannot be used with categorical variables.

    * If :arg:`compatibility` is ``False``, reproduces :meth:`~da.p7core.gtdoe.Generator.build_doe()` behavior:

      * Returns a :class:`.p7core.Result` instance.
      * All techniques are compatible with categorical variables.
      * If your design includes categorical variables, all techniques except the ones listed below run
        an independent subtask for each possible combination of categories,
        :arg:`count` is split evenly between those subtasks and must be greater
        than the number of subtasks (but may be ``0`` to use the default).
      * The following techniques keep their behavior from 6.35, regarding categorical variables:

        * Full Factorial --- generates all possible combinations of categories.
        * Fractional Factorial --- generates combinations as per the generating string
          (see :ref:`gtdoe_techniques_fractional_factorial` for details).
        * Orthogonal Array --- selects certain combinations to generate an array of the required type
          (see :ref:`gtdoe_techniques_oa` for details).

    .. rubric:: Sequential

    The sequential space-filling mode requires :arg:`bounds` only
    and is usable only if :arg:`compatibility` is ``True`` (default).

    In this mode, returned result does not contain a data sample.
    Instead, it is used as an infinite points generator
    (see :meth:`~da.p7core.gtdoe.Result.take()`).
    This mode is supported only by sequential techniques:

    * sequential uniform random generation (random sequence)
    * Sobol sequence
    * Halton sequence
    * Faure sequence

    .. rubric:: Batch

    For batch space-filling mode, specify :arg:`bounds` and :arg:`count`.

    In this mode, :ref:`GTDoE/Technique <GTDoE/Technique>` may specify any technique
    except ``"Adaptive"``, which switches to the sample-based adaptive DoE,
    and ``"AdaptiveDesign"``, which is supported only by
    :meth:`~da.p7core.gtdoe.Generator.build_doe()`.

    For the space-filling techniques, ``0`` is a valid :arg:`count` value,
    which means generating a sample of the default size:

    * Full Factorial ---
      default is the minimum required to generate a sample that includes
      all levels of variables, which have levels specified,
      and 2 levels for each variable, which has no specified levels.
    * Fractional Factorial ---
      default size is defined by the generating string;
      if you do not specify the generating string or main factors,
      default is the minimum possible sample size
      for the given number of variables (dimension).
    * Parametric Study ---
      default is the minimum possible sample size
      for the given number of variables (dimension).
    * Optimal Design ---
      default is the minimum sample size suitable for the target RSM model type
      (set by :ref:`GTDoE/OptimalDesign/Model <GTDoE/OptimalDesign/Model>`).
    * Box-Behnken ---
      generated sample size is defined by the number of variables,
      using default is recommended.
    * Orthogonal Array ---
      default is the minimum size of a proper orthogonal array for the given number of variables.
    * Other space-filling techniques ---
      default is an internal estimate depending on the design space dimension
      (the number of variables).

    Note that in certain cases it is not possible to generate as many as :arg:`count` points ---
    for example, if all variables are discrete, a full factorial DoE has fixed size.
    In such cases, only the possible number of points are generated and included in result,
    and GTDoE issues a warning.

    .. rubric:: Adaptive Blackbox-Based

    For the blackbox-based adaptive DoE, specify *blackbox*, *bounds* and *budget*.
    The generator switches to the blackbox-based adaptive DoE mode automatically.
    The :ref:`GTDoE/Technique<GTDoE/Technique>` option is ignored in the blackbox-based mode.

    Optionally you can also specify an initial sample:
    either *init_x* only (in this case the generator requests response values from the blackbox),
    or both *init_x* and *init_y*.
    In general form, *init_x* and *init_y* are 2D array-likes.
    1D samples are supported as a simplified form for the case of 1D input and/or response.

    In this mode, *bounds* are intended to contract the point generation area.
    Due to this, the generator does not automatically apply the bounds set for blackbox variables
    (see :meth:`da.p7core.blackbox.Blackbox.add_variable()`).
    You have to ensure that the generator bounds at least intersect with the blackbox variable bounds,
    because DoE points are generated only in the area of intersection. If the areas of the generator
    and blackbox bounds do not intersect, the :meth:`~da.p7core.gtdoe.Generator.generate()` raises an exception.

    If you just want the same bounds for the generator and the blackbox, specify the
    :meth:`~da.p7core.blackbox.Blackbox.variables_bounds()` return value as the *bounds* argument.

    .. rubric:: Adaptive Sample-Based

    The sample-based adaptive DoE works in two modes:

    #. *Filling mode*,
    #. *Property-preservation mode*.

    The *filling mode* aims to add new points to the design according to the selected criterion.
    The *property-preservation mode* aims to preserve certain space-filling property of the given initial design.

    **Filling mode**

    *Filling mode* aims to add new points to the design according to the selected criterion.

    To run the sample-based adaptive DoE in the *filling mode*,
    set :ref:`GTDoE/Technique<GTDoE/Technique>` to ``"Adaptive"`` and specify *bounds* and *count*.
    Note that unlike the blackbox-based adaptive DoE,
    the generator does not switch to the sample-based adaptive DoE mode automatically.

    The initial sample is optional in sample-based adaptive DoE,
    however the technique behavior depends on it.
    The initial sample may either include values of variables (*init_x* only),
    or include both variable and response values (*init_x* and *init_y*),
    or be empty.
    Running with an empty initial sample or with *init_x* only
    effectively limits adaptive DoE to uniform generation mode,
    and in this case valid settings for :ref:`GTDoE/Adaptive/Criterion<GTDoE/Adaptive/Criterion>`
    include only ``"Uniform"`` and ``"Auto"`` (and the latter defaults to ``"Uniform"``).
    Other criteria are based on approximation models
    and require a response sample (*init_y*) for model training.

    .. note::

       To simplify, if you run sample-based adaptive DoE
       without an initial sample or with :arg:`init_x` only, leave
       :ref:`GTDoE/Adaptive/Criterion <GTDoE/Adaptive/Criterion>` default (``"Auto"``).

    **Property-preservation mode**

    *Property-preservation mode* aims to preserve certain space-filling property of the given initial design.
    This mode is supported by the LHS, OLHS, and OA techniques.
    To run the sample-based adaptive DoE in the *property-preservation mode*,
    select one of the supported techniques with :ref:`GTDoE/Technique<GTDoE/Technique>`
    and specify :arg:`bounds`, :arg:`count` and :arg:`init_x`.

    In this mode, GTDoE preserves properties of the initial sample when possible:

    * For LHS: if the size of initial sample :arg:`init_x` is a factor of the additional sample size :arg:`count`,
      then the union of the initial design and generated design is also LHS.
    * For OA: if the initial sample is an orthogonal array with correct values of variables,
      the final sample is also an orthogonal array.
      The type of the final array (strict, balanced, or irregular) depends on :arg:`count`.
      With high enough :arg:`count`,
      it is possible that the final sample size exceeds the size of a full factorial sample.
      In this case,
      one or more full factorial samples are generated
      until the remaining count is less than the full factorial size,
      and the remainder is used to generate an orthogonal array.
      The final sample then is a union of one or more full factorial samples
      and an orthogonal array supplementing them to reach the requested sample size.

    .. rubric:: Modes Summary

    Call modes and valid argument combinations:

    +--------------------------------+------------------------------------------------------+
    |  Mode                          |  Arguments                                           |
    +================================+======================================================+
    |  Sequential space-filling DoE  |  *bounds*                                            |
    +--------------------------------+------------------------------------------------------+
    |  Batch space-filling DoE       |  *bounds*, *count*                                   |
    +--------------------------------+------------------------------------------------------+
    |  Blackbox-based adaptive DoE,  |  *blackbox*, *bounds*, *budget*                      |
    |  no initial sample             |                                                      |
    +--------------------------------+------------------------------------------------------+
    |  Blackbox-based adaptive DoE   |  *blackbox*, *bounds*, *budget*, *init_x*            |
    |  with an initial DoE only      |                                                      |
    +--------------------------------+------------------------------------------------------+
    |  Blackbox-based adaptive DoE   |  *blackbox*, *bounds*, *budget*, *init_x*, *init_y*  |
    |  with an input/response sample |                                                      |
    +--------------------------------+------------------------------------------------------+
    |  Sample-based adaptive DoE     |  *bounds*, *count*, *init_x*, *init_y*               |
    |  with a training sample        |                                                      |
    +--------------------------------+------------------------------------------------------+
    |  Sample-based adaptive DoE     |  *bounds*, *count*, *init_x*                         |
    |  with an initial DoE only      |                                                      |
    +--------------------------------+------------------------------------------------------+
    |  Adaptive DoE in uniform       |  *bounds*, *count*                                   |
    |  sampling mode                 |                                                      |
    +--------------------------------+------------------------------------------------------+

    """
    self._log_build_stamp(options=kwargs.get("options"))
    with _shared.sigint_watcher(self):
      if "blackbox" in kwargs:
        problem = kwargs["blackbox"]
        with _shared._suppress_history(problem=problem):
          configuration = self._read_limited_evaluations_configuration(options=kwargs.get("options"))
          with _limited_evaluations(problem=problem, watcher_ref=self._get_watcher, configuration=configuration) as blackbox:
            kwargs = dict((_, kwargs[_]) for _ in kwargs)
            kwargs["blackbox"] = blackbox
            return self._do_generate(bounds, **kwargs)
      else:
        return self._do_generate(bounds, **kwargs)

  def _do_generate(self, bounds, **kwargs):
    compatibility = kwargs.pop("compatibility", True)
    bounds = self._preprocess_bounds(bounds)
    count, blackbox, budget, options, init_x, init_y = self._preprocess_kwargs(bounds, **kwargs)

    size_x = bounds.shape[1]
    result_blackbox, catvars = None, []
    with _shared._scoped_options(self, options):
      sift_logger = _shared.Logger(self._logger, self.options._get('GTDoE/LogLevel').lower())

      technique_name = self.options._get('GTDoE/Technique')
      # Blackbox mode cannot be changed in this method
      if blackbox:
        if str(technique_name).lower() not in ('auto', 'adaptive'):
          sift_logger.warn("The GTDoE/Technique=%s option is ignored in the blackbox-based mode." % (technique_name,))
        self.options.set("GTDoE/Technique", "Adaptive")
        sift_logger.info('Using the Adaptive technique because the design defines adaptive responses.')
        self.report_ignore_ig(problem=kwargs.get("blackbox"), technique=technique_name, logger=sift_logger) # intentionally get the original blackbox
      elif str(technique_name).lower() == 'auto':
        count, extra_options = self._select_auto_technique(blackbox=bounds, count=(count or 0), sample_f=init_y, compatibility=True, logger=sift_logger)
        self.options.set(extra_options)
      else:
        sift_logger.info('Using the %s technique specified by the GTDoE/Technique option.' % (technique_name,))

      # Re-read technique because it might be resolved
      technique_name = self.options._get('GTDoE/Technique')
      technique_test = technique_name.lower()

      catvars = _shared.parse_json(self.options._get('GTDoE/CategoricalVariables'))

      params = {"count": count, "blackbox": blackbox, "budget": budget}

      init_x, valid_initial_points, result_blackbox = self._preprocess_initial_sample((blackbox or bounds), catvars, technique_name, init_x, init_y)
      self._assign_initial_sample_params(params=params, init_x=init_x, init_y=init_y, valid_points=valid_initial_points)

      if compatibility:
        info, points_x, points_f, status, model = self._gen(bounds, legacy=False, options=options, **params)
      else:
        categorical_results = []
        variables_names = result_blackbox.variables_names() if result_blackbox else [("x"+str(i)) for i in range(size_x)]

        for local_bounds, local_params, local_options, categorical_signature in self._enumerate_categorical_combinations(catvars, bounds, params, variables_names, technique_name):
          with _shared._scoped_options(self, local_options, keep_options=None):
            categorical_results.append(self._gen(local_bounds, legacy=False, options=None, validation_mode=False, **local_params) + (categorical_signature,))

        info, points_x, points_f, status, model = self._combine_categorical_combinations(categorical_results, catvars)

      if points_f is not None and not points_f.size:
        points_f = None

      if points_x is None or (compatibility and status == _status.IN_PROGRESS): # generator mode, old result, no dups by definition
        return Result(info, points_x, points_f, (None if status == _status.IN_PROGRESS else status), model=model)
      elif status == _status.IN_PROGRESS:
        raise _ex.WrongUsageError("Sequential space-filling is not compatible with matrix output.")

      solutions_table, fields = self._collect_solutions_table(points_x, points_f, result_blackbox, init_x, init_y, None)
      solutions_table = self._remove_dups_from_solutions_table(solutions_table, count, options)

      if compatibility:
        return Result(info, solutions_table[:, :size_x],
                      (solutions_table[:, size_x:] if points_f is not None else None),
                      (None if status == _status.IN_PROGRESS else status), model=model)

      solutions_table, fields, constraints_tol = self._prepare_new_result_data(result_blackbox, solutions_table, fields, None)

      designs, solutions_subsets, result_options = None, None, None # any exception here is ignorable

      try:
        result_options = _adaptive_fill._translate_general_options(self)
        if technique_test == 'ise':
          result_options['/GTOpt/EvaluateResultSubset'] = 'All' # force evaluation of all points (note intentional gtopt prefix)

        initial_sample, initial_fields = self._postprocess_initial_sample(result_blackbox, solutions_table, fields, init_x, init_y, None)
        designs = _designs._solutions_to_designs(result_blackbox, solutions_table, fields, _slice_or_none(initial_sample, initial_fields, "x"),
                                                  _slice_or_none(initial_sample, initial_fields, "f"), _slice_or_none(initial_sample, initial_fields, "c"),
                                                  constraints_tol)
        solutions_table, fields, solutions_subsets = _postprocess_solution_samples(default_solution=solutions_table, default_fields=dict(fields), initial_sample=initial_sample, initial_fields=initial_fields)
      except:
        pass

      result = _Result(status, info, solutions_table, dict(fields),
                      (_weakref.ref(result_blackbox) if result_blackbox is not None else None),
                        model=model, designs=designs, solutions_subsets=solutions_subsets, finalize=False)
      return result._finalize(problem=result_blackbox, auto_objective_type=("Adaptive" if technique_test == "adaptive" else "Evaluate"), options=result_options, logger=sift_logger)

  def _preprocess_bounds(self, bounds):
    if not _shared.is_sized(bounds) or len(bounds) != 2 or _shared.get_size(bounds[0]) != _shared.get_size(bounds[1]):
      raise _ex.InvalidProblemError('Wrong bounds structure!')
    return _shared.as_matrix(bounds, shape=(2, None), name="Design space bounds (lower, upper)")

  def _preprocess_kwargs(self, bounds, **kwargs):
    options = None
    count = None # None is "not set", 0 is "auto"
    budget = None
    blackbox = None
    sample_x = None
    sample_f = None

    private_blackbox = None

    recognized = ['options', 'count', 'blackbox', 'init_x', 'init_y', 'budget']
    for keyword, value in kwargs.items():
      if keyword not in recognized:
        if keyword == '_blackbox': #hidden kw - must be eliminated
          private_blackbox = value
        else:
          raise TypeError(("Keyword argument '%s' is not recognized!\nAvailable flags are:\n'"
                          + "', '".join(recognized) + "'") % keyword)

      if keyword == recognized[0]:
        _shared.check_concept_dict(value, recognized[0])
        options = value
      if keyword == recognized[1]:
        _shared.check_concept_int(value, recognized[1])
        count = int(value)
      if keyword == recognized[2]:
        blackbox = value
      if keyword == recognized[3] and value is not None:
        sample_x = _shared.as_matrix(value, shape=(None, len(bounds[0])), name="Initial sample containing values of variables ('init_x' argument)")
        if not len(sample_x):
          sample_x = None
      if keyword == recognized[4] and value is not None:
        sample_f = _shared.as_matrix(value, detect_none=True, name="Initial sample of objective function values ('init_y' argument)")
        if not len(sample_f):
          sample_f = None
      if keyword == recognized[5]:
        _shared.check_concept_int(value, recognized[5])
        budget = value

    if sample_f is not None:
      if sample_x is None:
        raise ValueError("Initial sample of objective function values ('init_y') requires initial sample containing values of variables ('init_x')")
      elif len(sample_x) != len(sample_f):
        raise ValueError("Initial sample of objective function values ('init_y') must have the same length as the initial sample containing values of variables ('init_x'): %d != %d" % (len(sample_f), len(sample_x)))

    if count is not None and budget is not None:
      raise _ex.GTException('Both \'count\' and \'budget\' arguments cannot be specified at the same time')

    if blackbox is not None and budget is None:
      raise _ex.InvalidProblemError('The "blackbox" argument requires the "budget" argument. Use 0 for automatic budget selection.')

    if not options:
      options = {}

    if blackbox is not None or private_blackbox is not None:
      with _shared._scoped_options(self, options):
        catvars = _shared.parse_json(self.options._get('GTDoE/CategoricalVariables'))

        if blackbox is not None:
          blackbox, catvars, warns, var_types = _bbconverter.preprocess_blackbox(blackbox, _bbconverter._make_location('Adaptive'), catvars, constraints_supporter="AdaptiveDesign")
        else: # implies private_blackbox is not None
          private_blackbox, catvars, warns, var_types = _bbconverter.preprocess_blackbox(private_blackbox, _bbconverter._make_location('Adaptive'), catvars, constraints_supporter="AdaptiveDesign")

        self._validate_initial_sample((blackbox or private_blackbox), sample_x=sample_x, sample_f=sample_f, sample_c=None)

        options['GTDoE/CategoricalVariables'] = catvars
        if var_types:
          options['/GTDoE/VariablesType'] = var_types
        for warn_message in (warns or []):
          _shared.Logger(self._logger, self.options._get('GTDoE/LogLevel').lower()).warn(warn_message)

    return count, blackbox, budget, options, sample_x, sample_f

  @staticmethod
  def _assign_initial_sample_params(params, init_x, init_y, valid_points):
    if init_x is None:
      return

    init_x = init_x[valid_points]
    if not init_x.size:
      return

    params['init_x'] = init_x

    if init_y is not None:
      params['init_y'] = init_y[valid_points]


  def _preprocess_initial_sample(self, blackbox, catvars, technique_name, sample_x, sample_f):
    result_blackbox = _bbconverter._make_result_compatible(blackbox, catvars, location=_bbconverter._make_location(technique_name),
                                                            size_f=(sample_f.shape[1] if sample_f is not None else 0))

    if result_blackbox is None or sample_x is None:
      return sample_x, slice(0 if sample_x is None else len(sample_x)), result_blackbox

    sample_x, valid_initial_points = result_blackbox._valid_input_points(sample_x)

    if self._logger:
      n_valid, n_original = len(sample_x[valid_initial_points]), len(sample_x)
      if n_valid < n_original:
        _shared.Logger(self._logger, self.options._get('GTDoE/LogLevel').lower()).warn("%d invalid points encountered in the initial sample" % ((n_original - n_valid),))

    # Even invalid points with known response may be useful,
    # unless technique does not support it at all.
    technique_test = str(technique_name).lower()
    if technique_test in ("olhs",):
      # all points must be explicitly valid
      return sample_x, valid_initial_points, result_blackbox
    elif technique_test in ("adaptive", "adaptivedesign"):
      # Use invalid points with known responses
      if sample_f is not None:
        useful_points = ~_numpy.isnan(sample_f).any(axis=1)
        useful_points[valid_initial_points] = True
        valid_initial_points = useful_points
      return sample_x, valid_initial_points, result_blackbox
    # consider all points are valid
    return sample_x, slice(len(sample_x)), result_blackbox

  @staticmethod
  def _validate_initial_sample(problem, sample_x, sample_f, sample_c):
    if sample_f is not None and sample_f.size:
      try:
        if sample_f.shape[1] != _read_property_or_method(problem, "size_f"):
          raise ValueError("Initial sample of objective function values must conform the number of objectives: %d != %d." % (sample_f.shape[1], problem.size_f()))
      except AttributeError:
        exc_info = _sys.exc_info()
        _shared.reraise(_ex.UnsupportedProblemError, "Initial sample of objective function values requires problem with objectives.", exc_info[2])

    if sample_c is not None and sample_c.size:
      try:
        if sample_c.shape[1] != _read_property_or_method(problem, "size_c"):
          raise ValueError("Initial sample of constraint function values must conform the number of constraints: %d != %d." % (sample_c.shape[1], problem.size_c()))
      except AttributeError:
        exc_info = _sys.exc_info()
        _shared.reraise(_ex.UnsupportedProblemError, "Initial sample of constraint function values requires constrained problem.", exc_info[2])

    try:
      problem._validate_linear_responses(sample_x, sample_f, sample_c)
    except AttributeError:
      # Intentionally do nothing
      pass

  def report_ignore_ig(self, problem, technique, logger):
    try:
      initial_guess = problem.initial_guess()
      if initial_guess is not None:
        initial_guess = ", ".join(("%s=%s" % _) for _ in zip(problem.variables_names(), initial_guess))
        logger.warn("The initial guess (%s) is ignored by the %s technique." % (initial_guess, technique))
    except:
      pass # no problem, this is not a generic problem

  @staticmethod
  def _collect_solutions_table(new_x, new_y, problem, init_x, init_f, init_c):
    if problem is not None:
      size_x, size_f, size_c = problem.size_x(), problem.size_f(), problem.size_c()
    else:
      size_x = new_x.shape[1]
      size_f = new_y.shape[1] if new_y is not None else init_f.shape[1] if init_f is not None else 0
      size_c = init_c.shape[1] if init_c is not None else 0

    fields, base_offset = [("x", slice(0, size_x))], size_x
    base_offset = _append_field_spec(fields, base_offset, "f", size_f)
    base_offset = _append_field_spec(fields, base_offset, "c", size_c)

    solutions_table = _shared._filled_array((new_x.shape[0], size_x+size_f+size_c), _shared._NONE)
    solutions_table[:, :size_x] = new_x[:]
    if new_y is not None:
      solutions_table[:new_y.shape[0], size_x:(size_x+size_f)] = new_y[:]

    if init_f is not None or init_c is not None:
      initial_sample = _shared._filled_array((init_x.shape[0], size_x+size_f+size_c), _shared._NONE)
      initial_sample[:, :size_x] = init_x[:]
      if init_f is not None:
        initial_sample[:, size_x:(size_x+size_f)] = init_f[:]
      if init_c is not None:
        initial_sample[:, -size_c:] = init_c[:]

      _designs._harmonize_datasets_inplace(problem, dict(fields), solutions_table, initial_sample)

    solutions_table[-new_x.shape[0]:, :size_x] = new_x[:]
    if new_y is not None:
      solutions_table[-new_x.shape[0]:, size_x:(size_x+size_f)] = new_y[:]

    return solutions_table, fields

  def _postprocess_initial_sample(self, problem, solutions_table, fields, sample_x, sample_f, sample_c):
    if sample_x is None:
      return None, dict()

    slices = dict(_ for _ in fields)

    # Evaluate points in initial sample. For the sake of DRY, convert it to solutions table and reuse _prepare_new_result_data
    initial_sample = _shared._filled_array((sample_x.shape[0], solutions_table.shape[1]), _shared._NONE)
    initial_sample[:, slices["x"]] = sample_x[:]

    if not ("f" in slices or "c" in slices):
      return initial_sample, dict(_ for _ in fields)

    if sample_f is not None:
      initial_sample[:, slices["f"]] = sample_f[:]

    if sample_c is not None:
      initial_sample[:, slices["c"]] = sample_c[:]

    # copy data back from new points to initial points because in case of Adaptive tech
    # the new points can contain evaluated responses
    _designs._harmonize_datasets_inplace(problem, slices, solutions_table, initial_sample)

    # evaluate holes if any
    initial_sample, fields, _ = self._prepare_new_result_data(problem, initial_sample, fields, self.options.values)
    return initial_sample, dict(_ for _ in fields)

  def _remove_dups_from_solutions_table(self, original_solutions_table, count, options):
    solutions_table = _designs._select_unique_rows(original_solutions_table, 0)
    if len(solutions_table) < len(original_solutions_table) and count and len(solutions_table) != count:
      with _shared._scoped_options(self, options):
        technique_name = self.options._get('GTDoE/Technique')
        sift_logger = _shared.Logger(self._logger, self.options._get('GTDoE/LogLevel').lower())
        sift_logger.warn("`%s` technique generated %d unique points, %d points were requested." % (technique_name, len(solutions_table), count))

    return solutions_table

  def _prepare_new_result_data(self, problem, solutions_table, fields, options):
    with _shared._scoped_options(self, options):
      constraints_tol = _adaptive_fill._read_constraints_tolerance(self)
      fields = [_ for _ in fields] # make a copy to avoid side effects

      if not problem:
        return solutions_table, fields, constraints_tol

      size_f, size_c = problem.size_f(), problem.size_c()
      if not size_f and not size_c:
        return solutions_table, fields, constraints_tol

      slices = dict(_ for _ in fields)
      assert "x" in slices # paranoid

      base_offset = solutions_table.shape[1] # memorize baseline (actually it must be size_x + size_f)

      if size_f and "f" not in slices:
        solutions_table = _shared._pad_columns(solutions_table, size_f, _shared._NONE)
        base_offset = _append_field_spec(fields, base_offset, "f", size_f)
        slices["f"] = fields[-1][1]

      if size_c and "c" not in slices:
        solutions_table = _shared._pad_columns(solutions_table, size_c, _shared._NONE)
        base_offset = _append_field_spec(fields, base_offset, "c", size_c)
        slices["c"] = fields[-1][1]

      return solutions_table, fields, constraints_tol

  def _gen(self, bounds, legacy, count=None, blackbox=None, budget=None, options=None, init_x=None, init_y=None, validation_mode=False):
    #fan demolition NOTE
    #In sequential mode we return generator, because user may want to reuse origin Generator obj for other purposes, returned generator has to be detachable from Generator obj,
    #Thus this function must be called from internally created Generator object only (for sequential use, yet for matrix use it can be called from anywhere with options preseravation).
    #But then there is not need in options preseravation.

    bounds = self._preprocess_bounds(bounds) # excessive, paranoidal re-check

    if count is not None and budget is not None:
      raise _ex.GTException('Both \'count\' and \'budget\' arguments cannot be specified at the same time')

    with _shared._scoped_options(self, options):
      try:
        if options is not None:
          self.options.set(options)

        catvars = _shared.parse_json(self.options._get('GTDoE/CategoricalVariables'))
        if catvars and not _shared.parse_json(self.options._get('/GTDoE/VariablesType')):
          var_types = ["Continuous",]*_shared.get_size(bounds[0])
          for i in catvars[::2]:
            var_types[i] = "Categorical"
          self.options.set('/GTDoE/VariablesType', var_types)

        count = self._update_count(bounds=bounds, count=count, blackbox=blackbox, budget=budget, init_x=init_x, init_y=init_y)

        sift_logger = _shared.Logger(self._logger, self.options._get('GTDoE/LogLevel').lower())

        if legacy:
          sift_logger.warn('Method Generator.generate() is deprecated. Use Generator.build_doe() instead.')

        doe_technique = self.options._get('GTDoE/Technique').lower()

        if count == 0 and doe_technique in ("faureseq", "haltonseq", "randomseq", "sobolseq", "lhs", "olhs", "adaptive"):
          count = self._heuristic_design_size(**self._heuristic_design_size_parameters(bounds))
          sift_logger.info("No target size is given. Using heuristic target size %d, since %s technique does not has natural design size." % (count, _get_technique_official_name(doe_technique)))

        if count is None and doe_technique not in ("auto", "faureseq", "haltonseq", "randomseq", "sobolseq", "ise"):
          raise _ex.InvalidProblemError('The %s technique requires explicit specification of points number.' % _get_technique_official_name(doe_technique))
        elif blackbox and doe_technique in ('fractionalfactorial', 'lhs', 'olhs'):
          # The message is the same as in C++ code of GenericTools
          raise _ex.InvalidProblemError('Technique `%s` cannot be used in blackbox mode.' % _get_technique_official_name(doe_technique))
        elif doe_technique == 'ise':
          return self._initial_sample_evaluation(blackbox=blackbox, sample_x=init_x, sample_f=init_y, validation_mode=validation_mode, sift_logger=sift_logger)
        elif doe_technique == 'fractionalfactorial':
          return self.__generate_doe_with_python(bounds, count, None, validation_mode=validation_mode) #init_x is used only for *lhs
        elif doe_technique == 'olhs' and self._apply_categorical_olhs(catvars, bounds, count or 0):
          return self._categorical_olhs(bounds, count, init_x, validation_mode=validation_mode)
        elif (doe_technique in ('lhs', 'olhs')) and (init_x is not None):
          return self.__generate_doe_with_python(bounds, count, init_x, validation_mode=validation_mode)

        bounds = _shared.convertToMatrix(bounds, vectorSize=_shared.get_size(bounds[0]), vectorsNumber=2, dataType=_ctypes.c_double, name="DoE generation bounds")

        if blackbox:
          return self._backend.adaptive_sample(count, bounds, blackbox, init_x, init_y, validation_mode=validation_mode)
        elif count is None:
          if validation_mode:
            return _adaptive_fill._report_validation_succeeded(None, None, None, None)
          return self._backend.start_sequence(bounds)
        elif count > 0:
          return self._backend.generate_sample(count, bounds, init_x, init_y, validation_mode=validation_mode)
        elif count == 0: # Batch mode with automatic budget (count=0) is available for listed tehcniques
          if doe_technique in ('auto', 'boxbehnken', 'fractionalfactorial', 'fullfactorial', 'optimaldesign', 'orthogonalarray', 'parametricstudy', 'diagonal'):
            return self._backend.generate_sample(count, bounds, init_x, init_y, validation_mode=validation_mode)
          else: # Techniques are not compatible with auto budget mode: 'lhs', 'olhs', 'adaptive', 'adaptivedesign'
            raise _ex.InvalidProblemError('The number of requested points must be greater than zero for %s technique' % _get_technique_official_name(doe_technique))
      except Exception:
        _, exc_val, exc_tb = _sys.exc_info()
        if isinstance(exc_val, _ex.ExceptionWrapper):
          exc_val.set_prefix("DoE generation failed, cause ")
        _shared.reraise(type(exc_val), exc_val, exc_tb)

  def _fill_adaptively(self, blackbox, count, search_intensity=_numpy.nan, level=None,
                      init_x=None, init_y=None, sample_x=None, sample_f=None, sample_c=None, time_limit=0, options={}):
    """
    Generate a DoE in a target-oriented way.

    :keyword blackbox: adaptive DoE blackbox, optional
    :type blackbox: :class:`~da.p7core.gtdoe.ProblemGeneric`
    :keyword count: the number of points to generate
    :type count: ``int``
    :keyword search_intensity: is between [0, 1] or NaN, determines how good points are clustered near target. NaN means heuristic selection of this value.
    :type search_intensity: `float`
    :keyword level: a target level for the level-set problem
    :type level: ``float``
    :keyword init_x: optional initial sample containing values of variables, prohibit *sample_x*
    :type init_x: :term:`array-like`, 1D or 2D
    :keyword init_y: optional initial sample or responses (function and constraint values), requires *sample_x*
    :type init_y: :term:`array-like`, 1D or 2D
    :keyword sample_x: optional initial sample containing values of variables, prohibit *init_x*
    :type sample_x: :term:`array-like`, 1D or 2D
    :keyword sample_f: optional initial sample of objective function values, requires *sample_x*
    :type sample_f: :term:`array-like`, 1D or 2D
    :keyword sample_c: optional initial sample of constraint function values, requires *sample_x*
    :type sample_c: :term:`array-like`, 1D or 2D
    :keyword options: doe options (not required, amends the options set through the :attr:`~da.p7core.gtdoe.Generator.options` interface)
    :type options: ``dict``
    :keyword level: a time limit
    :type level: None, ``float``
    :return: DoE sample
    :rtype: class`~da.p7core.gtdoe.adaptive_fill_aux.Result`



    Generates a DoE sample within bounds provided by *blackbox* definition. The size of sample is equal to *count*.

    The blackbox may provides constraints and objectives.

    * If constraints are provided generated DoE is trend to be in close to feasible area.
    * If objectives are provided, DoE searchs "points of interest" for such objectives.
      * If there is only one objective and *level* is set, then "points of interest" are points where the objective is close to given level value.
      * If the number of objectives more then one or *level* is not set, then "points of interest" are points where internal models are diverse.




    """
    _shared.check_type(blackbox, 'fill_adaptively argument', ProblemGeneric)
    _shared.check_concept_int(count, 'fill_adaptively argument')
    _shared.check_concept_numeric(search_intensity, 'fill_adaptively argument')
    _shared.check_concept_numeric(time_limit, 'fill_adaptively argument')
    _shared.check_concept_dict(options, 'fill_adaptively argument')
    if level is not None:
      _shared.check_concept_numeric(level, 'fill_adaptively argument')

    with _shared._scoped_options(self):
      return _adaptive_fill._fill(self, blackbox, count, search_intensity, level, init_x, init_y, sample_x, sample_f, sample_c, time_limit, options)

  def _update_count(self, bounds, count, blackbox, budget, init_x, init_y):
    if blackbox:
      if not budget or budget < 0: # note budget may be None
        tech = self.options._get('GTDoE/Technique')
        if tech.lower() in ("ise", "adaptive"):
          budget = 0
        else:
          raise _ex.InvalidProblemError('The "blackbox" argument requires the "budget" argument unless the generation technique is ISE or Adaptive.')
      count = budget
      if blackbox.size_x() != _shared.get_size(bounds[0]):
        raise _ex.InvalidProblemError('Inconsistent blackbox and bounds dimension')
      if init_x is not None:
        if blackbox.size_x() != init_x.shape[1]:
          raise _ex.InvalidProblemError('Inconsistent initial X-set and blackbox input dimension')
      if init_y is not None:
        if init_x is None or init_x.shape[0] != init_y.shape[0]:
          raise _ex.InvalidProblemError('Inconsistent initial X-set and target function values output size')
        if blackbox.size_f() != init_y.shape[1]:
          raise _ex.InvalidProblemError('Inconsistent target function values and blackbox output dimension')
    elif count is not None:
      if count >= 0:
        if init_x is not None:
          if init_x.shape[1] != _shared.get_size(bounds[0]):
            raise _ex.InvalidProblemError('Inconsistent initial X-set and bounds dimension')
        if init_y is not None:
          if init_x is None:
            raise _ex.InvalidProblemError('Initial Y-set requires initial X-set')
          elif init_x.shape[0] != init_y.shape[0]:
            raise _ex.InvalidProblemError('Inconsistent initial X-set and Y-set values output size')
      elif count < 0:
        raise _ex.InvalidProblemError('The number of requested points must be greater than or equal to zero')
    return count

  def _apply_categorical_olhs(self, categorical_variables, bounds, count):
    if not count:
      return False

    if any(len(levels) > 1 for levels in categorical_variables[1::2]):
      return True

    integer_variables = [i for i, kind in enumerate(_shared.parse_json(self.options._get('/GTDoE/VariablesType'))) \
                         if kind.lower() == "integer" and i not in categorical_variables[::2]]

    return any((int(bounds[1][i]) - int(bounds[0][i]) + 1) < count for i in integer_variables)

  def _categorical_olhs(self, bounds, count, init_x, validation_mode=False):
    sift_logger = _shared.Logger(self._logger, self.options._get('GTDoE/LogLevel').lower())

    categorical_variables = list(_shared.parse_json(self.options._get('GTDoE/CategoricalVariables')))

    intvars = [i for i, kind in enumerate(_shared.parse_json(self.options._get('/GTDoE/VariablesType'))) \
                if kind.lower() == "integer" and i not in categorical_variables[::2]]
    integer_variables = []

    for i in intvars:
      n_levels = int(bounds[1][i]) - int(bounds[0][i]) + 1
      if n_levels < count:
        categorical_variables.extend((i, _numpy.arange(int(bounds[0][i]), int(bounds[1][i]) + 1).tolist()))
      else:
        if (n_levels % count):
          sift_logger.warn("Integer variable #%d may violate LHS property: the number of levels available (%d) is not a multiple of the number of points requested (%d)." % (i, n_levels, count))
        integer_variables.append(i)

    assert categorical_variables or integer_variables

    points_dim = len(bounds[0])
    catvars = [_ for _ in categorical_variables[::2]]
    convars = [k for k in range(points_dim) if k not in catvars]
    categorical_variables[::2] = range(len(catvars))

    with _shared._scoped_options(self) as saved_options:
      self.options.reset()
      self.options.set(dict((k, saved_options[k]) for k in saved_options if k.lower() not in ("/gtdoe/variablestype",)))

      if convars:
        self.options.set("GTDoE/CategoricalVariables", [])
        self.options.set("/GTDoE/VariablesType", _shared.write_json([("Integer" if i in integer_variables else "Continuous") for i in convars]))

        sift_logger.info("\nFirst stage: generating OLHS design for the continuous variables %s\n " % convars)
        params = {} if init_x is None else {"init_x": init_x[:, convars]}
        info, points_con, points_y_con, status_con, _ = self._gen(([bounds[0][k] for k in convars], [bounds[1][k] for k in convars]), legacy=False, count=count, validation_mode=validation_mode, **params)
        if not catvars:
          return info, points_con, points_y_con, status_con, None
        sift_logger.info("\nSecond stage: generating OLHS design for the categorical variables %s\n " % catvars)

      self.options.set("GTDoE/Technique", "OrthogonalArray")
      self.options.set("GTDoE/OrthogonalArray/ArrayType", "Irregular")
      self.options.set("/GTDoE/OrthogonalArray/ComplementFullFactorial", not convars)
      self.options.set("GTDoE/CategoricalVariables", _shared.write_json(categorical_variables))
      self.options.set("/GTDoE/VariablesType", _shared.write_json(["Categorical"]*len(catvars)))

      if not convars:
        current_options = self.options.values
        info = {"Generator": {"Options": dict((k, current_options[k]) for k in current_options if not k.startswith("//"))}}

      params = {} if init_x is None else {"init_x": init_x[:, catvars]}
      _, points_cat, points_y_cat, status_cat, _ = self._gen(([bounds[0][k] for k in catvars], [bounds[1][k] for k in catvars]), legacy=False, count=count, validation_mode=validation_mode, **params)

    # in validation mode points_cat and/or points_con are N-by-0 matrices
    if not convars or (validation_mode and len(points_con) == len(points_cat)):
      points, points_y, status = points_cat, points_y_cat, status_cat
    elif len(points_con) != len(points_cat):
      raise _ex.InapplicableTechniqueException("Failed to genarate OLHS design with mixed categorical and continuous variables.")
    else:
      points_y, status = None, status_con
      points = _numpy.empty((len(points_con), points_dim), dtype=float)
      for i, k in enumerate(convars):
        points[:, k] = points_con[:, i]
      for i, k in enumerate(catvars):
        points[:, k] = points_cat[:, i]

    return info, points, points_y, status, None

  def _initial_sample_evaluation(self, blackbox, sample_x, sample_f, validation_mode, sift_logger=None):
    if not sift_logger:
      sift_logger = _shared.Logger(self._logger, self.options._get('GTDoE/LogLevel').lower())

    catvars = _shared.parse_json(self.options._get('GTDoE/CategoricalVariables'))
    with _bbconverter._as_problem_generic(blackbox=blackbox, catvars=catvars, location=_bbconverter._make_location('ISE'), logger=sift_logger) as problem:
      problem._validate()

      if problem.size_s():
        raise _ex.InapplicableTechniqueException("The initial sample evaluation (ISE) technique does not support robust optimization problems.")

      if sample_x is None:
        sample_x = _numpy.empty((0, problem.size_x()))

      info = {"Generator": {"Technique": "ISE", "Options" : {"GTDoE/Technique": "ISE"}}}
      if catvars:
        info["Generator"]["Options"]["GTDoE/CategoricalVariables"] = _shared.write_json(catvars)
      info["Generator"]["Mode"] = "Batch"
      info["Generator"]["BuildStamp"] = buildinfo.buildinfo().get("Build", {}).get("Stamp", 'version=' + str(__version__) + ';')

      size_f = problem.size_f()

      # we must evaluate sample_x if size_f for compatibility with old result
      if validation_mode or not size_f:
        return info, sample_x, (sample_f if size_f else None), _status.SUCCESS, None

      sift_logger.info("Evaluating objectives at initial sample points...")

      evaluation_mask_in = _numpy.zeros((len(sample_x), problem.size_full()), dtype=bool)

      if sample_f is not None and sample_f.size:
        evaluation_mask_in[:, :size_f] = _shared._find_holes(sample_f)
      else:
        evaluation_mask_in[:, :size_f] = True

      for i, kind in enumerate(_read_objectives_type(problem, "adaptive")):
        if kind == "payload":
          evaluation_mask_in[:, i] = False

      evaluation_data, evaluation_mask_out = _evaluate_sparse_data(problem, sample_x, evaluation_mask_in, batch_limit=int(self.options.get("/GTDoE/BatchSize")))
      _Result._reset_evaluation_error(problem=problem, logger=sift_logger)

      # Well, we can lose the constraints if any, but we cannot return constraints values.
      # This is not a problem because constraints are only possible within problem generic
      # so they are kept in designs.

      # make a copy to avoid excessive memory return
      if size_f < evaluation_data.shape[1]:
        evaluation_data = evaluation_data[:, :size_f].copy()
        evaluation_mask_in = evaluation_mask_in[:, :size_f]
        evaluation_mask_out = evaluation_mask_out[:, :size_f]

      if sample_f is not None and sample_f.size:
        evaluation_data[~evaluation_mask_in] = sample_f[~evaluation_mask_in] # keep the original values

    return info, sample_x, evaluation_data, _status.SUCCESS, None

  def _report_no_validation(self, technique_name):
    raise _ex.FeatureNotAvailableError("Validation mode does not supported for the `%s` technique." % (technique_name,))

  def _read_limited_evaluations_configuration(self, options):
    settings = {}
    with _shared._scoped_options(self, options):
      settings['responses_scalability'] = int(self.options._get("GTDoE/ResponsesScalability"))
      settings['watcher_timeout_ms'] = int(self.options._get("/GTOpt/WatcherCallGap"))
      settings['batch_size'] = int(self.options._get("/GTDoE/BatchSize"))
    return settings

  def _log_build_stamp(self, options):
    with _shared._scoped_options(self, options):
      sift_logger = _shared.Logger(self._logger, self.options._get('GTDoE/LogLevel').lower())
    sift_logger.info(buildinfo.buildinfo().get("Build", {}).get("Stamp", 'version=' + str(__version__) + ';'))

  def _test_candidate_technique(self, bounds, budget, options, max_design_size):
    try:
      self._backend.set_logger(None) # turn off backend logging for a while
      with _shared._scoped_options(self, options):
        _, fake_points, _, status, _ = self._backend.generate_sample(budget=budget, bounds=bounds, init_x=None, init_y=None, validation_mode=True)
      if status != _status.SUCCESS:
        return "inapplicable technique, no particular reason is given", None
      elif fake_points is None:
        return "cannot automatically select a target size", None
      elif len(fake_points) > max_design_size:
        return ("the automatically selected target size (%d) exceeds the heuristic threshold (%d)." % (len(fake_points), max_design_size)), len(fake_points)
      return None, len(fake_points)
    except:
      return str(_sys.exc_info()[1]), None
    finally:
      self._backend.set_logger(self._logger)

  def _heuristic_design_size(self, categorical_factorial_size, free_variables_count):
    if not free_variables_count:
      return categorical_factorial_size
    heuristic_design_size = min(DESIGN_SIZE_INFINITY, int(_numpy.round(_numpy.power(20, 1 + _numpy.log(1. + free_variables_count) / _numpy.log(5)))))
    heuristic_design_size = _imul_with_limit(categorical_factorial_size, heuristic_design_size, DESIGN_SIZE_INFINITY)
    return heuristic_design_size

  def _heuristic_design_size_parameters(self, bounds):
    free_variables_count = _numpy.count_nonzero(_numpy.less(bounds[0], bounds[1]))
    categorical_factorial_size = 1

    catvars = _shared.parse_json(self.options._get('GTDoE/CategoricalVariables'))
    if catvars:
      var_types =  _shared.parse_json(self.options._get('/GTDoE/VariablesType'))

      if not var_types:
        # Variables are contiguous except for the variables specified in the catvars dict.
        for i, levels in zip(catvars[::2], catvars[1::2]):
          if len(levels) > 1:
            free_variables_count -= 1 # don't count twice
            categorical_factorial_size = _imul_with_limit(categorical_factorial_size, len(levels), DESIGN_SIZE_INFINITY)
      else:
        # We must check the exact type of variable
        for i, levels in zip(catvars[::2], catvars[1::2]):
          if len(levels) > 1 and str(var_types[i]).lower() == "categorical":
            free_variables_count -= 1 # don't count twice
            categorical_factorial_size = _imul_with_limit(categorical_factorial_size, len(levels), DESIGN_SIZE_INFINITY)

    return {"categorical_factorial_size": categorical_factorial_size,  "free_variables_count": free_variables_count}

  def _select_auto_technique(self, blackbox, count, sample_f, logger, compatibility):
    def _number_of_levels(variable_type, variable_bounds, integer_threshold):
      variable_type = str(variable_type).lower()
      if variable_type  == "categorical":
        return True, True, len(variable_bounds)
      elif variable_type in ("discrete", "stepped"):
        n_levels = len(variable_bounds)
        return False, True, len(variable_bounds)
      elif variable_bounds[0] >= variable_bounds[1]:
        # gripped variable
        return False, True, 1
      elif variable_type == "integer":
        n_levels = int(_numpy.round(variable_bounds[1]) - _numpy.round(variable_bounds[0])) + 1
      else:
        # even continuous variable may have limited range
        bounds_range = variable_bounds[1] - variable_bounds[0]
        n_levels = int(min(bounds_range / (bounds_range * _numpy.finfo(float).eps), _numpy.iinfo(int).max))

      if n_levels <= 1:
        # due to rounding we can detect this case only here
        return False, True, 1
      return False, (n_levels <= integer_threshold), n_levels

    logger.info("Selecting the DoE technique...")

    catvars = _shared.parse_json(self.options._get('GTDoE/CategoricalVariables'))

    # Note that init_y is only needed to convert generation bounds to a blackbox.
    # But in this case, we will never choose AdaptiveDesign, so we don't care.
    with _bbconverter._as_problem_generic(blackbox=blackbox, catvars=catvars, location=_bbconverter._make_location('Auto'), logger=logger, init_y=sample_f) as problem:
      size_x = problem.size_x()
      bounds, catvars, _, var_types = _bbconverter._make_bounds(blackbox, catvars, "Auto")
      bounds = _shared.as_matrix(bounds, shape=(2, size_x))
      test_options = {"GTDoE/CategoricalVariables": catvars, "/GTDoE/VariablesType": var_types}
      if not var_types:
        var_types = ['continuous']*size_x

      discrete_integer_threshold = 10

      categorical_factorial_size = 1 # full factorial size of categorical variables
      discrete_factorial_size = 1 # minimal acceptable size of full factorial
      n_continuous_variables, n_discrete_variables, n_categorical_variables = 0, 0, 0
      discrete_levels = []

      for i, variable_type in enumerate(var_types):
        categorical_variable, discrete_behavior, max_levels = _number_of_levels(variable_type, problem.variables_bounds(i), discrete_integer_threshold)
        discrete_levels.append(max_levels)
        if categorical_variable:
          categorical_factorial_size = _imul_with_limit(categorical_factorial_size, max_levels, DESIGN_SIZE_INFINITY)
          n_categorical_variables += 1
        elif not discrete_behavior:
          n_continuous_variables += 1
        elif max_levels > 1:
          n_discrete_variables += 1
          discrete_factorial_size = _imul_with_limit(discrete_factorial_size, max_levels, DESIGN_SIZE_INFINITY)

      if categorical_factorial_size >= DESIGN_SIZE_INFINITY:
        raise _ex.InvalidProblemError("Cannot select an appropriate technique because there are too many possible combinations of levels for categorical variables (%d). Specify the technique to use." % (categorical_factorial_size,))
      elif not (n_continuous_variables + n_discrete_variables):
        # Don't need to check - this case won't overflow
        if categorical_factorial_size > 1:
          if count:
            ff_size_explanation = "The specified target DoE size is %d." % (count,)
          else:
            ff_size_explanation = "The target DoE size is not specified, using default (%d)." % (categorical_factorial_size,)
          logger.info("Using the Full Factorial technique because all variables are categorical. %s" % (ff_size_explanation,))
        else:
          logger.info("Can generate only 1 point because the design defines no free variables.")
        return count, {"GTDoE/Technique": "FullFactorial"}

      try:
        problem._validate()

        if compatibility:
          # The Adaptive Design technique is not supported by generate().
          if problem.size_c():
            logger.warn("Cannot use the Adaptive Design technique, constraints will be ignored when generating DoE: generate() is deprecated and does not support Adaptive Design, which is the only technique that can adapt to constraints.")

          if "adaptive" in _read_objectives_type(problem, "adaptive"):
            logger.info("Using the Adaptive technique because the design defines adaptive responses.")
            return count, {"GTDoE/Technique": "Adaptive"}
          else:
            logger.info("- Skipped the %s because there are no adaptive responses." % (("Adaptive technique" if problem.size_c() else "Adaptive Design and Adaptive techniques"),))
        else:
          adaptive_reasons = []
          if problem.size_c():
            adaptive_reasons.append("constraints")

          if "adaptive" in _read_objectives_type(problem, "adaptive"):
            adaptive_reasons.append("adaptive responses")

          if not adaptive_reasons:
            logger.info("- Skipped the Adaptive Design technique because there are no constraints and no adaptive responses.")
          else:
            # In validation mode, AdaptiveDesign's internal validation errors leak to top-level validation information.
            self_logger, self._logger = self._logger, None
            try:
              validation_result = _adaptive_fill._fill(self, problem, count, options=self.options.values, validation_mode=True)
            finally:
              self._logger = self_logger
            if validation_result:
              logger.info("Using the Adaptive Design technique because the design defines %s." % (" and ".join(adaptive_reasons)))
              return count, {"GTDoE/Technique": "AdaptiveDesign"}

            logger.info("- Cannot use the Adaptive Design technique:" + ("" if validation_result.details else " the problem does not pass Adaptive Design validation."))
            for note in validation_result.details:
              logger.info("    " + note.message)
      except:
        # Invalid problem, never choose AdaptiveDesign despite constraints and adaptive responses.
        exc_info = _sys.exc_info()
        logger.info("- Cannot use the " + ("Adaptive" if compatibility else "Adaptive Design") + " technique: " + str(exc_info[1]))

      discrete_factorial_size = _imul_with_limit(categorical_factorial_size, discrete_factorial_size, DESIGN_SIZE_INFINITY)
      heuristic_design_size = count or self._heuristic_design_size(categorical_factorial_size, n_continuous_variables + n_discrete_variables)

      if not n_continuous_variables:
        logger.info("- Skipped the OLHS technique because all variables have a limited set of possible values (discrete DoE).")

        if discrete_factorial_size <= heuristic_design_size:
          test_options["GTDoE/Technique"] = "FullFactorial"
          failure_reason, design_size = self._test_candidate_technique(bounds, discrete_factorial_size, test_options, heuristic_design_size)
          if not failure_reason:
            logger.info("Using the Full Factorial technique as the preferred discrete DoE, since the maximum possible size of a full factorial design (%d) is less than %s (%d)." \
                        % (discrete_factorial_size, ("the specified target DoE size" if count else "the default target DoE size with the same number of variables"), (count or heuristic_design_size)))
            return design_size, {"GTDoE/Technique": "FullFactorial"}
          logger.info("- Cannot use the Full Factorial technique: " + str(failure_reason))
        else:
          logger.info("Skipped the Full Factorial technique because the size of a full factorial design including all possible combinations of variable levels (%d) is greater than %s (%d)." \
                        % (discrete_factorial_size, ("the specified target DoE size" if count else "the default target DoE size with the same number of variables"), heuristic_design_size))

        test_options["GTDoE/Technique"] = "OrthogonalArray"
        if not _shared.parse_json(self.options.get("GTDoE/OrthogonalArray/LevelsNumber")):
          test_options["GTDoE/OrthogonalArray/LevelsNumber"] = discrete_levels
          failure_reason, design_size = self._test_candidate_technique(bounds, heuristic_design_size, test_options, DESIGN_SIZE_INFINITY)
          if not failure_reason:
            logger.info("Using the Orthogonal Array technique as it is the next preferred discrete DoE, and the size of an array including all possible values of each variable (%d) is less than %s (%d)." \
                        % (design_size, ("the specified target DoE size" if count else "the default target DoE size with the same number of variables"), (count or heuristic_design_size)))
            return design_size, {"GTDoE/Technique": "OrthogonalArray", "GTDoE/OrthogonalArray/LevelsNumber": discrete_levels}
          test_options["GTDoE/OrthogonalArray/LevelsNumber"] = []

        failure_reason, design_size = self._test_candidate_technique(bounds, heuristic_design_size, test_options, DESIGN_SIZE_INFINITY)
        if not failure_reason:
          logger.info("Using the Orthogonal Array technique with a minimum possible array size (%d) as it is the next preferred discrete DoE but the array size must not be greater than %s (%d)." \
                        % (design_size, ("the specified target DoE size" if count else "the default target DoE size with the same number of variables"), (count or heuristic_design_size)))
          return design_size, {"GTDoE/Technique": "OrthogonalArray"}
        logger.info("- Cannot use the Orthogonal Array technique: " + str(failure_reason))
      elif n_continuous_variables > 10:
        logger.info("- Skipped the OLHS technique because the number of continuous variables is too high (%d excluding constants)." % (n_continuous_variables))
      else:
        test_options["GTDoE/Technique"] = "OLHS"
        failure_reason, design_size = self._test_candidate_technique(bounds, heuristic_design_size, test_options, DESIGN_SIZE_INFINITY)
        if not failure_reason:
          if count:
            olhs_size_explanation = "The specified target DoE size is %d." % (count,)
          else:
            olhs_size_explanation = "The target DoE size is not specified, using default (%d)." % (design_size,)
          logger.info("Using the OLHS technique because the design defines %s variables. %s" \
                        % (("a mix of continuous and discrete" if n_discrete_variables else "continuous"), olhs_size_explanation,))
          return design_size, {"GTDoE/Technique": "OLHS"}
        logger.info("- Cannot use the OLHS technique: " + str(failure_reason))

      if count:
        lhs_size_explanation = "The specified target DoE size is %d." % (count,)
      else:
        lhs_size_explanation = "The target DoE size is not specified, using default (%d)." % (heuristic_design_size,)
      logger.info("Defaulting to the LHS technique. %s" % (lhs_size_explanation,))
      return heuristic_design_size, {"GTDoE/Technique": "LHS"}

  def _create_snapshot_watcher(self, problem, validation_mode):
    if not validation_mode:
      return _SolutionSnapshotFactory(generator=_OptionsTranslator(self), watcher=self._watcher, problem=problem, auto_objective_type="evaluate")
    return _SolutionSnapshotFactory(generator=None, watcher=self._watcher, problem=None, auto_objective_type=None)

def _append_field_spec(fields, base_offset, field_name, field_size):
  if not field_size:
    return base_offset
  next_offset = base_offset + field_size
  fields.append((field_name, slice(base_offset, next_offset)))
  return next_offset

def _slice_or_none(sample, fields_dict, field_name):
  return sample[:, fields_dict[field_name]] if field_name in fields_dict else None

def _read_property_or_method(problem, attr_name):
  attr_value = getattr(problem, attr_name)
  return attr_value() if callable(attr_value) else attr_value

def _imul_with_limit(a, b, limit):
  return 0 if a == 0 else a * b if (limit // a) >= b else limit

class _OptionsTranslator(object):
  def __init__(self, generator):
    self._options_manager = _options._OptionManager('GTOpt/')
    self._generator = generator

  @property
  def options(self):
    return _options.Options(self._options_manager.pointer, self)

  def _update_options(self):
    self.options.reset()
    _adaptive_fill._translate_general_options(self._generator, self)

class _SolutionSnapshotFactory(_designs._SolutionSnapshotFactoryBase):
  def __call__(self, data=None):
    return self.proceed(None)

  def proceed(self, result):
    if not self._user_watcher:
      return True

    data = {'ResultUpdated': True, 'RequestIntermediateResult': _weakref.ref(result)} if result else {}
    if not self._generator:
      return self._user_watcher(data or None)

    try:
      lazy_snapshot = _designs._DetachableSingleCallableRef(callable=self.snapshot, result=result)
      data['RequestIntermediateSnapshot'] = lazy_snapshot
      return self._user_watcher(data)
    finally:
      lazy_snapshot._reset()

  def snapshot(self, result):
    if self._last_snapshot is not None and result is None and self._history_length == len(self._problem._history_cache):
      return self._last_snapshot

    try:
      self._generator._update_options() # self uses GTOpt-based options so we read and translate actual GTDoE-based options

      final_result = result is not None
      if final_result:
        final_snapshot = self._modern_result_to_snapshot(result)
        if final_snapshot:
          return final_snapshot

      designs_table = self._collect_designs(extra_designs=self._result_to_designs(result))

      if not designs_table.size:
        # This must be the first call
        empty_status = _numpy.zeros((0,), dtype=int)
        return self._make_snapshot(designs=designs_table[:, :-1], status_initial=empty_status,
                                   status_feasibility=empty_status, status_optimality=empty_status)

      # Note "status" is the last column. Must be.
      designs_table, status_initial = designs_table[:, :-1], designs_table[:, -1]
      status_initial[_shared._find_holes(status_initial)] = _designs._SolutionSnapshot._UNDEFINED
      status_initial = status_initial.astype(int)
      status_feasibility = self._status_feasibility(design=designs_table, final_result=final_result)
      status_optimality = self._status_optimality(design=designs_table, status_feasibility=status_feasibility, final_result=final_result)

      return self._make_snapshot(designs=designs_table,
                                 status_initial=status_initial,
                                 status_feasibility=status_feasibility,
                                 status_optimality=status_optimality)
    except:
      pass

    return None
