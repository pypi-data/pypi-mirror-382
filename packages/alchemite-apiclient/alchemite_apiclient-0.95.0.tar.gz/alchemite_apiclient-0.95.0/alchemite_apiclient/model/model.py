"""
    Alchemite

    No description provided (generated by Openapi Generator https://github.com/openapitools/openapi-generator)  # noqa: E501
    Contact: support@intellegens.com
    Generated by: https://openapi-generator.tech
"""


import re  # noqa: F401
import sys  # noqa: F401

from alchemite_apiclient.model_utils import (  # noqa: F401
    ApiTypeError,
    ModelComposed,
    ModelNormal,
    ModelSimple,
    cached_property,
    change_keys_js_to_python,
    convert_js_args_to_python_args,
    date,
    datetime,
    file_type,
    none_type,
    validate_get_composed_info,
    OpenApiModel
)
from alchemite_apiclient.exceptions import ApiAttributeError


def lazy_import():
    from alchemite_apiclient.model.categorical_column import CategoricalColumn
    from alchemite_apiclient.model.hyperopt_target_function import HyperoptTargetFunction
    from alchemite_apiclient.model.model_column_info import ModelColumnInfo
    from alchemite_apiclient.model.model_permitted_column_relationships import ModelPermittedColumnRelationships
    from alchemite_apiclient.model.model_sharing import ModelSharing
    from alchemite_apiclient.model.model_status import ModelStatus
    from alchemite_apiclient.model.model_validation_methods import ModelValidationMethods
    from alchemite_apiclient.model.ordinal_column import OrdinalColumn
    globals()['CategoricalColumn'] = CategoricalColumn
    globals()['HyperoptTargetFunction'] = HyperoptTargetFunction
    globals()['ModelColumnInfo'] = ModelColumnInfo
    globals()['ModelPermittedColumnRelationships'] = ModelPermittedColumnRelationships
    globals()['ModelSharing'] = ModelSharing
    globals()['ModelStatus'] = ModelStatus
    globals()['ModelValidationMethods'] = ModelValidationMethods
    globals()['OrdinalColumn'] = OrdinalColumn


class Model(ModelNormal):
    """NOTE: This class is auto generated by OpenAPI Generator.
    Ref: https://openapi-generator.tech

    Do not edit the class manually.

    Attributes:
      allowed_values (dict): The key is the tuple path to the attribute
          and the for var_name this is (var_name,). The value is a dict
          with a capitalized key describing the allowed value and an allowed
          value. These dicts store the allowed enum values.
      attribute_map (dict): The key is attribute name
          and the value is json key in definition.
      discriminator_value_class_map (dict): A dict to go from the discriminator
          variable value to the discriminator class name.
      validations (dict): The key is the tuple path to the attribute
          and the for var_name this is (var_name,). The value is a dict
          that stores validations for max_length, min_length, max_items,
          min_items, exclusive_maximum, inclusive_maximum, exclusive_minimum,
          inclusive_minimum, and regex.
      additional_properties_type (tuple): A tuple of classes accepted
          as additional properties values.
    """

    allowed_values = {
        ('training_method',): {
            'ALCHEMITE': "alchemite",
        },
        ('hyperparameter_optimization_method',): {
            'NONE': "none",
            'RANDOM': "random",
            'TPE': "TPE",
        },
        ('training_dataset_outliers_job_status',): {
            'None': None,
            'PENDING': "pending",
            'RUNNING': "running",
            'DONE': "done",
            'FAILED': "failed",
        },
    }

    validations = {
        ('tags',): {
        },
        ('training_progress',): {
            'inclusive_maximum': 100,
            'inclusive_minimum': 0,
        },
        ('hyperparameter_optimization_progress',): {
            'inclusive_maximum': 100,
            'inclusive_minimum': 0,
        },
        ('validation_metric',): {
            'inclusive_maximum': 1,
        },
        ('validation_r_squared',): {
            'inclusive_maximum': 1,
        },
        ('exploration_exploitation',): {
            'inclusive_maximum': 1,
            'inclusive_minimum': 0,
        },
    }

    @cached_property
    def additional_properties_type():  # noqa
        """
        This must be a method because a model may have properties that are
        of type self, this must run after the class is loaded
        """
        return (bool, date, datetime, dict, float, int, list, str, none_type,)  # noqa: E501

    _nullable = False

    @cached_property
    def openapi_types():  # noqa
        """
        This must be a method because a model may have properties that are
        of type self, this must run after the class is loaded

        Returns
            openapi_types (dict): The key is attribute name
                and the value is attribute type.
        """
        lazy_import()
        return {
            'name': (str,),  # noqa: E501
            'training_method': (str,),  # noqa: E501
            'id': (str,),  # noqa: E501
            'tags': ([str],),  # noqa: E501
            'notes': (str,),  # noqa: E501
            'project_id': (str,),  # noqa: E501
            'status': (ModelStatus,),  # noqa: E501
            'revises_id': (str,),  # noqa: E501
            'revision_ids': ([str],),  # noqa: E501
            'training_method_version': (str,),  # noqa: E501
            'training_dataset_id': (str,),  # noqa: E501
            'training_start_time': (int,),  # noqa: E501
            'training_completion_time': (int,),  # noqa: E501
            'training_progress': (float,),  # noqa: E501
            'hyperparameter_optimization_method': (str,),  # noqa: E501
            'bespoke_column_hyperparameters': (bool,),  # noqa: E501
            'hyperparameter_optimization_start_time': (int,),  # noqa: E501
            'hyperparameter_optimization_completion_time': (int,),  # noqa: E501
            'hyperparameter_optimization_progress': (float,),  # noqa: E501
            'training_real_time': (int,),  # noqa: E501
            'training_cpu_time': (int,),  # noqa: E501
            'training_peak_memory_usage': (int,),  # noqa: E501
            'training_hyperparameters': ({str: (bool, date, datetime, dict, float, int, list, str, none_type)},),  # noqa: E501
            'training_column_headers': ([str],),  # noqa: E501
            'training_initial_column_headers': ([str],),  # noqa: E501
            'training_column_info': ([ModelColumnInfo],),  # noqa: E501
            'categorical_columns': ([CategoricalColumn], none_type,),  # noqa: E501
            'ordinal_columns': ([OrdinalColumn], none_type,),  # noqa: E501
            'file_size': (int,),  # noqa: E501
            'validation_method': (ModelValidationMethods,),  # noqa: E501
            'validation_metric': (float, none_type,),  # noqa: E501
            'validation_r_squared': (float, none_type,),  # noqa: E501
            'validation_target_columns': ([str], none_type,),  # noqa: E501
            'loaded': (bool,),  # noqa: E501
            'estimated_model_memory': (int,),  # noqa: E501
            'virtual_training': (bool,),  # noqa: E501
            'permitted_column_relationships': ([ModelPermittedColumnRelationships], none_type,),  # noqa: E501
            'hyperopt_sample_request': (int, none_type,),  # noqa: E501
            'virtual_experiment_validation': (bool,),  # noqa: E501
            'target_function': (bool, date, datetime, dict, float, int, list, str, none_type,),  # noqa: E501
            'exploration_exploitation': (float,),  # noqa: E501
            'training_dataset_outliers_job_id': (str, none_type,),  # noqa: E501
            'training_dataset_outliers_job_status': (str, none_type,),  # noqa: E501
            'created_at': (int,),  # noqa: E501
            'shared_through': ([str],),  # noqa: E501
            'sharing': (ModelSharing,),  # noqa: E501
            'detail': (str,),  # noqa: E501
        }

    @cached_property
    def discriminator():  # noqa
        return None


    attribute_map = {
        'name': 'name',  # noqa: E501
        'training_method': 'trainingMethod',  # noqa: E501
        'id': 'id',  # noqa: E501
        'tags': 'tags',  # noqa: E501
        'notes': 'notes',  # noqa: E501
        'project_id': 'projectId',  # noqa: E501
        'status': 'status',  # noqa: E501
        'revises_id': 'revisesId',  # noqa: E501
        'revision_ids': 'revisionIds',  # noqa: E501
        'training_method_version': 'trainingMethodVersion',  # noqa: E501
        'training_dataset_id': 'trainingDatasetId',  # noqa: E501
        'training_start_time': 'trainingStartTime',  # noqa: E501
        'training_completion_time': 'trainingCompletionTime',  # noqa: E501
        'training_progress': 'trainingProgress',  # noqa: E501
        'hyperparameter_optimization_method': 'hyperparameterOptimizationMethod',  # noqa: E501
        'bespoke_column_hyperparameters': 'bespokeColumnHyperparameters',  # noqa: E501
        'hyperparameter_optimization_start_time': 'hyperparameterOptimizationStartTime',  # noqa: E501
        'hyperparameter_optimization_completion_time': 'hyperparameterOptimizationCompletionTime',  # noqa: E501
        'hyperparameter_optimization_progress': 'hyperparameterOptimizationProgress',  # noqa: E501
        'training_real_time': 'trainingRealTime',  # noqa: E501
        'training_cpu_time': 'trainingCPUTime',  # noqa: E501
        'training_peak_memory_usage': 'trainingPeakMemoryUsage',  # noqa: E501
        'training_hyperparameters': 'trainingHyperparameters',  # noqa: E501
        'training_column_headers': 'trainingColumnHeaders',  # noqa: E501
        'training_initial_column_headers': 'trainingInitialColumnHeaders',  # noqa: E501
        'training_column_info': 'trainingColumnInfo',  # noqa: E501
        'categorical_columns': 'categoricalColumns',  # noqa: E501
        'ordinal_columns': 'ordinalColumns',  # noqa: E501
        'file_size': 'fileSize',  # noqa: E501
        'validation_method': 'validationMethod',  # noqa: E501
        'validation_metric': 'validationMetric',  # noqa: E501
        'validation_r_squared': 'validationRSquared',  # noqa: E501
        'validation_target_columns': 'validationTargetColumns',  # noqa: E501
        'loaded': 'loaded',  # noqa: E501
        'estimated_model_memory': 'estimatedModelMemory',  # noqa: E501
        'virtual_training': 'virtualTraining',  # noqa: E501
        'permitted_column_relationships': 'permittedColumnRelationships',  # noqa: E501
        'hyperopt_sample_request': 'hyperoptSampleRequest',  # noqa: E501
        'virtual_experiment_validation': 'virtualExperimentValidation',  # noqa: E501
        'target_function': 'targetFunction',  # noqa: E501
        'exploration_exploitation': 'explorationExploitation',  # noqa: E501
        'training_dataset_outliers_job_id': 'trainingDatasetOutliersJobId',  # noqa: E501
        'training_dataset_outliers_job_status': 'trainingDatasetOutliersJobStatus',  # noqa: E501
        'created_at': 'createdAt',  # noqa: E501
        'shared_through': 'sharedThrough',  # noqa: E501
        'sharing': 'sharing',  # noqa: E501
        'detail': 'detail',  # noqa: E501
    }

    read_only_vars = {
        'id',  # noqa: E501
        'revision_ids',  # noqa: E501
        'training_method_version',  # noqa: E501
        'training_start_time',  # noqa: E501
        'training_completion_time',  # noqa: E501
        'training_progress',  # noqa: E501
        'hyperparameter_optimization_method',  # noqa: E501
        'bespoke_column_hyperparameters',  # noqa: E501
        'hyperparameter_optimization_start_time',  # noqa: E501
        'hyperparameter_optimization_completion_time',  # noqa: E501
        'hyperparameter_optimization_progress',  # noqa: E501
        'training_real_time',  # noqa: E501
        'training_cpu_time',  # noqa: E501
        'training_peak_memory_usage',  # noqa: E501
        'training_hyperparameters',  # noqa: E501
        'training_column_headers',  # noqa: E501
        'training_initial_column_headers',  # noqa: E501
        'training_column_info',  # noqa: E501
        'categorical_columns',  # noqa: E501
        'ordinal_columns',  # noqa: E501
        'file_size',  # noqa: E501
        'validation_metric',  # noqa: E501
        'validation_r_squared',  # noqa: E501
        'validation_target_columns',  # noqa: E501
        'loaded',  # noqa: E501
        'estimated_model_memory',  # noqa: E501
        'virtual_training',  # noqa: E501
        'permitted_column_relationships',  # noqa: E501
        'hyperopt_sample_request',  # noqa: E501
        'virtual_experiment_validation',  # noqa: E501
        'target_function',  # noqa: E501
        'exploration_exploitation',  # noqa: E501
        'training_dataset_outliers_job_id',  # noqa: E501
        'training_dataset_outliers_job_status',  # noqa: E501
        'created_at',  # noqa: E501
        'shared_through',  # noqa: E501
        'detail',  # noqa: E501
    }

    _composed_schemas = {}

    @classmethod
    @convert_js_args_to_python_args
    def _from_openapi_data(cls, name, *args, **kwargs):  # noqa: E501
        """Model - a model defined in OpenAPI

        Args:
            name (str):

        Keyword Args:
            training_method (str): The method used to train the model.. defaults to "alchemite", must be one of ["alchemite", ]  # noqa: E501
            _check_type (bool): if True, values for parameters in openapi_types
                                will be type checked and a TypeError will be
                                raised if the wrong type is input.
                                Defaults to True
            _path_to_item (tuple/list): This is a list of keys or values to
                                drill down to the model in received_data
                                when deserializing a response
            _spec_property_naming (bool): True if the variable names in the input data
                                are serialized names, as specified in the OpenAPI document.
                                False if the variable names in the input data
                                are pythonic names, e.g. snake case (default)
            _configuration (Configuration): the instance to use when
                                deserializing a file_type parameter.
                                If passed, type conversion is attempted
                                If omitted no type conversion is done.
            _visited_composed_classes (tuple): This stores a tuple of
                                classes that we have traveled through so that
                                if we see that class again we will not use its
                                discriminator again.
                                When traveling through a discriminator, the
                                composed schema that is
                                is traveled through is added to this set.
                                For example if Animal has a discriminator
                                petType and we pass in "Dog", and the class Dog
                                allOf includes Animal, we move through Animal
                                once using the discriminator, and pick Dog.
                                Then in Dog, we will make an instance of the
                                Animal class but this time we won't travel
                                through its discriminator because we passed in
                                _visited_composed_classes = (Animal,)
            id (str): Unique identifier for the model.. [optional]  # noqa: E501
            tags ([str]): Optional tags to attach to the model. [optional]  # noqa: E501
            notes (str): An optional free field for notes about the dataset. [optional]  # noqa: E501
            project_id (str): The project this model belongs to. The user must have permission to see the respective project to set this value . [optional]  # noqa: E501
            status (ModelStatus): [optional]  # noqa: E501
            revises_id (str): The UUID of the model this revisesID (its parent).. [optional]  # noqa: E501
            revision_ids ([str]): The UUIDs of the models that are revisions of this model (its children).. [optional]  # noqa: E501
            training_method_version (str): The version of the method used to train the model.. [optional]  # noqa: E501
            training_dataset_id (str): ID of the dataset used to train the model.. [optional]  # noqa: E501
            training_start_time (int): The Unix Timestamp in seconds when the model status switched to 'training' upon the last training request. Note that this will be just after hyperparameter optimization finishes, if that was requested. . [optional]  # noqa: E501
            training_completion_time (int): The Unix Timestamp in seconds when the model last completed training.. [optional]  # noqa: E501
            training_progress (float): The percentage completion of the model training process.. [optional]  # noqa: E501
            hyperparameter_optimization_method (str): The hyperparameter optimization method that was used to find the optimal hyperparameters to train the model on. [optional]  # noqa: E501
            bespoke_column_hyperparameters (bool): Whether to use bespoke hyperparameters for each target column. If false, hyperparameters are shared between columns. Defaults to true.. [optional]  # noqa: E501
            hyperparameter_optimization_start_time (int): The Unix Timestamp in seconds when the model last began hyperparameter optimization.. [optional]  # noqa: E501
            hyperparameter_optimization_completion_time (int): The Unix Timestamp in seconds when the model last completed hyperparameter optimization.. [optional]  # noqa: E501
            hyperparameter_optimization_progress (float): The percentage completion of the hyperparameter optimization process.. [optional]  # noqa: E501
            training_real_time (int): The real-world time in seconds that Alchemite took to train the model.. [optional]  # noqa: E501
            training_cpu_time (int): The CPU time in seconds that Alchemite took to train the model.. [optional]  # noqa: E501
            training_peak_memory_usage (int): The peak amount of memory (specifically the resident set size) in bytes used while training the model.. [optional]  # noqa: E501
            training_hyperparameters ({str: (bool, date, datetime, dict, float, int, list, str, none_type)}): The hyperparameters in JSON format used to train the model.. [optional]  # noqa: E501
            training_column_headers ([str]): The list of column headers in the order that the model was trained on (with descriptor columns first).. [optional]  # noqa: E501
            training_initial_column_headers ([str]): The list of column headers that were initially uploaded, before extensions or calculated columns are applied.. [optional]  # noqa: E501
            training_column_info ([ModelColumnInfo]): Additional information/statistics for each column, listed in the order that model was trained on (with descriptor columns first).. [optional]  # noqa: E501
            categorical_columns ([CategoricalColumn], none_type): The possible categorical values for each categorical column in the dataset the model was trained on. [optional]  # noqa: E501
            ordinal_columns ([OrdinalColumn], none_type): The possible ordinal values for each ordinal column in the dataset the model was trained on. [optional]  # noqa: E501
            file_size (int): The size of the model in bytes.. [optional]  # noqa: E501
            validation_method (ModelValidationMethods): [optional]  # noqa: E501
            validation_metric (float, none_type): The median of validation metrics (whether R^2 for continuous and ordinal columns, MCC for categorical columns, or the targeted metric when using targets during training) across the validation target columns in the validation set.. [optional]  # noqa: E501
            validation_r_squared (float, none_type): Coefficient of determination, R^2, calculated as the median across the target columns in the validation set. Deprecated, use `validationMetric` instead for a measure of the overall fit of the model or the `trainingColumnInfo` to find the coefficient of determination for each column with continuous data.. [optional]  # noqa: E501
            validation_target_columns ([str], none_type): A list of column names specifying the columns to use to calculate the model's validation metric.  Cannot include descriptor columns.. [optional]  # noqa: E501
            loaded (bool): If true then the model has been loaded into memory and will be used to respond to impute requests.  If false then the model will only be loaded into memory at request time.. [optional]  # noqa: E501
            estimated_model_memory (int): The expected memory footprint of the model in bytes.. [optional]  # noqa: E501
            virtual_training (bool): If true then only the descriptor columns were used as input in the first iteration of training. [optional]  # noqa: E501
            permitted_column_relationships ([ModelPermittedColumnRelationships], none_type): An array of objects defining which columns the ML model is able to use or not use as inputs when modelling specific columns.  The \"allow\" and \"disallow\" arrays must contain distinct columns. They do not need to contain all columns in the dataset.  If columns are not allowed in either \"allow\" nor \"disallow\", the model will use default behaviors:   - use all descriptors for all targets when virtualTraining is true.   - use all descriptors + targets when virtualTraining is false for all targets (except for the same target -> target).  if virtualTraining is false:   This is equivalent to passing \"allow\": list_of_all_columns for every column in the dataset.   Therefore, passing allow when virtualTraining is false has no effect on the model.   However, columns passed within \"disallow\" will have an effect.  if virtualTraining is true:   This is equivalent to passing \"allow\": list_of_all_descriptors and passing \"disallow\" for all non descriptors.   Therefore, passing descriptor columns in the \"allow\" list has no effect on the model.   Similarly, passing non descriptor columns in the \"disallow\" list has no effect on the model.   However, columns passed within \"allow\" for non descriptors, and \"disallow\" for descriptors will have an effect.  Interaction with Measurement Groups:   If measurement groups are specified for the training dataset that are incompatible, a 400 response is returned.   This happens when a column defined in \"name\" and one or more columns defined in \"allow\" are part of the same measurement group. . [optional]  # noqa: E501
            hyperopt_sample_request (int, none_type): The maximum number of hyperparameter optimization samples used for training the model.  Training may stop before the specified amount of samples if an ideal set of hyperparameters if found early.  . [optional]  # noqa: E501
            virtual_experiment_validation (bool): If true then only the descriptor columns were used to make predictions when computing the validation metric.. [optional]  # noqa: E501
            target_function (bool, date, datetime, dict, float, int, list, str, none_type): [optional]  # noqa: E501
            exploration_exploitation (float): The exploration exploitation ratio used for training the model. [optional] if omitted the server will use the default value of 1  # noqa: E501
            training_dataset_outliers_job_id (str, none_type): ID of the training outliers job. [optional]  # noqa: E501
            training_dataset_outliers_job_status (str, none_type): Status of outliers training job. [optional]  # noqa: E501
            created_at (int): The Unix Timestamp in seconds when POST /models was called. If `0` (Unix system time zero) then creation timestamp unavailable. This can happen for older models. . [optional]  # noqa: E501
            shared_through ([str]): If a model has been shared with the user then this will show through which group(s) it has been shared. Won't be set if the user requesting the resource owns it. Deprecated: Please use `sharing` to determine how the access for the model was achieved. . [optional]  # noqa: E501
            sharing (ModelSharing): [optional]  # noqa: E501
            detail (str): The error provided by Alchemite for why the model failed to train if  an issue occurs during model creation . [optional]  # noqa: E501
        """

        training_method = kwargs.get('training_method', "alchemite")
        _check_type = kwargs.pop('_check_type', True)
        _spec_property_naming = kwargs.pop('_spec_property_naming', False)
        _path_to_item = kwargs.pop('_path_to_item', ())
        _configuration = kwargs.pop('_configuration', None)
        _visited_composed_classes = kwargs.pop('_visited_composed_classes', ())

        self = super(OpenApiModel, cls).__new__(cls)

        if args:
            raise ApiTypeError(
                "Invalid positional arguments=%s passed to %s. Remove those invalid positional arguments." % (
                    args,
                    self.__class__.__name__,
                ),
                path_to_item=_path_to_item,
                valid_classes=(self.__class__,),
            )

        self._data_store = {}
        self._check_type = _check_type
        self._spec_property_naming = _spec_property_naming
        self._path_to_item = _path_to_item
        self._configuration = _configuration
        self._visited_composed_classes = _visited_composed_classes + (self.__class__,)

        self.name = name
        self.training_method = training_method
        for var_name, var_value in kwargs.items():
            if var_name not in self.attribute_map and \
                        self._configuration is not None and \
                        self._configuration.discard_unknown_keys and \
                        self.additional_properties_type is None:
                # discard variable.
                continue
            setattr(self, var_name, var_value)
        return self

    required_properties = set([
        '_data_store',
        '_check_type',
        '_spec_property_naming',
        '_path_to_item',
        '_configuration',
        '_visited_composed_classes',
    ])

    @convert_js_args_to_python_args
    def __init__(self, name, *args, **kwargs):  # noqa: E501
        """Model - a model defined in OpenAPI

        Args:
            name (str):

        Keyword Args:
            training_method (str): The method used to train the model.. defaults to "alchemite", must be one of ["alchemite", ]  # noqa: E501
            _check_type (bool): if True, values for parameters in openapi_types
                                will be type checked and a TypeError will be
                                raised if the wrong type is input.
                                Defaults to True
            _path_to_item (tuple/list): This is a list of keys or values to
                                drill down to the model in received_data
                                when deserializing a response
            _spec_property_naming (bool): True if the variable names in the input data
                                are serialized names, as specified in the OpenAPI document.
                                False if the variable names in the input data
                                are pythonic names, e.g. snake case (default)
            _configuration (Configuration): the instance to use when
                                deserializing a file_type parameter.
                                If passed, type conversion is attempted
                                If omitted no type conversion is done.
            _visited_composed_classes (tuple): This stores a tuple of
                                classes that we have traveled through so that
                                if we see that class again we will not use its
                                discriminator again.
                                When traveling through a discriminator, the
                                composed schema that is
                                is traveled through is added to this set.
                                For example if Animal has a discriminator
                                petType and we pass in "Dog", and the class Dog
                                allOf includes Animal, we move through Animal
                                once using the discriminator, and pick Dog.
                                Then in Dog, we will make an instance of the
                                Animal class but this time we won't travel
                                through its discriminator because we passed in
                                _visited_composed_classes = (Animal,)
            id (str): Unique identifier for the model.. [optional]  # noqa: E501
            tags ([str]): Optional tags to attach to the model. [optional]  # noqa: E501
            notes (str): An optional free field for notes about the dataset. [optional]  # noqa: E501
            project_id (str): The project this model belongs to. The user must have permission to see the respective project to set this value . [optional]  # noqa: E501
            status (ModelStatus): [optional]  # noqa: E501
            revises_id (str): The UUID of the model this revisesID (its parent).. [optional]  # noqa: E501
            revision_ids ([str]): The UUIDs of the models that are revisions of this model (its children).. [optional]  # noqa: E501
            training_method_version (str): The version of the method used to train the model.. [optional]  # noqa: E501
            training_dataset_id (str): ID of the dataset used to train the model.. [optional]  # noqa: E501
            training_start_time (int): The Unix Timestamp in seconds when the model status switched to 'training' upon the last training request. Note that this will be just after hyperparameter optimization finishes, if that was requested. . [optional]  # noqa: E501
            training_completion_time (int): The Unix Timestamp in seconds when the model last completed training.. [optional]  # noqa: E501
            training_progress (float): The percentage completion of the model training process.. [optional]  # noqa: E501
            hyperparameter_optimization_method (str): The hyperparameter optimization method that was used to find the optimal hyperparameters to train the model on. [optional]  # noqa: E501
            bespoke_column_hyperparameters (bool): Whether to use bespoke hyperparameters for each target column. If false, hyperparameters are shared between columns. Defaults to true.. [optional]  # noqa: E501
            hyperparameter_optimization_start_time (int): The Unix Timestamp in seconds when the model last began hyperparameter optimization.. [optional]  # noqa: E501
            hyperparameter_optimization_completion_time (int): The Unix Timestamp in seconds when the model last completed hyperparameter optimization.. [optional]  # noqa: E501
            hyperparameter_optimization_progress (float): The percentage completion of the hyperparameter optimization process.. [optional]  # noqa: E501
            training_real_time (int): The real-world time in seconds that Alchemite took to train the model.. [optional]  # noqa: E501
            training_cpu_time (int): The CPU time in seconds that Alchemite took to train the model.. [optional]  # noqa: E501
            training_peak_memory_usage (int): The peak amount of memory (specifically the resident set size) in bytes used while training the model.. [optional]  # noqa: E501
            training_hyperparameters ({str: (bool, date, datetime, dict, float, int, list, str, none_type)}): The hyperparameters in JSON format used to train the model.. [optional]  # noqa: E501
            training_column_headers ([str]): The list of column headers in the order that the model was trained on (with descriptor columns first).. [optional]  # noqa: E501
            training_initial_column_headers ([str]): The list of column headers that were initially uploaded, before extensions or calculated columns are applied.. [optional]  # noqa: E501
            training_column_info ([ModelColumnInfo]): Additional information/statistics for each column, listed in the order that model was trained on (with descriptor columns first).. [optional]  # noqa: E501
            categorical_columns ([CategoricalColumn], none_type): The possible categorical values for each categorical column in the dataset the model was trained on. [optional]  # noqa: E501
            ordinal_columns ([OrdinalColumn], none_type): The possible ordinal values for each ordinal column in the dataset the model was trained on. [optional]  # noqa: E501
            file_size (int): The size of the model in bytes.. [optional]  # noqa: E501
            validation_method (ModelValidationMethods): [optional]  # noqa: E501
            validation_metric (float, none_type): The median of validation metrics (whether R^2 for continuous and ordinal columns, MCC for categorical columns, or the targeted metric when using targets during training) across the validation target columns in the validation set.. [optional]  # noqa: E501
            validation_r_squared (float, none_type): Coefficient of determination, R^2, calculated as the median across the target columns in the validation set. Deprecated, use `validationMetric` instead for a measure of the overall fit of the model or the `trainingColumnInfo` to find the coefficient of determination for each column with continuous data.. [optional]  # noqa: E501
            validation_target_columns ([str], none_type): A list of column names specifying the columns to use to calculate the model's validation metric.  Cannot include descriptor columns.. [optional]  # noqa: E501
            loaded (bool): If true then the model has been loaded into memory and will be used to respond to impute requests.  If false then the model will only be loaded into memory at request time.. [optional]  # noqa: E501
            estimated_model_memory (int): The expected memory footprint of the model in bytes.. [optional]  # noqa: E501
            virtual_training (bool): If true then only the descriptor columns were used as input in the first iteration of training. [optional]  # noqa: E501
            permitted_column_relationships ([ModelPermittedColumnRelationships], none_type): An array of objects defining which columns the ML model is able to use or not use as inputs when modelling specific columns.  The \"allow\" and \"disallow\" arrays must contain distinct columns. They do not need to contain all columns in the dataset.  If columns are not allowed in either \"allow\" nor \"disallow\", the model will use default behaviors:   - use all descriptors for all targets when virtualTraining is true.   - use all descriptors + targets when virtualTraining is false for all targets (except for the same target -> target).  if virtualTraining is false:   This is equivalent to passing \"allow\": list_of_all_columns for every column in the dataset.   Therefore, passing allow when virtualTraining is false has no effect on the model.   However, columns passed within \"disallow\" will have an effect.  if virtualTraining is true:   This is equivalent to passing \"allow\": list_of_all_descriptors and passing \"disallow\" for all non descriptors.   Therefore, passing descriptor columns in the \"allow\" list has no effect on the model.   Similarly, passing non descriptor columns in the \"disallow\" list has no effect on the model.   However, columns passed within \"allow\" for non descriptors, and \"disallow\" for descriptors will have an effect.  Interaction with Measurement Groups:   If measurement groups are specified for the training dataset that are incompatible, a 400 response is returned.   This happens when a column defined in \"name\" and one or more columns defined in \"allow\" are part of the same measurement group. . [optional]  # noqa: E501
            hyperopt_sample_request (int, none_type): The maximum number of hyperparameter optimization samples used for training the model.  Training may stop before the specified amount of samples if an ideal set of hyperparameters if found early.  . [optional]  # noqa: E501
            virtual_experiment_validation (bool): If true then only the descriptor columns were used to make predictions when computing the validation metric.. [optional]  # noqa: E501
            target_function (bool, date, datetime, dict, float, int, list, str, none_type): [optional]  # noqa: E501
            exploration_exploitation (float): The exploration exploitation ratio used for training the model. [optional] if omitted the server will use the default value of 1  # noqa: E501
            training_dataset_outliers_job_id (str, none_type): ID of the training outliers job. [optional]  # noqa: E501
            training_dataset_outliers_job_status (str, none_type): Status of outliers training job. [optional]  # noqa: E501
            created_at (int): The Unix Timestamp in seconds when POST /models was called. If `0` (Unix system time zero) then creation timestamp unavailable. This can happen for older models. . [optional]  # noqa: E501
            shared_through ([str]): If a model has been shared with the user then this will show through which group(s) it has been shared. Won't be set if the user requesting the resource owns it. Deprecated: Please use `sharing` to determine how the access for the model was achieved. . [optional]  # noqa: E501
            sharing (ModelSharing): [optional]  # noqa: E501
            detail (str): The error provided by Alchemite for why the model failed to train if  an issue occurs during model creation . [optional]  # noqa: E501
        """

        training_method = kwargs.get('training_method', "alchemite")
        _check_type = kwargs.pop('_check_type', True)
        _spec_property_naming = kwargs.pop('_spec_property_naming', False)
        _path_to_item = kwargs.pop('_path_to_item', ())
        _configuration = kwargs.pop('_configuration', None)
        _visited_composed_classes = kwargs.pop('_visited_composed_classes', ())

        if args:
            raise ApiTypeError(
                "Invalid positional arguments=%s passed to %s. Remove those invalid positional arguments." % (
                    args,
                    self.__class__.__name__,
                ),
                path_to_item=_path_to_item,
                valid_classes=(self.__class__,),
            )

        self._data_store = {}
        self._check_type = _check_type
        self._spec_property_naming = _spec_property_naming
        self._path_to_item = _path_to_item
        self._configuration = _configuration
        self._visited_composed_classes = _visited_composed_classes + (self.__class__,)

        self.name = name
        self.training_method = training_method
        for var_name, var_value in kwargs.items():
            if var_name not in self.attribute_map and \
                        self._configuration is not None and \
                        self._configuration.discard_unknown_keys and \
                        self.additional_properties_type is None:
                # discard variable.
                continue
            setattr(self, var_name, var_value)
            if var_name in self.read_only_vars:
                raise ApiAttributeError(f"`{var_name}` is a read-only attribute. Use `from_openapi_data` to instantiate "
                                     f"class with read only attributes.")
