"""Persistence helpers for saving, loading, and pruning benchmark runs."""

from __future__ import annotations

import json
from dataclasses import asdict
from datetime import datetime, timezone
from pathlib import Path

from .run_model import Run


def get_root(base: Path | None = None) -> Path:
    """Get .pybenchx root directory and ensure it exists with README."""
    base = base or Path.cwd()
    root = (base / ".pybenchx").resolve()

    _ensure_structure(root)

    return root


def _ensure_structure(root: Path) -> None:
    """Ensure basic directory structure exists."""
    for sub in (
        root / "runs",
        root / "baselines",
        root / "exports",
        root / "exports" / "chart",
    ):
        sub.mkdir(parents=True, exist_ok=True)

    readme_path = root / "README.md"
    if not readme_path.exists():
        readme_content = """# PyBenchX Storage

Stores benchmark runs and baselines for your project.

## Structure

- **`runs/`** - Auto-saved benchmark history (complete record)
- **`baselines/`** - Named baselines for comparison

## Main Commands

```bash
pybench list                           # list runs and baselines
pybench stats                          # storage statistics
pybench clean --keep 100               # clean old runs

pybench examples/ --save-baseline main # create baseline
pybench examples/ --vs main            # compare with baseline
pybench examples/ --vs last            # compare with last run
```

## Documentation

- **Repository:** https://github.com/fullzer4/pybenchx
- **Commands:** `pybench --help` and `pybench run --help`
- **CLI Guide:** https://github.com/fullzer4/pybenchx#readme

---
*Auto-generated by pybenchx | Directory gitignored by default*
"""
        readme_path.write_text(readme_content, encoding="utf-8")


def ensure_dirs(root: Path) -> None:
    """Create standard directory structure (legacy, now handled by get_root)."""
    _ensure_structure(root)


def _ts_now() -> str:
    """Generate timestamp in format: 2025-08-30T2132Z."""
    return datetime.now(timezone.utc).strftime("%Y-%m-%dT%H%MZ")


def run_filename(meta: dict, label: str | None = None) -> str:
    """Generate filename for a run."""
    ts = meta.get("started_at") or _ts_now()
    branch = (meta.get("git") or {}).get("branch") or "detached"
    sha = (meta.get("git") or {}).get("sha") or "unknown"
    profile = meta.get("profile") or "quick"
    parts = [ts, f"{branch}@{sha}", f"{profile}"]
    if label:
        parts.append(label)
    if label:
        stem = "_".join(parts[:-1])
        return f"{stem}.{parts[-1]}.json"
    return f"{ts}_{branch}@{sha}.{profile}.json"


def auto_save_run(run: Run, *, root: Path | None = None) -> Path:
    """Auto-save every run to .pybenchx/runs/ (for history tracking).

    This enables:
    - Always having a baseline to compare against
    - Historical performance tracking
    - Easy rollback to previous runs
    """
    return save_run(run, label=None, root=root)


def save_run(run: Run, label: str | None = None, *, root: Path | None = None) -> Path:
    """Save a run with optional label."""
    root = get_root(root)
    ensure_dirs(root)
    meta = asdict(run.meta)
    fname = run_filename(meta, label)
    path = root / "runs" / fname
    with path.open("w", encoding="utf-8") as f:
        json.dump(asdict(run), f, indent=2)
    return path


def save_baseline(run: Run, name: str, *, root: Path | None = None) -> Path:
    """Save a named baseline."""
    root = get_root(root)
    ensure_dirs(root)
    path = root / "baselines" / f"{name}.json"
    with path.open("w", encoding="utf-8") as f:
        json.dump(asdict(run), f, indent=2)
    return path


def run_basename(run: Run, label: str | None = None) -> str:
    """Return the canonical filename stem for a run (without extension)."""
    meta = asdict(run.meta)
    fname = run_filename(meta, label)
    return Path(fname).stem


def default_export_path(
    run: Run,
    fmt: str,
    *,
    root: Path | None = None,
    base_name: str | None = None,
) -> Path:
    """Return the default export path under .pybenchx for a given format."""
    root = get_root(root)
    ensure_dirs(root)

    fmt_norm = fmt.lower()
    if fmt_norm in {"md", "markdown"}:
        ext = ".md"
        dir_name = "markdown"
    elif fmt_norm == "csv":
        ext = ".csv"
        dir_name = "csv"
    elif fmt_norm == "chart":
        ext = ".html"
        dir_name = "chart"
    else:  # default json
        ext = ".json"
        dir_name = fmt_norm

    export_dir = root / "exports" / dir_name
    export_dir.mkdir(parents=True, exist_ok=True)

    stem = base_name or run_basename(run)
    return export_dir / f"{stem}{ext}"


def load_run(path: Path) -> Run:
    """Load a run from JSON file."""
    from .run_model import Run, RunMeta, StatSummary, VariantResult
    data = json.loads(Path(path).read_text(encoding="utf-8"))
    meta = RunMeta(**data["meta"])
    results = []
    for vr in data.get("results", []):
        stats = StatSummary(**vr["stats"])
        results.append(VariantResult(**{**vr, "stats": stats}))
    return Run(
        meta=meta,
        suite_signature=data.get("suite_signature", ""),
        results=results,
    )


def load_baseline(name_or_path: str, *, root: Path | None = None) -> tuple[str, Run]:
    """Load a baseline by name or path.

    Usage:
        load_baseline("main")           # from .pybenchx/baselines/main.json
        load_baseline("path/to/run.json")  # absolute path
    """
    p = Path(name_or_path)
    if p.suffix == ".json" and p.exists():
        return (p.name, load_run(p))
    root = get_root(root)
    path = root / "baselines" / f"{name_or_path}.json"
    return (path.name, load_run(path))


def get_latest_run(*, root: Path | None = None) -> Run | None:
    """Get the most recent run from .pybenchx/runs/."""
    root = get_root(root)
    runs_dir = root / "runs"
    if not runs_dir.exists():
        return None

    run_files = sorted(
        runs_dir.glob("*.json"),
        key=lambda p: p.stat().st_mtime,
        reverse=True,
    )
    if not run_files:
        return None

    return load_run(run_files[0])


def list_baselines(*, root: Path | None = None) -> list[str]:
    """List all available baseline names."""
    root = get_root(root)
    baselines_dir = root / "baselines"
    if not baselines_dir.exists():
        return []

    return sorted([p.stem for p in baselines_dir.glob("*.json")])


def list_recent_runs(limit: int = 10, *, root: Path | None = None) -> list[Path]:
    """List recent runs (most recent first)."""
    root = get_root(root)
    runs_dir = root / "runs"
    if not runs_dir.exists():
        return []

    run_files = sorted(
        runs_dir.glob("*.json"),
        key=lambda p: p.stat().st_mtime,
        reverse=True,
    )
    return run_files[:limit]


def clean_old_runs(keep: int = 100, *, root: Path | None = None) -> int:
    """Clean old auto-saved runs, keeping only the N most recent.

    Args:
        keep: Number of recent runs to keep (default: 100)
        root: Root directory (default: current .pybenchx)

    Returns:
        Number of runs deleted
    """
    root = get_root(root)
    runs_dir = root / "runs"
    if not runs_dir.exists():
        return 0

    # Get all auto-saved runs (without labels)
    run_files = sorted(
        [p for p in runs_dir.glob("*.json") if "." + p.stem.split(".")[-1] == ".json"],
        key=lambda p: p.stat().st_mtime,
        reverse=True
    )

    # Keep labeled runs (they have an extra component)
    labeled = [p for p in runs_dir.glob("*.json") if len(p.stem.split(".")) > 1]
    auto_saved = [p for p in run_files if p not in labeled]

    if len(auto_saved) <= keep:
        return 0

    to_delete = auto_saved[keep:]
    deleted = 0
    for path in to_delete:
        try:
            path.unlink()
            deleted += 1
        except Exception:
            pass

    return deleted


def get_storage_stats(*, root: Path | None = None) -> dict:
    """Get statistics about stored runs and baselines.

    Returns:
        Dictionary with:
        - total_runs: Total number of runs
        - labeled_runs: Number of labeled runs
        - baselines: Number of baselines
        - total_size_mb: Total disk usage in MB
        - oldest_run: Timestamp of oldest run
        - newest_run: Timestamp of newest run
    """
    root = get_root(root)

    stats = {
        "total_runs": 0,
        "labeled_runs": 0,
        "baselines": 0,
        "total_size_mb": 0.0,
        "oldest_run": None,
        "newest_run": None,
    }

    runs_dir = root / "runs"
    if runs_dir.exists():
        run_files = list(runs_dir.glob("*.json"))
        stats["total_runs"] = len(run_files)
        stats["labeled_runs"] = len(
            [p for p in run_files if len(p.stem.split(".")) > 1]
        )

        if run_files:
            sorted_runs = sorted(run_files, key=lambda p: p.stat().st_mtime)
            stats["oldest_run"] = datetime.fromtimestamp(
                sorted_runs[0].stat().st_mtime
            ).isoformat()
            stats["newest_run"] = datetime.fromtimestamp(
                sorted_runs[-1].stat().st_mtime
            ).isoformat()

        for f in run_files:
            stats["total_size_mb"] += f.stat().st_size / (1024 * 1024)

    baselines_dir = root / "baselines"
    if baselines_dir.exists():
        baseline_files = list(baselines_dir.glob("*.json"))
        stats["baselines"] = len(baseline_files)

        for f in baseline_files:
            stats["total_size_mb"] += f.stat().st_size / (1024 * 1024)

    stats["total_size_mb"] = round(stats["total_size_mb"], 2)
    return stats


__all__ = [
    "get_root",
    "ensure_dirs",
    "save_run",
    "auto_save_run",
    "save_baseline",
    "load_run",
    "load_baseline",
    "get_latest_run",
    "list_baselines",
    "list_recent_runs",
    "clean_old_runs",
    "get_storage_stats",
    "run_filename",
]

