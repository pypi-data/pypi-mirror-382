"""
æ ¸å¿ƒç›‘æ§æ¨¡å—

ä¸»è¦åŠŸèƒ½ï¼š
1. ç›‘æ§æ‰€æœ‰è·¯ç”±æ¥å£çš„è®¿é—®è¯·æ±‚
2. è®°å½•è¯¦ç»†çš„è¯·æ±‚ä¿¡æ¯ï¼ˆIPã€è®¾å¤‡ã€è¯·æ±‚å¤´ã€è¯·æ±‚ä½“ç­‰ï¼‰
3. æä¾›ç»Ÿè®¡åˆ†æåŠŸèƒ½
4. å¼‚å¸¸å¤„ç†å’Œæ•°æ®æ¸…ç†

"""

import os
import json
import time
import uuid
import pymysql
import hashlib
import functools
from datetime import datetime, timedelta
from typing import Dict, Any
from urllib.parse import urlparse
from dbutils.pooled_db import PooledDB # type: ignore
from mdbq.myconf import myconf # type: ignore
# from mdbq.log import mylogger
from flask import request, g
import re
import ipaddress

parser = myconf.ConfigParser()
host, port, username, password = parser.get_section_values(
    file_path=os.path.join(os.path.expanduser("~"), 'spd.txt'),
    section='mysql',
    keys=['host', 'port', 'username', 'password'],
)

# logger = mylogger.MyLogger(
#     logging_mode='file',
#     log_level='info',
#     log_format='json',
#     max_log_size=50,
#     backup_count=5,
#     enable_async=False,  # æ˜¯å¦å¯ç”¨å¼‚æ­¥æ—¥å¿—
#     sample_rate=1,  # é‡‡æ ·DEBUG/INFOæ—¥å¿—
#     sensitive_fields=[],  #  æ•æ„Ÿå­—æ®µè¿‡æ»¤
#     enable_metrics=False,  # æ˜¯å¦å¯ç”¨æ€§èƒ½æŒ‡æ ‡
# )


class RouteMonitor:
    """è·¯ç”±ç›‘æ§æ ¸å¿ƒç±»"""
    
    def __init__(self, database='api_monitor_logs'):
        """åˆå§‹åŒ–ç›‘æ§ç³»ç»Ÿ"""
        self.database = database
        self.init_database_pool()
        self.init_database_tables()

    def init_database_pool(self):
        """åˆå§‹åŒ–æ•°æ®åº“è¿æ¥æ± """
        try:
            self.pool = PooledDB(
                creator=pymysql,
                maxconnections=2,  # ç›‘æ§ç³»ç»Ÿè¿æ¥æ•°è¾ƒå°
                mincached=1,
                maxcached=2,
                blocking=True,
                host=host,
                port=int(port),
                user=username,
                password=password,
                ping=1,
                charset='utf8mb4',
                cursorclass=pymysql.cursors.DictCursor
            )

            # åˆ›å»ºæ•°æ®åº“å¹¶åˆ‡æ¢
            connection = self.pool.connection()
            try:
                with connection.cursor() as cursor:
                    cursor.execute(f"CREATE DATABASE IF NOT EXISTS `{self.database}` DEFAULT CHARACTER SET utf8mb4 COLLATE utf8mb4_0900_ai_ci")
                    cursor.execute(f"USE `{self.database}`")
            finally:
                connection.close()
                
        except Exception as e:
            # logger.error("æ•°æ®åº“è¿æ¥æ± åˆå§‹åŒ–å¤±è´¥", {
            #     "é”™è¯¯ä¿¡æ¯": str(e),
            #     "æ•°æ®åº“": self.database
            # })
            raise
    
    def ensure_database_context(self, cursor):
        """ç¡®ä¿å½“å‰æ¸¸æ ‡å¤„äºæ­£ç¡®çš„æ•°æ®åº“ä¸Šä¸‹æ–‡ä¸­"""
        try:
            cursor.execute(f"USE `{self.database}`")
        except Exception as e:
            # logger.warning("åˆ‡æ¢æ•°æ®åº“ä¸Šä¸‹æ–‡å¤±è´¥ï¼Œå°è¯•é‡æ–°åˆ›å»º", {
            #     "æ•°æ®åº“": self.database,
            #     "é”™è¯¯": str(e)
            # })
            cursor.execute(f"CREATE DATABASE IF NOT EXISTS `{self.database}` DEFAULT CHARACTER SET utf8mb4 COLLATE utf8mb4_0900_ai_ci")
            cursor.execute(f"USE `{self.database}`")
        
    def init_database_tables(self):
        """åˆå§‹åŒ–æ•°æ®åº“è¡¨ç»“æ„"""
        try:
            connection = self.pool.connection()
            try:
                with connection.cursor() as cursor:
                    # ç¡®ä¿ä½¿ç”¨æ­£ç¡®çš„æ•°æ®åº“ä¸Šä¸‹æ–‡
                    self.ensure_database_context(cursor)
                    
                    # åˆ›å»ºè¯¦ç»†è¯·æ±‚è®°å½•è¡¨ - ä¿®å¤MySQL 8.4+å…¼å®¹æ€§
                    cursor.execute("""
                        CREATE TABLE IF NOT EXISTS `api_request_logs` (
                            `id` BIGINT AUTO_INCREMENT PRIMARY KEY COMMENT 'ä¸»é”®ID',
                            `request_id` VARCHAR(128) NOT NULL COMMENT 'è¯·æ±‚å”¯ä¸€æ ‡è¯†',
                            `timestamp` DATETIME(3) NOT NULL DEFAULT CURRENT_TIMESTAMP(3) COMMENT 'è¯·æ±‚æ—¶é—´ï¼ˆç²¾ç¡®åˆ°æ¯«ç§’ï¼‰',
                            `method` VARCHAR(10) NOT NULL COMMENT 'HTTPæ–¹æ³•',
                            `endpoint` VARCHAR(500) NOT NULL COMMENT 'è¯·æ±‚ç«¯ç‚¹',
                            `full_url` TEXT COMMENT 'å®Œæ•´URL',
                            `client_ip` VARCHAR(45) NOT NULL COMMENT 'å®¢æˆ·ç«¯IPåœ°å€',
                            `real_ip` VARCHAR(45) COMMENT 'çœŸå®IPåœ°å€',
                            `forwarded_ips` TEXT COMMENT 'è½¬å‘IPé“¾',
                            `user_agent` TEXT COMMENT 'ç”¨æˆ·ä»£ç†',
                            `referer` VARCHAR(1000) COMMENT 'æ¥æºé¡µé¢',
                            `host` VARCHAR(255) COMMENT 'è¯·æ±‚ä¸»æœº',
                            `scheme` VARCHAR(10) COMMENT 'åè®®ç±»å‹',
                            `port` INT COMMENT 'ç«¯å£å·',
                            `request_headers` JSON COMMENT 'è¯·æ±‚å¤´ä¿¡æ¯',
                            `request_params` JSON COMMENT 'è¯·æ±‚å‚æ•°',
                            `request_body` LONGTEXT COMMENT 'è¯·æ±‚ä½“å†…å®¹',
                            `request_size` INT DEFAULT 0 COMMENT 'è¯·æ±‚å¤§å°ï¼ˆå­—èŠ‚ï¼‰',
                            `response_status` INT COMMENT 'å“åº”çŠ¶æ€ç ',
                            `response_size` INT COMMENT 'å“åº”å¤§å°ï¼ˆå­—èŠ‚ï¼‰',
                            `process_time` DECIMAL(10,3) COMMENT 'å¤„ç†æ—¶é—´ï¼ˆæ¯«ç§’ï¼‰',
                            `session_id` VARCHAR(128) COMMENT 'ä¼šè¯ID',
                            `user_id` VARCHAR(64) COMMENT 'ç”¨æˆ·ID',
                            `auth_token` TEXT COMMENT 'è®¤è¯ä»¤ç‰Œï¼ˆè„±æ•ï¼‰',
                            `device_fingerprint` VARCHAR(256) COMMENT 'è®¾å¤‡æŒ‡çº¹',
                            `device_info` JSON COMMENT 'è®¾å¤‡ä¿¡æ¯',
                            `geo_country` VARCHAR(100) COMMENT 'åœ°ç†ä½ç½®-å›½å®¶',
                            `geo_region` VARCHAR(100) COMMENT 'åœ°ç†ä½ç½®-åœ°åŒº',
                            `geo_city` VARCHAR(100) COMMENT 'åœ°ç†ä½ç½®-åŸå¸‚',
                            `is_bot` BOOLEAN DEFAULT FALSE COMMENT 'æ˜¯å¦ä¸ºæœºå™¨äºº',
                            `is_mobile` BOOLEAN DEFAULT FALSE COMMENT 'æ˜¯å¦ä¸ºç§»åŠ¨è®¾å¤‡',
                            `browser_name` VARCHAR(50) COMMENT 'æµè§ˆå™¨åç§°',
                            `browser_version` VARCHAR(20) COMMENT 'æµè§ˆå™¨ç‰ˆæœ¬',
                            `os_name` VARCHAR(50) COMMENT 'æ“ä½œç³»ç»Ÿåç§°',
                            `os_version` VARCHAR(20) COMMENT 'æ“ä½œç³»ç»Ÿç‰ˆæœ¬',
                            `error_message` TEXT COMMENT 'é”™è¯¯ä¿¡æ¯',
                            `business_data` JSON COMMENT 'ä¸šåŠ¡æ•°æ®',
                            `tags` JSON COMMENT 'æ ‡ç­¾ä¿¡æ¯',
                            UNIQUE KEY `uk_request_id` (`request_id`),
                            INDEX `idx_timestamp` (`timestamp`),
                            INDEX `idx_endpoint` (`endpoint`(191)),
                            INDEX `idx_client_ip` (`client_ip`),
                            INDEX `idx_user_id` (`user_id`),
                            INDEX `idx_status` (`response_status`),
                            INDEX `idx_method_endpoint` (`method`, `endpoint`(191)),
                            INDEX `idx_timestamp_endpoint` (`timestamp`, `endpoint`(191))
                        ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci 
                        COMMENT='APIè¯·æ±‚è¯¦ç»†æ—¥å¿—è¡¨';
                    """)
                    # åˆ›å»ºè®¿é—®ç»Ÿè®¡æ±‡æ€»è¡¨
                    cursor.execute("""
                        CREATE TABLE IF NOT EXISTS `api_access_statistics` (
                            `id` BIGINT AUTO_INCREMENT PRIMARY KEY COMMENT 'ä¸»é”®ID',
                            `date` DATE NOT NULL COMMENT 'ç»Ÿè®¡æ—¥æœŸ',
                            `hour` TINYINT NOT NULL DEFAULT 0 COMMENT 'å°æ—¶ï¼ˆ0-23ï¼‰',
                            `endpoint` VARCHAR(500) NOT NULL COMMENT 'ç«¯ç‚¹',
                            `method` VARCHAR(10) NOT NULL COMMENT 'HTTPæ–¹æ³•',
                            `total_requests` INT UNSIGNED DEFAULT 0 COMMENT 'æ€»è¯·æ±‚æ•°',
                            `success_requests` INT UNSIGNED DEFAULT 0 COMMENT 'æˆåŠŸè¯·æ±‚æ•°',
                            `error_requests` INT UNSIGNED DEFAULT 0 COMMENT 'é”™è¯¯è¯·æ±‚æ•°',
                            `unique_ips` INT UNSIGNED DEFAULT 0 COMMENT 'å”¯ä¸€IPæ•°',
                            `unique_users` INT UNSIGNED DEFAULT 0 COMMENT 'å”¯ä¸€ç”¨æˆ·æ•°',
                            `avg_response_time` DECIMAL(10,3) DEFAULT 0 COMMENT 'å¹³å‡å“åº”æ—¶é—´ï¼ˆæ¯«ç§’ï¼‰',
                            `max_response_time` DECIMAL(10,3) DEFAULT 0 COMMENT 'æœ€å¤§å“åº”æ—¶é—´ï¼ˆæ¯«ç§’ï¼‰',
                            `min_response_time` DECIMAL(10,3) DEFAULT 0 COMMENT 'æœ€å°å“åº”æ—¶é—´ï¼ˆæ¯«ç§’ï¼‰',
                            `total_request_size` BIGINT UNSIGNED DEFAULT 0 COMMENT 'æ€»è¯·æ±‚å¤§å°ï¼ˆå­—èŠ‚ï¼‰',
                            `total_response_size` BIGINT UNSIGNED DEFAULT 0 COMMENT 'æ€»å“åº”å¤§å°ï¼ˆå­—èŠ‚ï¼‰',
                            `bot_requests` INT UNSIGNED DEFAULT 0 COMMENT 'æœºå™¨äººè¯·æ±‚æ•°',
                            `mobile_requests` INT UNSIGNED DEFAULT 0 COMMENT 'ç§»åŠ¨ç«¯è¯·æ±‚æ•°',
                            `created_at` TIMESTAMP DEFAULT CURRENT_TIMESTAMP COMMENT 'åˆ›å»ºæ—¶é—´',
                            `updated_at` TIMESTAMP DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT 'æ›´æ–°æ—¶é—´',
                            UNIQUE KEY `uk_date_hour_endpoint_method` (`date`, `hour`, `endpoint`(191), `method`),
                            INDEX `idx_date` (`date`),
                            INDEX `idx_endpoint` (`endpoint`(191)),
                            INDEX `idx_date_endpoint` (`date`, `endpoint`(191))
                        ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci 
                        COMMENT='APIè®¿é—®ç»Ÿè®¡æ±‡æ€»è¡¨';
                    """)
                    
                    # åˆ›å»ºIPè®¿é—®ç»Ÿè®¡è¡¨
                    cursor.execute("""
                        CREATE TABLE IF NOT EXISTS `ip_access_statistics` (
                            `id` BIGINT AUTO_INCREMENT PRIMARY KEY COMMENT 'ä¸»é”®ID',
                            `date` DATE NOT NULL COMMENT 'ç»Ÿè®¡æ—¥æœŸ',
                            `ip_address` VARCHAR(45) NOT NULL COMMENT 'IPåœ°å€',
                            `total_requests` INT UNSIGNED DEFAULT 0 COMMENT 'æ€»è¯·æ±‚æ•°',
                            `unique_endpoints` INT UNSIGNED DEFAULT 0 COMMENT 'è®¿é—®çš„å”¯ä¸€ç«¯ç‚¹æ•°',
                            `success_rate` DECIMAL(5,2) DEFAULT 0 COMMENT 'æˆåŠŸç‡ï¼ˆ%ï¼‰',
                            `avg_response_time` DECIMAL(10,3) DEFAULT 0 COMMENT 'å¹³å‡å“åº”æ—¶é—´ï¼ˆæ¯«ç§’ï¼‰',
                            `first_access` DATETIME COMMENT 'é¦–æ¬¡è®¿é—®æ—¶é—´',
                            `last_access` DATETIME COMMENT 'æœ€åè®¿é—®æ—¶é—´',
                            `user_agent_hash` VARCHAR(64) COMMENT 'ç”¨æˆ·ä»£ç†å“ˆå¸Œ',
                            `is_suspicious` BOOLEAN DEFAULT FALSE COMMENT 'æ˜¯å¦å¯ç–‘',
                            `risk_score` TINYINT UNSIGNED DEFAULT 0 COMMENT 'é£é™©è¯„åˆ†ï¼ˆ0-100ï¼‰',
                            `geo_country` VARCHAR(50) COMMENT 'åœ°ç†ä½ç½®-å›½å®¶',
                            `geo_region` VARCHAR(100) COMMENT 'åœ°ç†ä½ç½®-åœ°åŒº',
                            `created_at` TIMESTAMP DEFAULT CURRENT_TIMESTAMP COMMENT 'åˆ›å»ºæ—¶é—´',
                            `updated_at` TIMESTAMP DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT 'æ›´æ–°æ—¶é—´',
                            UNIQUE KEY `uk_date_ip` (`date`, `ip_address`),
                            INDEX `idx_date` (`date`),
                            INDEX `idx_ip` (`ip_address`),
                            INDEX `idx_suspicious` (`is_suspicious`),
                            INDEX `idx_risk_score` (`risk_score`)
                        ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci 
                        COMMENT='IPè®¿é—®ç»Ÿè®¡è¡¨';
                    """)
                    # åˆ›å»ºç³»ç»Ÿæ€§èƒ½ç»Ÿè®¡è¡¨
                    cursor.execute("""
                        CREATE TABLE IF NOT EXISTS `system_performance_stats` (
                            `id` BIGINT AUTO_INCREMENT PRIMARY KEY COMMENT 'ä¸»é”®ID',
                            `timestamp` DATETIME NOT NULL COMMENT 'ç»Ÿè®¡æ—¶é—´',
                            `total_requests_per_minute` INT UNSIGNED DEFAULT 0 COMMENT 'æ¯åˆ†é’Ÿæ€»è¯·æ±‚æ•°',
                            `avg_response_time` DECIMAL(10,3) DEFAULT 0 COMMENT 'å¹³å‡å“åº”æ—¶é—´ï¼ˆæ¯«ç§’ï¼‰',
                            `error_rate` DECIMAL(5,2) DEFAULT 0 COMMENT 'é”™è¯¯ç‡ï¼ˆ%ï¼‰',
                            `active_ips` INT UNSIGNED DEFAULT 0 COMMENT 'æ´»è·ƒIPæ•°',
                            `peak_concurrent_requests` INT UNSIGNED DEFAULT 0 COMMENT 'å³°å€¼å¹¶å‘è¯·æ±‚æ•°',
                            `slowest_endpoint` VARCHAR(500) COMMENT 'æœ€æ…¢ç«¯ç‚¹',
                            `slowest_response_time` DECIMAL(10,3) DEFAULT 0 COMMENT 'æœ€æ…¢å“åº”æ—¶é—´ï¼ˆæ¯«ç§’ï¼‰',
                            `most_accessed_endpoint` VARCHAR(500) COMMENT 'æœ€çƒ­é—¨ç«¯ç‚¹',
                            `most_accessed_count` INT UNSIGNED DEFAULT 0 COMMENT 'æœ€çƒ­é—¨ç«¯ç‚¹è®¿é—®æ¬¡æ•°',
                            INDEX `idx_timestamp` (`timestamp`)
                        ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci 
                        COMMENT='ç³»ç»Ÿæ€§èƒ½ç»Ÿè®¡è¡¨';
                    """)
                connection.commit()
                
            finally:
                connection.close()
                
        except Exception as e:
            # logger.error("æ•°æ®åº“è¡¨ç»“æ„åˆå§‹åŒ–å¤±è´¥", {
            #     "é”™è¯¯ä¿¡æ¯": str(e),
            #     "é”™è¯¯ç±»å‹": type(e).__name__,
            #     "æ•°æ®åº“": self.database,
            #     "å½±å“": "ç›‘æ§ç³»ç»Ÿå¯èƒ½æ— æ³•æ­£å¸¸å·¥ä½œ"
            # })
            # é™é»˜å¤„ç†åˆå§‹åŒ–é”™è¯¯ï¼Œé¿å…å½±å“ä¸»åº”ç”¨
            pass
    
    def generate_request_id(self) -> str:
        """ç”Ÿæˆå”¯ä¸€çš„è¯·æ±‚ID"""
        timestamp = str(int(time.time() * 1000))  # æ¯«ç§’æ—¶é—´æˆ³
        random_part = uuid.uuid4().hex[:8]
        return f"req_{timestamp}_{random_part}"
    
    def extract_device_info(self, user_agent: str) -> Dict[str, Any]:
        """æå–è®¾å¤‡ä¿¡æ¯"""
        device_info = {
            'is_mobile': False,
            'is_bot': False,
            'browser_name': 'Unknown',
            'browser_version': 'Unknown',
            'os_name': 'Unknown',
            'os_version': 'Unknown'
        }
        
        if not user_agent:
            return device_info
        
        user_agent_lower = user_agent.lower()
        
        # æ£€æµ‹ç§»åŠ¨è®¾å¤‡
        mobile_keywords = ['mobile', 'android', 'iphone', 'ipad', 'ipod', 'windows phone']
        device_info['is_mobile'] = any(keyword in user_agent_lower for keyword in mobile_keywords)
        
        # æ£€æµ‹æœºå™¨äºº
        bot_keywords = ['bot', 'crawler', 'spider', 'scraper', 'curl', 'wget', 'python-requests']
        device_info['is_bot'] = any(keyword in user_agent_lower for keyword in bot_keywords)
        
        # æµè§ˆå™¨æ£€æµ‹
        browsers = [
            ('chrome', r'chrome/(\d+)'),
            ('firefox', r'firefox/(\d+)'),
            ('safari', r'safari/(\d+)'),
            ('edge', r'edge/(\d+)'),
            ('opera', r'opera/(\d+)')
        ]
        
        for browser, pattern in browsers:
            match = re.search(pattern, user_agent_lower)
            if match:
                device_info['browser_name'] = browser.title()
                device_info['browser_version'] = match.group(1)
                break
        
        # æ“ä½œç³»ç»Ÿæ£€æµ‹
        os_patterns = [
            ('Windows', r'windows nt (\d+\.\d+)'),
            ('macOS', r'mac os x (\d+_\d+)'),
            ('Linux', r'linux'),
            ('Android', r'android (\d+)'),
            ('iOS', r'os (\d+_\d+)')
        ]
        
        for os_name, pattern in os_patterns:
            match = re.search(pattern, user_agent_lower)
            if match:
                device_info['os_name'] = os_name
                if len(match.groups()) > 0:
                    device_info['os_version'] = match.group(1).replace('_', '.')
                break
        
        return device_info
    
    def generate_device_fingerprint(self, request_data: Dict) -> str:
        """ç”Ÿæˆè®¾å¤‡æŒ‡çº¹"""
        fingerprint_data = {
            'user_agent': request_data.get('user_agent', ''),
            'accept_language': request_data.get('request_headers', {}).get('Accept-Language', ''),
            'accept_encoding': request_data.get('request_headers', {}).get('Accept-Encoding', ''),
            'connection': request_data.get('request_headers', {}).get('Connection', ''),
        }
        
        fingerprint_str = json.dumps(fingerprint_data, sort_keys=True)
        return hashlib.md5(fingerprint_str.encode()).hexdigest()
    
    def sanitize_data(self, data: Any, max_length: int = 10000) -> Any:
        """æ•°æ®æ¸…ç†å’Œæˆªæ–­"""
        if data is None:
            return None
        
        if isinstance(data, str):
            # ç§»é™¤æ•æ„Ÿä¿¡æ¯
            sensitive_patterns = [
                (r'password["\']?\s*[:=]\s*["\']?[^"\'&\s]+', 'password: [REDACTED]'),
                (r'token["\']?\s*[:=]\s*["\']?[^"\'&\s]+', 'token: [REDACTED]'),
                (r'key["\']?\s*[:=]\s*["\']?[^"\'&\s]+', 'key: [REDACTED]'),
            ]
            
            sanitized = data
            for pattern, replacement in sensitive_patterns:
                sanitized = re.sub(pattern, replacement, sanitized, flags=re.IGNORECASE)
            
            # æˆªæ–­è¿‡é•¿çš„å†…å®¹
            if len(sanitized) > max_length:
                sanitized = sanitized[:max_length] + '...[TRUNCATED]'
            
            return sanitized
        
        elif isinstance(data, dict):
            sanitized = {}
            for key, value in data.items():
                if key.lower() in ['password', 'token', 'key', 'secret']:
                    sanitized[key] = '[REDACTED]'
                else:
                    sanitized[key] = self.sanitize_data(value, max_length)
            return sanitized
        
        elif isinstance(data, list):
            return [self.sanitize_data(item, max_length) for item in data[:100]]  # é™åˆ¶åˆ—è¡¨é•¿åº¦
        
        return data
    
    def get_real_ip(self, request) -> tuple:
        """è·å–çœŸå®IPåœ°å€"""
        # IPåœ°å€ä¼˜å…ˆçº§é¡ºåº
        ip_headers = [
            'X-Forwarded-For',
            'X-Real-IP',
            'CF-Connecting-IP',  # Cloudflare
            'X-Client-IP',
            'X-Forwarded',
            'Forwarded-For',
            'Forwarded'
        ]
        
        forwarded_ips = []
        real_ip = request.remote_addr
        
        for header in ip_headers:
            header_value = request.headers.get(header)
            if header_value:
                # å¤„ç†å¤šä¸ªIPçš„æƒ…å†µï¼ˆç”¨é€—å·åˆ†éš”ï¼‰
                ips = [ip.strip() for ip in header_value.split(',')]
                forwarded_ips.extend(ips)
                
                # å–ç¬¬ä¸€ä¸ªæœ‰æ•ˆçš„IPä½œä¸ºçœŸå®IP
                for ip in ips:
                    if self.is_valid_ip(ip) and not self.is_private_ip(ip):
                        real_ip = ip
                        break
                
                if real_ip != request.remote_addr:
                    break
        
        return real_ip, forwarded_ips
    
    def is_valid_ip(self, ip: str) -> bool:
        """éªŒè¯IPåœ°å€æ ¼å¼"""
        try:
            ipaddress.ip_address(ip)
            return True
        except ValueError:
            return False
    
    def is_private_ip(self, ip: str) -> bool:
        """æ£€æŸ¥æ˜¯å¦ä¸ºç§æœ‰IP"""
        try:
            return ipaddress.ip_address(ip).is_private
        except ValueError:
            return False
    
    def collect_request_data(self, request) -> Dict[str, Any]:
        """æ”¶é›†è¯·æ±‚æ•°æ®"""
        start_time = getattr(g, 'request_start_time', time.time())
        request_id = self.generate_request_id()
        
        # è®¾ç½®è¯·æ±‚IDåˆ°å…¨å±€å˜é‡ä¸­ï¼Œä¾›åç»­ä½¿ç”¨
        g.request_id = request_id
        # è·å–çœŸå®IP
        real_ip, forwarded_ips = self.get_real_ip(request)
        
        # è·å–è¯·æ±‚å¤´ä¿¡æ¯
        headers = dict(request.headers)
        sanitized_headers = self.sanitize_data(headers)
        
        # è·å–è¯·æ±‚å‚æ•°
        request_params = {}
        if request.args:
            request_params.update(dict(request.args))
        
        # è·å–è¯·æ±‚ä½“
        request_body = None
        request_size = 0
        
        try:
            if request.method in ['POST', 'PUT', 'PATCH']:
                if request.is_json:
                    request_body = request.get_json()
                elif request.form:
                    request_body = dict(request.form)
                else:
                    body_data = request.get_data()
                    if body_data:
                        try:
                            request_body = body_data.decode('utf-8')
                        except UnicodeDecodeError:
                            request_body = f"[BINARY_DATA:{len(body_data)}_bytes]"
                
                if request_body:
                    request_size = len(str(request_body).encode('utf-8'))
        except Exception as e:
            request_body = "[ERROR_READING_BODY]"
            # logger.warning("è¯»å–è¯·æ±‚ä½“å¤±è´¥", {
            #     "è¯·æ±‚ID": request_id,
            #     "é”™è¯¯": str(e)
            # })
        
        # æ¸…ç†æ•æ„Ÿæ•°æ®
        sanitized_body = self.sanitize_data(request_body)
        sanitized_params = self.sanitize_data(request_params)
        
        # è®¾å¤‡ä¿¡æ¯æå–
        user_agent = request.headers.get('User-Agent', '')
        device_info = self.extract_device_info(user_agent)
        # URLè§£æ
        parsed_url = urlparse(request.url)
        
        # æ„å»ºè¯·æ±‚æ•°æ®
        request_data = {
            'request_id': request_id,
            'timestamp': datetime.now(),
            'method': request.method,
            'endpoint': request.endpoint or request.path,
            'full_url': request.url,
            'client_ip': request.remote_addr,
            'real_ip': real_ip,
            'forwarded_ips': json.dumps(forwarded_ips) if forwarded_ips else None,
            'user_agent': user_agent,
            'referer': request.headers.get('Referer'),
            'host': request.headers.get('Host'),
            'scheme': parsed_url.scheme,
            'port': parsed_url.port,
            'request_headers': json.dumps(sanitized_headers),
            'request_params': json.dumps(sanitized_params) if sanitized_params else None,
            'request_body': json.dumps(sanitized_body) if sanitized_body else None,
            'request_size': request_size,
            'session_id': request.cookies.get('session_id'),
            'user_id': getattr(request, 'current_user', {}).get('id') if hasattr(request, 'current_user') else None,
            'auth_token': self.mask_token(request.headers.get('Authorization')),
            'device_fingerprint': self.generate_device_fingerprint({
                'user_agent': user_agent,
                'request_headers': sanitized_headers
            }),
            'device_info': json.dumps(device_info),
            'is_bot': device_info['is_bot'],
            'is_mobile': device_info['is_mobile'],
            'browser_name': device_info['browser_name'],
            'browser_version': device_info['browser_version'],
            'os_name': device_info['os_name'],
            'os_version': device_info['os_version'],
        }
        
        return request_data
    
    def mask_token(self, token: str) -> str:
        """è„±æ•å¤„ç†ä»¤ç‰Œ"""
        if not token:
            return None
        
        if len(token) <= 8:
            return '*' * len(token)
        
        if len(token) > 255:
            return token[:10] + '*' * (min(len(token), 10)) + token[-10:]
        
        return token[:4] + '*' * (len(token) - 8) + token[-4:]
    
    def save_request_log(self, request_data: Dict[str, Any], response_data: Dict[str, Any] = None):
        """ä¿å­˜è¯·æ±‚æ—¥å¿—åˆ°æ•°æ®åº“"""
        request_id = request_data.get('request_id', 'unknown')
        
        try:
            # åˆå¹¶å“åº”æ•°æ®
            if response_data:
                request_data.update(response_data)
            
            connection = self.pool.connection()
            try:
                with connection.cursor() as cursor:
                    # ç¡®ä¿ä½¿ç”¨æ­£ç¡®çš„æ•°æ®åº“ä¸Šä¸‹æ–‡
                    self.ensure_database_context(cursor)
                    
                    # æ’å…¥è¯·æ±‚æ—¥å¿—
                    columns = ', '.join([f"`{key}`" for key in request_data.keys()])
                    placeholders = ', '.join(['%s'] * len(request_data))
                    
                    sql = f"""
                        INSERT INTO `api_request_logs` ({columns})
                        VALUES ({placeholders})
                    """
                    
                    cursor.execute(sql, list(request_data.values()))
                connection.commit()
                
            finally:
                connection.close()
                
        except Exception as e:
            # logger.error("ä¿å­˜è¯·æ±‚æ—¥å¿—å¤±è´¥", {
            #     "è¯·æ±‚ID": request_id,
            #     "é”™è¯¯ä¿¡æ¯": str(e),
            #     "é”™è¯¯ç±»å‹": type(e).__name__,
            #     "å½±å“": "æ—¥å¿—ä¸¢å¤±ï¼Œä½†ä¸å½±å“ä¸»ä¸šåŠ¡"
            # })
            # é™é»˜å¤„ç†é”™è¯¯ï¼Œä¸å½±å“ä¸»ä¸šåŠ¡
            pass
    
    def update_statistics(self, request_data: Dict[str, Any]):
        """æ›´æ–°ç»Ÿè®¡æ•°æ®"""
        request_id = request_data.get('request_id', 'unknown')
        # endpoint = request_data.get('endpoint', '')
        # status_code = request_data.get('response_status', 500)
        
        try:
            connection = self.pool.connection()
            try:
                with connection.cursor() as cursor:
                    # ç¡®ä¿ä½¿ç”¨æ­£ç¡®çš„æ•°æ®åº“ä¸Šä¸‹æ–‡
                    self.ensure_database_context(cursor)
                    
                    now = datetime.now()
                    date = now.date()
                    hour = now.hour
                    
                    # æ›´æ–°APIè®¿é—®ç»Ÿè®¡
                    cursor.execute("""
                        INSERT INTO `api_access_statistics` 
                        (`date`, `hour`, `endpoint`, `method`, `total_requests`, 
                         `success_requests`, `error_requests`, `avg_response_time`)
                        VALUES (%s, %s, %s, %s, 1, %s, %s, %s)
                        ON DUPLICATE KEY UPDATE
                        `total_requests` = `total_requests` + 1,
                        `success_requests` = `success_requests` + %s,
                        `error_requests` = `error_requests` + %s,
                        `avg_response_time` = (
                            (`avg_response_time` * (`total_requests` - 1) + %s) / `total_requests`
                        ),
                        `updated_at` = CURRENT_TIMESTAMP
                    """, (
                        date, hour, 
                        request_data.get('endpoint', ''),
                        request_data.get('method', ''),
                        1 if (request_data.get('response_status', 500) < 400) else 0,
                        1 if (request_data.get('response_status', 500) >= 400) else 0,
                        request_data.get('process_time', 0),
                        1 if (request_data.get('response_status', 500) < 400) else 0,
                        1 if (request_data.get('response_status', 500) >= 400) else 0,
                        request_data.get('process_time', 0)
                    ))
                    
                    # æ›´æ–°IPè®¿é—®ç»Ÿè®¡
                    cursor.execute("""
                        INSERT INTO `ip_access_statistics` 
                        (`date`, `ip_address`, `total_requests`, `first_access`, `last_access`,
                         `user_agent_hash`)
                        VALUES (%s, %s, 1, %s, %s, %s)
                        ON DUPLICATE KEY UPDATE
                        `total_requests` = `total_requests` + 1,
                        `last_access` = %s,
                        `updated_at` = CURRENT_TIMESTAMP
                    """, (
                        date,
                        request_data.get('real_ip', request_data.get('client_ip')),
                        now, now,
                        hashlib.md5((request_data.get('user_agent', '')).encode()).hexdigest(),
                        now
                    ))
                    
                connection.commit()
                
            finally:
                connection.close()
                
        except Exception as e:
            # logger.error("æ›´æ–°ç»Ÿè®¡æ•°æ®å¤±è´¥", {
            #     "è¯·æ±‚ID": request_id,
            #     "é”™è¯¯ä¿¡æ¯": str(e),
            #     "é”™è¯¯ç±»å‹": type(e).__name__,
            #     "å½±å“": "ç»Ÿè®¡æ•°æ®ç¼ºå¤±ï¼Œä½†ä¸å½±å“ä¸»ä¸šåŠ¡"
            # })
            # é™é»˜å¤„ç†é”™è¯¯
            pass

    def monitor_request(self, func):
        """è¯·æ±‚ç›‘æ§è£…é¥°å™¨"""
        @functools.wraps(func)
        def wrapper(*args, **kwargs):
            # è®°å½•å¼€å§‹æ—¶é—´
            start_time = time.time()
            g.request_start_time = start_time
            
            # æ”¶é›†è¯·æ±‚æ•°æ®
            request_data = self.collect_request_data(request)
            request_id = request_data.get('request_id', 'unknown')
            
            try:
                # æ‰§è¡ŒåŸå‡½æ•°
                response = func(*args, **kwargs)
                
                # è®°å½•å“åº”ä¿¡æ¯
                end_time = time.time()
                process_time = round((end_time - start_time) * 1000, 3)
                
                response_status = getattr(response, 'status_code', 200) if hasattr(response, 'status_code') else 200
                
                # ğŸš€ å…¼å®¹æµå¼å“åº”ï¼šæ£€æŸ¥æ˜¯å¦ä¸ºç›´é€šæ¨¡å¼
                response_size = 0
                try:
                    if hasattr(response, 'direct_passthrough') and response.direct_passthrough:
                        # æµå¼å“åº”æ¨¡å¼ï¼Œæ— æ³•è·å–å‡†ç¡®å¤§å°ï¼Œä½¿ç”¨ä¼°ç®—å€¼
                        response_size = -1  # æ ‡è®°ä¸ºæµå¼å“åº”
                    elif hasattr(response, 'get_data'):
                        response_size = len(str(response.get_data()))
                    else:
                        response_size = 0
                except (RuntimeError, Exception):
                    # å¦‚æœè·å–æ•°æ®å¤±è´¥ï¼ˆå¦‚ç›´é€šæ¨¡å¼ï¼‰ï¼Œä½¿ç”¨é»˜è®¤å€¼
                    response_size = -1  # æ ‡è®°ä¸ºæ— æ³•è·å–å¤§å°
                
                response_data = {
                    'response_status': response_status,
                    'process_time': process_time,
                    'response_size': response_size
                }
                # ä¿å­˜æ—¥å¿—
                self.save_request_log(request_data, response_data)
                
                # æ›´æ–°ç»Ÿè®¡
                request_data.update(response_data)
                self.update_statistics(request_data)
                
                return response
                
            except Exception as e:
                # è®°å½•é”™è¯¯ä¿¡æ¯
                end_time = time.time()
                process_time = round((end_time - start_time) * 1000, 3)
                
                error_data = {
                    'response_status': 500,
                    'process_time': process_time,
                    'error_message': str(e),
                    'response_size': 0
                }
                
                # logger.error("è¯·æ±‚å¤„ç†å¼‚å¸¸", {
                #     "è¯·æ±‚ID": request_id,
                #     "å‡½æ•°å": func.__name__,
                #     "é”™è¯¯ä¿¡æ¯": str(e),
                #     "é”™è¯¯ç±»å‹": type(e).__name__,
                #     "å¤„ç†æ—¶é—´": f"{process_time}ms",
                #     "ç»“æœ": "å¼‚å¸¸"
                # })
                
                # ä¿å­˜é”™è¯¯æ—¥å¿—
                self.save_request_log(request_data, error_data)
                
                # æ›´æ–°ç»Ÿè®¡
                request_data.update(error_data)
                self.update_statistics(request_data)
                
                # é‡æ–°æŠ›å‡ºå¼‚å¸¸
                raise e
                
        return wrapper

    def get_statistics_summary(self, days: int = 7) -> Dict[str, Any]:
        """è·å–ç»Ÿè®¡æ‘˜è¦"""
        try:
            connection = self.pool.connection()
            try:
                with connection.cursor() as cursor:
                    # ç¡®ä¿ä½¿ç”¨æ­£ç¡®çš„æ•°æ®åº“ä¸Šä¸‹æ–‡
                    self.ensure_database_context(cursor)
                    
                    end_date = datetime.now().date()
                    start_date = end_date - timedelta(days=days)
                    
                    # æ€»ä½“ç»Ÿè®¡
                    cursor.execute("""
                        SELECT 
                            SUM(total_requests) as total_requests,
                            SUM(success_requests) as success_requests,
                            SUM(error_requests) as error_requests,
                            AVG(avg_response_time) as avg_response_time,
                            COUNT(DISTINCT endpoint) as unique_endpoints
                        FROM api_access_statistics 
                        WHERE date BETWEEN %s AND %s
                    """, (start_date, end_date))
                    
                    summary = cursor.fetchone() or {}
                    # çƒ­é—¨ç«¯ç‚¹
                    cursor.execute("""
                        SELECT endpoint, SUM(total_requests) as requests
                        FROM api_access_statistics 
                        WHERE date BETWEEN %s AND %s
                        GROUP BY endpoint
                        ORDER BY requests DESC
                        LIMIT 10
                    """, (start_date, end_date))
                    
                    top_endpoints = cursor.fetchall()
                    
                    # æ´»è·ƒIPç»Ÿè®¡
                    cursor.execute("""
                        SELECT COUNT(DISTINCT ip_address) as unique_ips,
                               SUM(total_requests) as total_ip_requests
                        FROM ip_access_statistics 
                        WHERE date BETWEEN %s AND %s
                    """, (start_date, end_date))
                    
                    ip_stats = cursor.fetchone() or {}
                    
                    result = {
                        'period': f'{start_date} to {end_date}',
                        'summary': summary,
                        'top_endpoints': top_endpoints,
                        'ip_statistics': ip_stats
                    }
                    
                    return result
                    
            finally:
                connection.close()
                    
        except Exception as e:
            # logger.error("è·å–ç»Ÿè®¡æ‘˜è¦å¤±è´¥", {
            #     "æŸ¥è¯¢å¤©æ•°": days,
            #     "é”™è¯¯ä¿¡æ¯": str(e),
            #     "é”™è¯¯ç±»å‹": type(e).__name__,
            #     "å½±å“": "ç»Ÿè®¡æ‘˜è¦ä¸å¯ç”¨"
            # })
            return {'error': str(e)}


# å…¨å±€ç›‘æ§å®ä¾‹
route_monitor = RouteMonitor()

# å¯¼å‡ºç›‘æ§è£…é¥°å™¨
monitor_request = route_monitor.monitor_request

# å¯¼å‡ºå…¶ä»–æœ‰ç”¨çš„å‡½æ•°
def get_request_id():
    """è·å–å½“å‰è¯·æ±‚ID"""
    return getattr(g, 'request_id', None)

def get_statistics_summary(days: int = 7):
    """è·å–ç»Ÿè®¡æ‘˜è¦"""
    return route_monitor.get_statistics_summary(days)