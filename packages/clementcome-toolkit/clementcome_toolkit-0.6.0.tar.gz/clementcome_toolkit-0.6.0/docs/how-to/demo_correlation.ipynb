{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How-to Guide: Correlations\n",
    "\n",
    "Dans le fichier `cc_tk.feature.correlation`, 3 méthodes de sélection de variables à partir des corrélations sont implémentées. Ces 3 méthodes sont implémentées au travers de l'interface `TransformerMixin` de `sklearn` pour pouvoir être intégrée facilement dans des pipelines.\n",
    "\n",
    "1. Corrélation avec la variable cible (`CorrelationToTarget`) : on garde uniquement les variables qui sont corrélées avec la variable à prédire. Le seuil de corrélation est un paramètre de ce transformer.\n",
    "2. Détection des corrélations par paires (`PairwiseCorrelationDrop`) : quand une variable est corrélée (seuil de corrélation en paramètre), on retire cette variable de notre sélection. Par symétrie, on devrait retirer les deux variables en questions, le choix qui est fait est de retirer celle qui est en moyenne la plus corrélée avec les autres variables. Cette méthode est expliquée [ici](https://towardsdatascience.com/are-you-dropping-too-many-correlated-features-d1c96654abe6) et étendue pour éviter de retirer trop de colonnes. L'extension repose sur le fait que l'on retire itérativement les variables corrélées pour éviter de les prendre en compte lorsque l'on s'intéresse aux variables suivantes.\n",
    "3. Regroupement de variables en fonction de leurs corrélations (`ClusteringCorrelation`) : les variables sont regroupés par une CAH en prenant comme distance $1-abs(corr(X_i, X_j))$. Les groupes sont déterminés par un seuil de corrélation, toutes les variables dans un groupe sont corrélées à plus de $1 - seuil$. La méthode est détaillée [ici](https://kobia.fr/automatiser-la-reduction-des-correlations-par-clustering/). Pour chaque groupe, 2 possibilités : on garde un nombre de colonnes fixé à l'avance (1 par défaut), on construit une PCA pour chaque groupe et on choisit le nombre de composantes à garder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import set_config\n",
    "\n",
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.dummy import DummyRegressor\n",
    "\n",
    "from cc_tk.feature.correlation import (\n",
    "    CorrelationToTarget,\n",
    "    ClusteringCorrelation,\n",
    "    PairwiseCorrelationDrop,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_config(transform_output=\"pandas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = load_diabetes(return_X_y=True, as_frame=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline = DummyRegressor()\n",
    "baseline.fit(X_train, y_train)\n",
    "baseline.score(X_test, y_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Corrélation avec la cible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_target_pipeline = make_pipeline(\n",
    "    MinMaxScaler().set_output(transform=\"pandas\"),\n",
    "    CorrelationToTarget(threshold=0.1),\n",
    "    LinearRegression(),\n",
    ")\n",
    "correlation_target_pipeline.fit(X_train, y_train)\n",
    "correlation_target_pipeline.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_target_pipeline[\"correlationtotarget\"]._selected_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_target_pipeline[\"correlationtotarget\"].plot_correlation()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Corrélation par pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_pairwise_pipeline = make_pipeline(\n",
    "    MinMaxScaler().set_output(transform=\"pandas\"),\n",
    "    PairwiseCorrelationDrop(threshold=0.8),\n",
    "    LinearRegression(),\n",
    ")\n",
    "correlation_pairwise_pipeline.fit(X_train, y_train)\n",
    "correlation_pairwise_pipeline.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_pairwise_pipeline[\"pairwisecorrelationdrop\"]._columns_selection"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clusters de corrélation\n",
    "\n",
    "Il y a deux `summary_method` disponibles:\n",
    "- la valeur par défaut `first` qui utilise uniquement les premières variables de chaque cluster. On peut voir les variables retenues avec l'attribut `_selected_columns_`\n",
    "- `pca` qui utilise l'analyse en composantes principales pour résumer les clusters. On peut voir les colonnes en output avec l'attribut `_output_columns`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_clustering_pipeline = make_pipeline(\n",
    "    MinMaxScaler().set_output(transform=\"pandas\"),\n",
    "    ClusteringCorrelation(threshold=0.8, summary_method=\"pca\", n_variables_by_cluster=2),\n",
    "    LinearRegression(),\n",
    ")\n",
    "correlation_clustering_pipeline.fit(X_train, y_train)\n",
    "correlation_clustering_pipeline.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dendro = correlation_clustering_pipeline[\"clusteringcorrelation\"].plot_dendro()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_clustering_pipeline[\"clusteringcorrelation\"]._output_columns\n",
    "# correlation_clustering_pipeline[\"clusteringcorrelation\"]._selected_columns_   # When summary_method=\"first\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_clustering_pipeline[\n",
    "    \"clusteringcorrelation\"\n",
    "].plot_correlation_matrix()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combinaison de différents transformer\n",
    "\n",
    "Il est aussi possible de combiner différentes méthodes de sélection de variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_combined_pipeline = make_pipeline(\n",
    "    MinMaxScaler().set_output(transform=\"pandas\"),\n",
    "    CorrelationToTarget(threshold=0.1),\n",
    "    ClusteringCorrelation(threshold=0.3, summary_method=\"first\"),\n",
    "    LinearRegression(),\n",
    ")\n",
    "correlation_combined_pipeline.fit(X_train, y_train)\n",
    "correlation_combined_pipeline.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.15 ('engage-pip')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  },
  "vscode": {
   "interpreter": {
    "hash": "493bc9df2b15572748d078fe9d83121fa3b3669e37d640ad38f957bd03c7eb3f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
