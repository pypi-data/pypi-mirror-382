Metadata-Version: 2.4
Name: ch_srtgen
Version: 1.0.7
Summary: AI-powered SRT subtitle generator with Whisper and OpenAI translation
Home-page: https://github.com/your-username/srt-generator
Author: SRT Generator Team
Author-email: srt-generator@example.com
Project-URL: Bug Reports, https://github.com/your-username/srt-generator/issues
Project-URL: Source, https://github.com/your-username/srt-generator
Project-URL: Documentation, https://github.com/your-username/srt-generator#readme
Keywords: whisper,openai,translation,subtitle,srt,ai,speech-to-text
Classifier: Development Status :: 5 - Production/Stable
Classifier: Intended Audience :: Developers
Classifier: License :: OSI Approved :: MIT License
Classifier: Operating System :: OS Independent
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.10
Classifier: Programming Language :: Python :: 3.11
Classifier: Programming Language :: Python :: 3.12
Classifier: Programming Language :: Python :: 3.13
Requires-Python: >=3.10
Description-Content-Type: text/markdown
Requires-Dist: requests>=2.31.0
Requires-Dist: python-dotenv>=1.0.0
Requires-Dist: pydantic>=2.5.0
Requires-Dist: crewai>=0.28.0
Provides-Extra: whisper
Requires-Dist: openai-whisper; extra == "whisper"
Requires-Dist: torch>=2.0.0; extra == "whisper"
Requires-Dist: torchaudio>=2.0.0; extra == "whisper"
Requires-Dist: ffmpeg-python>=0.2.0; extra == "whisper"
Provides-Extra: dev
Requires-Dist: pytest>=7.0.0; extra == "dev"
Requires-Dist: pytest-cov>=4.0.0; extra == "dev"
Requires-Dist: black>=23.0.0; extra == "dev"
Requires-Dist: flake8>=6.0.0; extra == "dev"
Requires-Dist: mypy>=1.0.0; extra == "dev"
Dynamic: author
Dynamic: author-email
Dynamic: classifier
Dynamic: description
Dynamic: description-content-type
Dynamic: home-page
Dynamic: keywords
Dynamic: project-url
Dynamic: provides-extra
Dynamic: requires-dist
Dynamic: requires-python
Dynamic: summary

# Integrated SRT Subtitle Generator

A tool that uses Whisper speech recognition and OpenAI GPT to generate Korean SRT subtitles.

## ğŸš€ Features

- **Integrated workflow**: Speech-to-text â†’ Korean translation â†’ SRT generation
- **Flexible execution**: Run full process or individual steps
- **User-friendly GUI**: Intuitive interface
- **Simplified structure**: Minimal dependencies

## ğŸ“ Project Structure

```
SRT_Generator/
â”œâ”€â”€ src/                           # Integrated GUI
â”‚   â”œâ”€â”€ integrated_srt_generator.py
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â””â”€â”€ run_integrated.bat
â”œâ”€â”€ translator/                    # Translation tools
â”‚   â””â”€â”€ src/local_whisper_korean_subtitle_generator/
â”‚       â””â”€â”€ tools/
â”‚           â”œâ”€â”€ korean_translation_tool.py
â”‚           â””â”€â”€ srt_formatter_tool.py
â”œâ”€â”€ input/                         # Input files
â”œâ”€â”€ output/                        # Output files
â””â”€â”€ README.md
```

## ğŸ› ï¸ Installation and Run

### 1. Run the integrated GUI (recommended)
```bash
cd src
run_integrated.bat
```

### 2. Run individual steps
```bash
# Transcription only
cd src
python integrated_srt_generator.py

# Translation only (when JSON file already exists)
cd src
python integrated_srt_generator.py
```

## ğŸ“‹ Usage

### Using the integrated GUI

1. **Settings**
   - Select Whisper model (tiny ~ large-v3)
   - Select language (auto, ko, en, ja, etc.)
   - Enter OpenAI API key

2. **File selection**
   - Input file: target video/audio file
   - Output folder: where to save result files

3. **Actions**
   - **Start full process**: Transcription â†’ Translation â†’ SRT generation
   - **Transcription only**: Generate JSON file
   - **Translation only**: Convert existing JSON to Korean SRT

### Workflow

1. **Transcription** (Whisper)
   - Video/Audio â†’ JSON (timestamp + text)

2. **Korean translation** (OpenAI GPT)
   - English text â†’ Korean translation

3. **SRT generation** (Formatter)
   - Translated text â†’ SRT subtitle file

## ğŸ”§ Configuration

### API key setup

#### Method 1: Environment file (.env) [recommended]
1. Copy `env.template` to `.env`
2. Put your real API key in `.env`:
   ```
   OPENAI_API_KEY=your_actual_api_key_here
   ```

#### Method 2: Enter via GUI
- Enter the API key in the GUI after launching the app

#### Method 3: System environment variable
```bash
# Windows
set OPENAI_API_KEY=your_actual_api_key_here

# Linux/Mac
export OPENAI_API_KEY=your_actual_api_key_here
```

**âš ï¸ Security notes:**
- Never commit `.env` to Git
- Do not hardcode API keys in code
- Do not upload API keys to public repos

### Model selection
- **tiny**: Fastest, lower accuracy
- **base**: Balanced (recommended)
- **small**: Good accuracy
- **medium**: Higher accuracy
- **large**: Highest accuracy, slowest

## ğŸ“ Output files

- **JSON file**: `filename.json` (Whisper result)
- **SRT file**: `filename.srt` (final subtitles)

## ğŸ› Troubleshooting

### Common issues
1. **FFmpeg error**: Install FFmpeg
2. **API key error**: Check OpenAI API key
3. **Out of memory**: Use a smaller Whisper model

### Logs
You can check detailed progress and errors in the GUI log panel.

## ğŸ“„ License

This project is distributed under the MIT License.
