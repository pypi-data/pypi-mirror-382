{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tweedie Compound Poisson\n",
    "\n",
    "\n",
    "this is mostly about the parameterization between the Tweedie representation and the compound Poisson Gamma representation\n",
    "\n",
    "Notation:\n",
    "\n",
    "- lambda $\\lambda$ : Poisson rate\n",
    "- alpha, beta $\\alpha, \\beta$ : standard Gamma parameters\n",
    "- tau, gamma $\\tau, \\gamma$ : Gamma distribution with mean and precision\n",
    "- $p$ : Tweedie power parameter for variance function\n",
    "- phi $\\phi$ : Tweedie dispersion\n",
    "\n",
    "E for expectation, V for variance\n",
    "\n",
    "random variables and realization for each observation \n",
    "(typical element or vector of iid random variables, subscript i for specific observation)\n",
    "\n",
    "- N, n : Poisson count of events (claims)\n",
    "- X, x : Gamma distributed amounts for one event (size of single claim)\n",
    "- Y, y : Tweedie or compound Poisson distributed total claim size\n",
    "\n",
    "\n",
    "**Gamma distribution**\n",
    "\n",
    "$E(X) = \\tau = \\alpha / \\beta$ \n",
    "\n",
    "$V(X) = \\tau^2 / \\gamma = \\alpha / \\beta^2$\n",
    "\n",
    "$\\alpha = \\gamma$    remark: we drop \\gamma and work with \\alpha in the Tweedie definition\n",
    "\n",
    "$\\beta = \\gamma / \\tau$\n",
    "\n",
    "$Gamma(\\alpha, \\beta) = Gamma(\\gamma, \\gamma / \\tau)$\n",
    "\n",
    "sum of identical Gamma distributed random variables $Z = X_1 + ... + X_n$\n",
    "\n",
    "$Z \\tilde{} Gamma(n \\alpha, \\beta)$\n",
    "\n",
    "$E(Z) = n E(X) = n \\alpha / \\beta = n \\tau$\n",
    "\n",
    "$V(Z) = n V(X) = n \\alpha / \\beta^2 = (n \\tau)^2 / (n \\gamma) = n \\tau^2 / \\gamma$\n",
    "\n",
    "\n",
    "**Compound Poisson**\n",
    "\n",
    "properties of compound distribution\n",
    "\n",
    "$E(Y) = E(N) E(X)$\n",
    "\n",
    "$V(Y) = E(N) V(X) + V(N) (E(X))^2$\n",
    "\n",
    "for Poisson Gamma\n",
    "\n",
    "$\\mu = E(Y) = \\lambda \\tau$\n",
    "\n",
    "$V(Y) = \\lambda \\tau^2 / \\alpha + \\lambda  \\tau^2 = \\lambda  \\tau^2 (1 + 1 / \\alpha)$\n",
    "\n",
    "\n",
    "**Tweedie**\n",
    "\n",
    "$E(Y) = \\mu$\n",
    "\n",
    "$V(Y) = \\phi  \\mu^p$\n",
    "\n",
    "**parameter transformation compound Poisson to Tweedie**\n",
    "\n",
    "$(\\lambda, \\alpha, \\tau) -> (\\mu, p, \\phi)$\n",
    "\n",
    "$p = (\\alpha + 2) / (\\alpha + 1)$   copied, derivation missing\n",
    "\n",
    "$\\mu = \\lambda \\tau$\n",
    "\n",
    "$\\phi = \\lambda^{1 - p} \\tau^{2-p} / (2 - p)$\n",
    "\n",
    "substituting in for p, we have\n",
    "\n",
    "$\\phi = \\lambda^{-1 / (1 + \\alpha)} \\tau^{\\alpha / (1 + \\alpha)} / (2 - p)$\n",
    "\n",
    "\n",
    "**parameter transformation compound Poisson to Tweedie**\n",
    "\n",
    "$(\\mu, p, \\phi) -> (\\lambda, \\alpha, \\tau)$\n",
    "\n",
    "(derived directly, I didn't find reference again, verify)\n",
    "\n",
    "$\\lambda = \\mu^{2 - p} / (\\phi (2 - p))$\n",
    "\n",
    "$\\tau = \\mu / \\lambda = \\mu^{p - 1} \\phi (2 - p)$\n",
    "\n",
    "$\\alpha = (2 - p) / (p - 1)$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sum of Gamma random variables\n",
    "\n",
    "helper functions for our parameterization of sum of gamma random variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_gamma(n, mean, alpha):\n",
    "\tbeta = alpha / mean\n",
    "\treturn stats.gamma(n * alpha, scale=1.0 / beta)\n",
    "\n",
    "\n",
    "def gamma_moments(n, mean, alpha):\n",
    "\treturn n * mean, n * mean**2 / alpha\n",
    "\n",
    "\n",
    "def gamma_transform_params(mean, alpha):\n",
    "\treturn alpha, alpha / mean\n",
    "\n",
    "\n",
    "def transform_params_t2cp(mean, dispersion, power):\n",
    "\ttmp = 2 - power\n",
    "\tp_rate = mean**tmp / dispersion / tmp  # lambda\n",
    "\tg_mean = mean / p_rate  # tau, mean of one gamma\n",
    "\tg_shape = tmp / (\n",
    "\t\tpower - 1\n",
    "\t)  # alpha, shape parameter of gamma  #TODO check with scipy\n",
    "\treturn p_rate, g_mean, g_shape  # lambda, tau, alpha\n",
    "\n",
    "\n",
    "def transform_params_cp2t(p_rate, g_mean, g_shape):\n",
    "\t# lambda, tau, alpha = p_rate, g_mean, g_shape\n",
    "\tpower = (g_shape + 2) / (g_shape + 1)  # p = (alpha + 2) / (alpha + 1)\n",
    "\tmean = p_rate * g_mean  # mu = lambda * tau\n",
    "\t# phi = lambda^{1 - p} tau^{2-p} / (2 - p)\n",
    "\tdispersion = p_rate ** (1 - power) * g_mean ** (2 - power) / (2 - power)\n",
    "\treturn mean, dispersion, power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49.9213085308 247.218239837\n",
      "(50.0, 250.0)\n"
     ]
    }
   ],
   "source": [
    "n, mean, alpha = 5, 10.0, 2\n",
    "nobs = 50000\n",
    "\n",
    "g = get_gamma(n, mean, alpha)\n",
    "x = g.rvs(size=nobs)\n",
    "print(x.mean(), x.var())\n",
    "print(gamma_moments(n, mean, alpha))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.0174283961 50.0381128838\n",
      "(10.0, 50.0)\n"
     ]
    }
   ],
   "source": [
    "g1 = get_gamma(1, mean, alpha)\n",
    "x1 = g1.rvs(size=nobs)\n",
    "print(x1.mean(), x1.var())\n",
    "print(gamma_moments(1, mean, alpha))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37.5437058362 314.018469859\n",
      "25.0339588498 62.8157470727\n",
      "50.0534528226 252.233653316\n",
      "(array([25, 50]), array([  62.5,  250. ]))\n",
      "(37.5, 140.625) average tau\n"
     ]
    }
   ],
   "source": [
    "# try vectorized   # make sure we get independent random variables with broadcasting\n",
    "nobs_half = nobs // 2\n",
    "mean_gamma = np.repeat([5, 10], [nobs // 2, nobs - nobs // 2])\n",
    "gv = get_gamma(n, mean_gamma, alpha)\n",
    "xv = gv.rvs(size=nobs)\n",
    "print(xv.mean(), xv.var())\n",
    "print(xv[:nobs_half].mean(), xv[:nobs_half].var())\n",
    "print(xv[nobs_half:].mean(), xv[nobs_half:].var())\n",
    "\n",
    "print(gamma_moments(n, mean_gamma[[0, -1]], alpha))\n",
    "print(gamma_moments(n, mean_gamma[[0, -1]].mean(), alpha), 'average tau')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment: heterogeneity in Gamma sample\n",
    "\n",
    "There is some additivity in Gamma distribution, even with heterogeneous alpha but common beta. But it doesn't seem to work out.\n",
    "Something is missing here, i.e. I'm not comparing the right things.\n",
    "\n",
    "try to keep beta fixed and adjust alpha\n",
    "\n",
    "alpha = tau * beta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.48182207983 34.0763575434\n",
      "4.97122808799 18.5838655488\n",
      "9.99241607167 36.9626851543\n",
      "(array([ 5, 10]), array([ 18.75,  37.5 ]))\n",
      "(7.5, 28.125) average tau\n"
     ]
    }
   ],
   "source": [
    "nobs_half = nobs // 2\n",
    "mean_gamma = np.repeat([5, 10], [nobs // 2, nobs - nobs // 2])\n",
    "# implied beta and alpha\n",
    "beta = mean_gamma.mean() / alpha\n",
    "alpha2 = mean_gamma / beta\n",
    "n = 1\n",
    "gv = get_gamma(n, mean_gamma, alpha2)\n",
    "xv = gv.rvs(size=nobs)\n",
    "print(xv.mean(), xv.var())\n",
    "print(xv[:nobs_half].mean(), xv[:nobs_half].var())\n",
    "print(xv[nobs_half:].mean(), xv[nobs_half:].var())\n",
    "\n",
    "print(gamma_moments(n, mean_gamma[[0, -1]], alpha2[[0, -1]]))\n",
    "print(gamma_moments(n, mean_gamma[[0, -1]].mean(), alpha), 'average tau')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 1.33333333,  2.66666667]), 2.0, 2)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha2[[0, -1]], alpha2[[0, -1]].mean(), alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.75"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.3161314209771906, 0, 3.7771517408926223)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.gamma.fit(xv[:nobs_half], floc=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2.6787044454247018, 0, 3.7303167539574598)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.gamma.fit(xv[nobs_half:], floc=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.4900531123550462, 0, 5.0211781162637052)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.gamma.fit(xv, floc=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 0.2)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gamma_transform_params(mean, alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 1.33333333,  2.66666667]), array([ 0.26666667,  0.26666667]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gamma_transform_params(mean_gamma[[0, -1]], alpha2[[0, -1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.09481481,  0.18962963])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha2[[0, -1]] / beta**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.14222222222222222"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha / beta**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulate Compound Poisson Tweedie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.59382336737 49.2819146512\n",
      "5.10368166511 22.3507122165\n",
      "10.0839650696 63.8115056912\n",
      "[ 5 10]\n",
      "[ 22.36067977  63.2455532 ]\n"
     ]
    }
   ],
   "source": [
    "# try vectorized   # make sure we get independent random variables with broadcasting\n",
    "nobs = 10000\n",
    "nobs_half = nobs // 2\n",
    "mean_tweedie = np.repeat([5, 10], [nobs // 2, nobs - nobs // 2])\n",
    "indicator = mean_tweedie == 10\n",
    "dispersion = 2\n",
    "power = 1.5\n",
    "p_rate, g_mean, alpha = transform_params_t2cp(\n",
    "\tmean_tweedie, dispersion, power\n",
    ")  # lambda, tau, alpha\n",
    "\n",
    "# n is a bad choice because we use it as shortcut to number in names\n",
    "y_poi = np.random.poisson(p_rate, size=nobs)\n",
    "\n",
    "# Note gamma.rvs doesn't work with alpha=0, i.e. y_poisson = 0\n",
    "\n",
    "mask_nonzeros = y_poi > 0\n",
    "gv_ = get_gamma(y_poi[mask_nonzeros], g_mean[mask_nonzeros], alpha)\n",
    "xv_ = gv_.rvs(size=mask_nonzeros.sum())\n",
    "xv = np.zeros(y_poi.shape)\n",
    "xv[mask_nonzeros] = xv_\n",
    "print(xv.mean(), xv.var())\n",
    "print(xv[:nobs_half].mean(), xv[:nobs_half].var())\n",
    "print(xv[nobs_half:].mean(), xv[nobs_half:].var())\n",
    "\n",
    "print(mean_tweedie[[0, -1]])\n",
    "print(dispersion * mean_tweedie[[0, -1]] ** power)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def simulate_tweedie(mean, dispersion, power):\n",
    "\t\"\"\"\n",
    "\tSimulate Tweedie random variables\n",
    "\n",
    "\tParameters\n",
    "\t----------\n",
    "\tmean_tweedie : array_like\n",
    "\t    array of means of Tweedie distribution\n",
    "\tdispersion : float\n",
    "\t    dispersion of Tweedie distribution\n",
    "\tpower : float in interval (1, 2)\n",
    "\t    variance parameter for the Tweedie distribution\n",
    "\n",
    "\t\"\"\"\n",
    "\tmean = np.asarray(mean)\n",
    "\tp_rate, g_mean, alpha = transform_params_t2cp(\n",
    "\t\tmean, dispersion, power\n",
    "\t)  # lambda, tau, alpha\n",
    "\n",
    "\t# n is a bad choice because we use it as shortcut to number in names\n",
    "\ty_poi = np.random.poisson(p_rate, size=nobs)\n",
    "\n",
    "\t# Note gamma.rvs doesn't work with alpha=0, i.e. y_poisson = 0\n",
    "\n",
    "\tmask_nonzeros = y_poi > 0\n",
    "\tgv_ = get_gamma(y_poi[mask_nonzeros], g_mean[mask_nonzeros], alpha)\n",
    "\txv_ = gv_.rvs(size=mask_nonzeros.sum())\n",
    "\txv = np.zeros(y_poi.shape)\n",
    "\txv[mask_nonzeros] = xv_\n",
    "\treturn xv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Note: we cannot simulate 0 gamma random variables\n",
    "# get_gamma(0, 10, alpha).rvs()  # raises ValueError: Domain error in arguments.\n",
    "# np.random.gamma(0, 10, size=5) # raises ValueError shape <= 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Generalized Linear Model Regression Results                  \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                10000\n",
      "Model:                            GLM   Df Residuals:                     9998\n",
      "Model Family:                 Tweedie   Df Model:                            1\n",
      "Link Function:                    log   Scale:                   2.05612722742\n",
      "Method:                          IRLS   Log-Likelihood:                    nan\n",
      "Date:                Fri, 29 Apr 2016   Deviance:                       24836.\n",
      "Time:                        20:30:19   Pearson chi2:                 2.06e+04\n",
      "No. Iterations:                     7                                         \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          1.5952      0.014    117.207      0.000       1.568       1.622\n",
      "x1             0.7352      0.018     41.524      0.000       0.700       0.770\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "family_link = sm.families.Tweedie(link_power=0, var_power=1.5)\n",
    "\n",
    "xv2 = simulate_tweedie(mean_tweedie, dispersion, power)\n",
    "endog = xv2\n",
    "exog = sm.add_constant(indicator)\n",
    "\n",
    "model1 = sm.GLM(endog, exog, family=family_link)\n",
    "res1 = model1.fit()\n",
    "print(res1.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.546280648061214, 2.0561272274176154)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res1.model.estimate_tweedie_power(res1.fittedvalues), res1.scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  4.92907119,  10.28148966]),)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(np.exp(res1.params.cumsum()),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10000,), (10000,))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xv.shape, indicator.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A brief Monte Carlo Study\n",
    "\n",
    "This uses the true power parameter in estimating the mean parameters and dispersion. It doesn't use the estimated power parameter, which is unbiased in this case but the mean parameters don't include the extra noise. \n",
    "However, the mean parameter are also consistent with misspecified variance, because of the orthogonality between mean and variance parameters. The standard errors of the parameter estimates would be incorrect if variance is misspecified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time 41.97686195373535\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "result_mc = []\n",
    "n_rep = 1000\n",
    "t0 = time.time()\n",
    "for i in range(n_rep):\n",
    "\tendog = simulate_tweedie(mean_tweedie, dispersion, power)\n",
    "\tmodel1 = sm.GLM(endog, exog, family=family_link)\n",
    "\tres1 = model1.fit()\n",
    "\tp, dis = res1.model.estimate_tweedie_power(res1.fittedvalues), res1.scale\n",
    "\tr = np.concatenate((res1.params, res1.bse, [p, dis]))\n",
    "\tresult_mc.append(r)\n",
    "\n",
    "t1 = time.time()\n",
    "print('time', t1 - t0)\n",
    "result_mc = np.asarray(result_mc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MC mean and variance\n",
      "[ 1.60961325  0.69332718  0.01337654  0.01747699  1.49635664  2.00079205]\n",
      "[  1.70755365e-04   2.88743317e-04   1.31063351e-08   2.05875134e-08\n",
      "   2.25523156e-03   9.78343146e-04]\n",
      "\n",
      "var params [ 1.49635664  2.00079205] true: [1.5, 2]\n"
     ]
    }
   ],
   "source": [
    "print('MC mean and variance')\n",
    "m_mc = result_mc.mean(0)\n",
    "v_mc = result_mc.var(0)\n",
    "print(m_mc)\n",
    "print(v_mc)\n",
    "print()\n",
    "print('var params', m_mc[-2:], 'true:', [1.5, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean params [ 1.60961325  0.69332718]\n",
      "true params [ 1.60943791  0.69314718]\n"
     ]
    }
   ],
   "source": [
    "params_true = np.concatenate((np.log([5]), np.diff(np.log([5, 10]))))\n",
    "print('mean params', m_mc[:2])\n",
    "print('true params', params_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 1.60943791,  2.30258509]), array([ 0.69314718]))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.log([5, 10]), np.diff(np.log([5, 10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean bse [ 0.01337654  0.01747699]\n",
      "MC std   [ 0.01306734  0.01699245]\n"
     ]
    }
   ],
   "source": [
    "print('mean bse', result_mc[:, 2:4].mean(0))\n",
    "print('MC std  ', result_mc[:, :2].std(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregation Property of Tweedie Compound Poisson\n",
    "\n",
    "The underlying compound Poisson process is homogeneous in time. Tweedie is also a exponential model that satisfies several aggregation properties. In the following we look at the results of estimators when we aggregate observations. In the compound Poisson interpretation the observations are aggregates of periods of time. If we assume that the data represent one period in the initial case, then each observation in the aggregated case represents two periods. In count applications and similarly in Tweedie we can represent the underlying number of time and persion units by the exposure. In the insurance case, exposure is the total time policies are in effect that are represented by an observation. In epidemiological application, exposure commonly be in person-years.\n",
    "\n",
    "First we look at the original data which is the last replication from our Monte Carlo run above. By construction, the data is generated by a Tweedie compound Poisson process with a relatively large sample size, therefore estimation will not be distorted by possible misspecification and the noise or randomness in the estimates will be relatively small.\n",
    "\n",
    "Then, we combine two observations into one, where by construction observations have the same values of the explanatory variables. In this exercise the exposure increases for all information by the same amount, specifically the expectation of the response variable for each observation is now twice the original value.\n",
    "\n",
    "Summary of results\n",
    "\n",
    "- using exposure=2 replicates our original estimates except for small differences based on numerical optimization.\n",
    "- ignoring the aggregation of observation leads to doubling of the mean parameter but does not change their standard errors.\n",
    "- rescaling the response variable (dividing by 2) and using frequency weights leads to the same mean parameter estimates as in the original sample, but produces small changes in the standard errors. The response variable is now the mean of two observations, while the frequency weight indicates that this mean stands for two observations. This means that for each two observation we replaced the original value by the average of the two observation. In general, this can be capture by variance weights for distributions where taking the mean of observations is distributed by the same distribution family as the original observation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Generalized Linear Model Regression Results                  \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                10000\n",
      "Model:                            GLM   Df Residuals:                     9998\n",
      "Model Family:                 Tweedie   Df Model:                            1\n",
      "Link Function:                    log   Scale:                   1.93864085019\n",
      "Method:                          IRLS   Log-Likelihood:                    nan\n",
      "Date:                Fri, 29 Apr 2016   Deviance:                       23927.\n",
      "Time:                        20:44:49   Pearson chi2:                 1.94e+04\n",
      "No. Iterations:                     7                                         \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          1.5990      0.013    121.118      0.000       1.573       1.625\n",
      "x1             0.7065      0.017     41.012      0.000       0.673       0.740\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "print(res1.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "endog_year = endog.reshape(-1, 2).sum(1)\n",
    "exog_year = exog[::2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5672255066101113 1.33006176142\n"
     ]
    }
   ],
   "source": [
    "model_year = sm.GLM(\n",
    "\tendog_year, exog_year, family=family_link, exposure=2 * np.ones(endog_year.shape)\n",
    ")\n",
    "res_year = model_year.fit()\n",
    "p_year, dis_year = (\n",
    "\tres_year.model.estimate_tweedie_power(res_year.fittedvalues),\n",
    "\tres_year.scale,\n",
    ")\n",
    "print(p_year, dis_year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Generalized Linear Model Regression Results                  \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                 5000\n",
      "Model:                            GLM   Df Residuals:                     4998\n",
      "Model Family:                 Tweedie   Df Model:                            1\n",
      "Link Function:                    log   Scale:                   1.33006176142\n",
      "Method:                          IRLS   Log-Likelihood:                    nan\n",
      "Date:                Fri, 29 Apr 2016   Deviance:                       7406.0\n",
      "Time:                        20:53:43   Pearson chi2:                 6.65e+03\n",
      "No. Iterations:                     6                                         \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          1.5990      0.013    122.960      0.000       1.574       1.625\n",
      "x1             0.7065      0.017     41.636      0.000       0.673       0.740\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "print(res_year.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  4.94828969,  10.02929738])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.exp(res_year.params.cumsum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5672255066101095 1.33006176142\n"
     ]
    }
   ],
   "source": [
    "model_year = sm.GLM(\n",
    "\tendog_year, exog_year, family=family_link, freq_weights=np.ones(endog_year.shape)\n",
    ")\n",
    "res_year = model_year.fit()\n",
    "p_year, dis_year = (\n",
    "\tres_year.model.estimate_tweedie_power(res_year.fittedvalues),\n",
    "\tres_year.scale,\n",
    ")\n",
    "print(p_year, dis_year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Generalized Linear Model Regression Results                  \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                 5000\n",
      "Model:                            GLM   Df Residuals:                     4998\n",
      "Model Family:                 Tweedie   Df Model:                            1\n",
      "Link Function:                    log   Scale:                   1.33006176142\n",
      "Method:                          IRLS   Log-Likelihood:                    nan\n",
      "Date:                Fri, 29 Apr 2016   Deviance:                       7406.0\n",
      "Time:                        20:53:48   Pearson chi2:                 6.65e+03\n",
      "No. Iterations:                     6                                         \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          2.2922      0.013    176.261      0.000       2.267       2.318\n",
      "x1             0.7065      0.017     41.636      0.000       0.673       0.740\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "print(res_year.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  4.94828969,  10.02929738])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.exp(res_year.params.cumsum()) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5725796672896315 0.94030755413\n"
     ]
    }
   ],
   "source": [
    "model_year = sm.GLM(\n",
    "\tendog_year / 2,\n",
    "\texog_year,\n",
    "\tfamily=family_link,\n",
    "\tfreq_weights=2 * np.ones(endog_year.shape),\n",
    ")\n",
    "res_year = model_year.fit()\n",
    "p_year, dis_year = (\n",
    "\tres_year.model.estimate_tweedie_power(res_year.fittedvalues),\n",
    "\tres_year.scale,\n",
    ")\n",
    "print(p_year, dis_year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Generalized Linear Model Regression Results                  \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                 5000\n",
      "Model:                            GLM   Df Residuals:                     9998\n",
      "Model Family:                 Tweedie   Df Model:                            1\n",
      "Link Function:                    log   Scale:                   0.94030755413\n",
      "Method:                          IRLS   Log-Likelihood:                    nan\n",
      "Date:                Fri, 29 Apr 2016   Deviance:                       10474.\n",
      "Time:                        20:57:43   Pearson chi2:                 9.40e+03\n",
      "No. Iterations:                     6                                         \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          1.5990      0.009    173.910      0.000       1.581       1.617\n",
      "x1             0.7065      0.012     58.888      0.000       0.683       0.730\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "print(res_year.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  4.94828969,  10.02929738])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.exp(res_year.params.cumsum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
