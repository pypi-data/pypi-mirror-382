*模型交互系统-内置模型处理器[内置模型配置,model_settings]
相关文件地址:agent_os2/agent_os/base_model/processor_registry.py;agent_os2/agent_os/base_model/utility.py
AgentOS2内置了多个模型处理器,支持OpenAI ChatCompletion和Google GenAI官方的LLM/LVM的交互,以及基于LiteLLM的转发接口,此外还支持OpenAI Imagine生图模型,OpenAI DallE,GPT-IMAGE-1的生图模型和Flux生图模型
agent_settings.json中定义了被注册的Processor与模型配置的model_name之间的映射关系
与内置模型交互:
严格的接受的输入格式:str|dict[str,str]
灵活的内部输入格式处理解析能力:
1.对内置大语言模型处理器而言:
如果输入是dict,他们接受system,user两个键构建单次对话
如果输入是str,可以基于开头的标识符system:,user:,assistant:和换行符构建多轮对话
example
"system:你是一位翻译大师,擅长翻译文学作品并且带有本地化\nuser:请帮我翻译以下文本:\n<文本>\nassistant:<翻译结果>\nuser:请继续翻译"
如果该文本属于user信息,处理器支持对多模态输入的解析
支持的解析格式:
(1)@[ModalType](本地路径/网络地址)
(2)@[ModalType/Extension](本地路径/网络地址)
(3)@[ModalType:params](本地路径/网络地址)
(4)@[ModalType/Extension:params](本地路径/网络地址)
解释：
(1)ModalType:必填,可选项有[Text,Image,Video,Audio,Docs],其中Docs特指二进制格式的文档文件,如PDF
(2)Extension:可选,用于指定文件编码类型,如果不指定则默认尝试解析路径中的后缀名
(3)params:可选,用于指定加载该文件的附带参数,内置处理器支持的参数有:
-对于走OpenAIChatProcessor(openai-chat),Image类型支持detail参数来决定输入图片的品质,可选项有[low,high]
-对于走GoogleChatProcessor(google-chat),Video类型支持fps,决定每秒取多少帧,默认值是1；start_offset和end_offset,用于剪辑视频,单位是xxxs
example
@[Image:detail=high](...)
@[Video:fps=5,start_offset=10s,end_offset=170s]
常见大语言模型支持的模态
GPT-4O,GPT5系列:Text,Image,Docs
Gemini-2.5系列:Text,Image,Docs,Audio,Video
Grok4系列:Text,Image
Grok3系列:Text
Claude3.5/3.7/4系列:Text,Image
返回值:
(1)OpenAIChatProcessor返回的总是str
(2)GoogleChatProcessor如果不开启include_thoughts参数返回的也是str,如果开启则流式返回的是(思考内容,回答内容),最终结果是一个带有思考总结和回答的字符串
2.对生图模型而言:
仅接受str输入作为单次生成图片的prompt
在AgentOS之中,self.prompts如果存在,则在提示词模板嵌入上下文后自动将prompts用于调用指定model_config的模型
资源限制:
内置处理器支持以下资源消耗统计量:
total_tokens,prompt_tokens,completion_tokens,cost($)