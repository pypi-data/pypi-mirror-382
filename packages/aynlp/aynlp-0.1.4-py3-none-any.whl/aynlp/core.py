from .tokenizer import Tokenizer
from .lemmatizer import Lemmatizer
from .stemmer import Stemmer
from .stopwords import StopwordRemover
from .pos_tagger import POSTagger
from .ner import NER
from .sentiment import SentimentAnalyzer
from tabulate import tabulate


class AYNLP:
    """Unified NLP pipeline with table output ğŸ¯"""

    def __init__(self):
        self.tokenizer = Tokenizer()
        self.stopword_remover = StopwordRemover()
        self.lemmatizer = Lemmatizer()
        self.stemmer = Stemmer()
        self.pos_tagger = POSTagger()
        self.ner = NER()
        self.sentiment_analyzer = SentimentAnalyzer()

    def analyze(self, text):
        tokens = self.tokenizer.tokenize(text)
        filtered_tokens = self.stopword_remover.remove(tokens)
        pos_tags = self.pos_tagger.tag(tokens)
        lemmas = [self.lemmatizer.lemmatize(tok, tag) for tok, tag in pos_tags]
        stems = [self.stemmer.stem(tok) for tok in tokens]
        entities = self.ner.extract_entities(tokens)
        sentiment = self.sentiment_analyzer.analyze(text)

        data = [
            ["ğŸ§© Tokens", ", ".join(tokens)],
            ["ğŸš« Filtered Tokens", ", ".join(filtered_tokens)],
            ["ğŸ”¤ Lemmas", ", ".join(lemmas)],
            ["ğŸŒ± Stems", ", ".join(stems)],
            ["ğŸ·ï¸ POS Tags", ", ".join([f"{w}/{t}" for w, t in pos_tags])],
            ["ğŸ§  Entities", ", ".join([f"{e} ({t})" for e, t in entities]) if entities else "â€”"],
            ["ğŸ’¬ Sentiment",
             "ğŸ˜Š Positive" if sentiment == "positive"
             else ("ğŸ˜ Neutral" if sentiment == "neutral" else "ğŸ˜ Negative")],
        ]

        table = tabulate(data, headers=["ğŸ” Feature", "ğŸ“Š Result"], tablefmt="fancy_grid")
        return table
