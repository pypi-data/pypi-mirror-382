# SPDX-FileCopyrightText: Copyright (c) 2023-2025 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
# SPDX-License-Identifier: Apache-2.0
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

ARG GPU_TYPE=dgpu
ARG LIBTORCH_VERSION_ARM64="2.9.0.dev20250828+cu130"
ARG LIBTORCH_VERSION_AMD64="2.9.0.dev20250829+cu130"
ARG LIBTORCH_VISION_VERSION="0.24.0.dev20250829"

{% if application_type == 'CppCMake' %}
# Build C++ application in the builder stage
FROM {{ build_image }} AS builder
ENV DEBIAN_FRONTEND=noninteractive

RUN apt-get update && \
    apt-get install -y --no-install-recommends jq

WORKDIR /src
COPY ./app/* /src

RUN mkdir -p /install/.cmake/api/v1/query/ && \
    touch /install/.cmake/api/v1/query/codemodel-v2
RUN cd /src && \
    cmake -S . -DHOLOHUB_DOWNLOAD_DATASETS=OFF {{ cmake_args }} -B /install && \
    cmake --build /install -j && \
    export OUTNAME=$(cat $(find /install/.cmake/api/v1/reply -type f | xargs grep -l "nameOnDisk") | jq -r '.nameOnDisk') && \
    cd /install && \
    if [ "${OUTNAME}" != "{{ command_filename }}" ]; then mv ./${OUTNAME} ./{{ command_filename }}; fi

RUN rm /install/CMakeCache.txt /install/Makefile /install/cmake_install.cmake && \
    rm -r /install/CMakeFiles/ /install/.cmake/
{% endif %}



FROM {{ base_image }} AS base

RUN apt-get update \
    && apt-get install -y --no-install-recommends --no-install-suggests \
        curl \
        jq \
    && rm -rf /var/lib/apt/lists/*

{% if 'onnx' in includes %}
# Collect onnx dependencies
FROM base AS onnx-dependencies
ARG GPU_TYPE
ARG ONNX_RUNTIME_VERSION=1.22.1

WORKDIR /opt/onnxruntime

# Download onnx binaries
RUN CUDA_MAJOR_MINOR=$(echo ${CUDA_VERSION} | cut -d. -f1-2) \
    && echo "Downloading from https://edge.urm.nvidia.com/artifactory/sw-holoscan-thirdparty-generic-local/onnxruntime/onnxruntime-${ONNX_RUNTIME_VERSION}-cuda-${CUDA_MAJOR_MINOR}-$(uname -m).tar.gz" \
    && curl -S -L -# -o ort.tgz \
    https://edge.urm.nvidia.com/artifactory/sw-holoscan-thirdparty-generic-local/onnxruntime/onnxruntime-${ONNX_RUNTIME_VERSION}-cuda-${CUDA_MAJOR_MINOR}-$(uname -m).tar.gz
RUN mkdir -p ${ONNX_RUNTIME_VERSION} \
    && tar -xf ort.tgz -C ${ONNX_RUNTIME_VERSION} --strip-components 2 --no-same-owner --no-same-permissions \
    && rm -f ort.tgz
WORKDIR /
# End collect onnx dependencies
{% endif %}

FROM base AS release
ENV DEBIAN_FRONTEND=noninteractive
ENV TERM=xterm-256color

ARG GPU_TYPE
ARG UNAME
ARG UID
ARG GID
ARG LIBTORCH_VERSION_ARM64
ARG LIBTORCH_VERSION_AMD64
ARG LIBTORCH_VISION_VERSION

RUN mkdir -p /etc/holoscan/ \
        && mkdir -p /opt/holoscan/ \
        && mkdir -p {{ working_dir }} \
        && mkdir -p {{ app_dir }} \
        && mkdir -p {{ full_input_path }} \
        && mkdir -p {{ full_output_path }}

LABEL base="{{ base_image }}"
LABEL tag="{{ tag }}"
LABEL org.opencontainers.image.title="{{ title }}"
LABEL org.opencontainers.image.version="{{ version }}"
LABEL org.nvidia.holoscan="{{ holoscan_sdk_version }}"

{% if sdk_type == 'monai-deploy' %}
LABEL org.monai.deploy.app-sdk="{{ monai_deploy_app_sdk_version }}"
{% endif %}

ENV HOLOSCAN_INPUT_PATH={{ full_input_path }}
ENV HOLOSCAN_OUTPUT_PATH={{ full_output_path }}
ENV HOLOSCAN_WORKDIR={{ working_dir }}
ENV HOLOSCAN_APPLICATION={{ app_dir }}
ENV HOLOSCAN_TIMEOUT={{ timeout }}
ENV HOLOSCAN_MODEL_PATH={{ models_dir }}
ENV HOLOSCAN_DOCS_PATH={{ docs_dir }}
ENV HOLOSCAN_CONFIG_PATH={{ config_file_path }}
ENV HOLOSCAN_APP_MANIFEST_PATH={{ app_json }}
ENV HOLOSCAN_PKG_MANIFEST_PATH={{ pkg_json }}
ENV HOLOSCAN_LOGS_PATH={{ logs_dir }}
ENV HOLOSCAN_VERSION={{ holoscan_sdk_version }}

# Update NV GPG repo key
# https://developer.nvidia.com/blog/updating-the-cuda-linux-gpg-repository-key/
RUN rm -f /etc/apt/sources.list.d/cuda*.list \
    && curl -OL https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2404/{{ cuda_deb_arch }}/cuda-keyring_1.1-1_all.deb \
    && dpkg -i cuda-keyring_1.1-1_all.deb \
    && rm -f cuda-keyring_1.1-1_all.deb \
    && apt-get update

{% if 'debug' in includes %}
# Install debugging tools
RUN apt-get update \
    && apt-get install -y --no-install-recommends --no-install-suggests  \
        build-essential \
        ccache \
        gdb \
        strace \
        sudo \
    && rm -rf /var/lib/apt/lists/*
### End install debugging tools
{% endif %}


{% if 'holoviz' in includes %}
# Install Holoviz dependencies
RUN apt-get update \
    && apt-get install --no-install-recommends --no-install-suggests --allow-downgrades --allow-change-held-packages -y \
        libvulkan1="1.3.275.0-*" \
        # X11 support \
        libgl1="1.7.0-*" \
        # Wayland support \
        libwayland-client0="1.22.0-*" \
        libwayland-egl1="1.22.0-*" \
        libxkbcommon0="1.6.0-*"  \
        libdecor-0-plugin-1-cairo="0.2.2-*" \
        libegl1="1.7.0-*" \
    && rm -rf /var/lib/apt/lists/*
# End install Holoviz dependencies
{% endif %}


{% if 'torch' in includes %}
# Install torch dependencies
ENV PYTHON_VERSION=3.12.3-*
ENV PYTHON_PIP_VERSION=24.0+dfsg-*
ENV LIBTORCH=/opt/libtorch
ENV LD_LIBRARY_PATH=$LD_LIBRARY_PATH:${LIBTORCH}

RUN apt update \
    && apt-get install -y --no-install-recommends --no-install-suggests \
        python3-minimal=${PYTHON_VERSION} \
        libpython3-stdlib=${PYTHON_VERSION} \
        python3=${PYTHON_VERSION} \
        python3-venv=${PYTHON_VERSION} \
        python3-pip=${PYTHON_PIP_VERSION} \
        python3-dev \
        libjpeg-turbo8="2.1.5-*" \
        libnuma1="2.0.18-*" \
        libhwloc15="2.10.0-*" \
        libopenblas0="0.3.26+ds-*" \
        libevent-core-2.1-7 \
        libevent-pthreads-2.1-7 \
        cuda-cupti-$(echo ${CUDA_VERSION} | sed 's/\./-/g' | cut -d- -f1,2)  \
        libcudnn9-cuda-$(echo ${CUDA_VERSION} | cut -d. -f1) \
    && rm -rf /var/lib/apt/lists/*
RUN rm -rf /usr/lib/python3.12/EXTERNALLY-MANAGED \
    && if [ "${GPU_TYPE}" = "igpu" ]; then \
        echo "Torch installation is not supported for iGPU."; \
        exit 1; \
    else \
        INDEX_URL="https://download.pytorch.org/whl/nightly/cu130"; \
        if [ "${GPU_TYPE}" = "dgpu" ]; then \
            if [ $(uname -m) = "aarch64" ]; then \
            LIBTORCH_VERSION="${LIBTORCH_VERSION_ARM64}"; \
        else \
                LIBTORCH_VERSION="${LIBTORCH_VERSION_AMD64}"; \
            fi; \
        fi; \
    fi; \
    echo "Installing torch==${LIBTORCH_VERSION} from $INDEX_URL"; \
    python3 -m pip install --break-system-packages --force-reinstall torch==${LIBTORCH_VERSION} torchvision==${LIBTORCH_VISION_VERSION} torchaudio --index-url $INDEX_URL; \
    if ! find /usr/local/lib/python3.12/dist-packages/torch -name libtorch_cuda.so | grep -q .; then \
        echo "libtorch_cuda.so not found, torch installation failed"; \
        exit 1; \
    fi
# Set up Holoscan SDK container libtorch to be found with ldconfig for app C++ build and runtime
RUN echo $(python3 -c "import torch; print(torch.__path__[0])")/lib > /etc/ld.so.conf.d/libtorch.conf \
    && ldconfig \
    && ldconfig -p | grep -q "libtorch.so"
WORKDIR /
### End install torch dependencies
{% endif %}


{% if 'onnx' in includes %}
# Install onnx dependencies
ENV ONNX_RUNTIME=/opt/onnxruntime
ENV LD_LIBRARY_PATH=$LD_LIBRARY_PATH:${ONNX_RUNTIME}

# Copy ONNX Runtime
COPY --from=onnx-dependencies ${ONNX_RUNTIME} ${ONNX_RUNTIME}


# CLARAHOLOS-1689 requires libnvinfer_plugin
{% if gpu_type == "dgpu" %}

RUN apt-get update \
    && CUDA_MAJOR_VERSION=$(echo ${CUDA_VERSION} | cut -d. -f1) \
    && TRT_VERSION_VAR_NAME="TENSORRT_CU${CUDA_MAJOR_VERSION}" \
    && TRT_VERSION=$(apt-cache madison libnvinfer10 | grep "+cuda${CUDA_MAJOR_VERSION}" | head -n 1 | awk '{print $3}') \
    && apt-get install --no-install-recommends --no-install-suggests --allow-downgrades -y \
        libnvinfer10="${TRT_VERSION}" \
        libnvinfer-plugin10="${TRT_VERSION}" \
        libnvonnxparsers10="${TRT_VERSION}" \
        libcusparselt0 \
        libcudnn9-cuda-${CUDA_MAJOR_VERSION} \
    && rm -f /usr/lib/*/libcudnn*train.so* \
    && rm -rf /var/lib/apt/lists/*
{% endif %}
### End install onnx dependencies
{% endif %}
{% if health_probe is defined %}
# Install gRPC health probe
RUN curl -L -o /bin/grpc_health_probe {{ health_probe | pprint }} \
    && chmod +x /bin/grpc_health_probe && ls -l /bin/grpc_health_probe

HEALTHCHECK --interval=10s --timeout=1s \
    CMD /bin/grpc_health_probe -addr=:8765 || exit 1

# End install gRPC health probe
{% endif %}

{% if application_type == 'PythonModule' or application_type == 'PythonFile' %}
{% if not 'torch' in includes %}
# If torch is installed, we can skip installing Python
ENV PYTHON_VERSION=3.12.3-*
ENV PYTHON_PIP_VERSION=24.0+dfsg-*

RUN apt update \
    && apt-get install -y --no-install-recommends --no-install-suggests \
        python3-minimal=${PYTHON_VERSION} \
        libpython3-stdlib=${PYTHON_VERSION} \
        python3=${PYTHON_VERSION} \
        python3-venv=${PYTHON_VERSION} \
        python3-pip=${PYTHON_PIP_VERSION} \
    && rm -rf /var/lib/apt/lists/*
{% endif %}

{% if holoscan_deb_arch == "arm64" %}
# Requires python3-dev on aarch64
RUN apt update \
    && apt-get install -y --no-install-recommends --no-install-suggests \
        gcc \
        python3-dev \
    && rm -rf /var/lib/apt/lists/*
{% endif %}

{% endif %}

{% if application_type == 'CppCMake' or application_type == 'Binary' %}

ENV LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/opt/nvidia/holoscan/lib

RUN if [ "{{ holoscan_deb_arch }}" = "arm64" ]; then \
        GDR_REPO_ARCH=aarch64 ; \
    else \
        GDR_REPO_ARCH=x64 ; \
    fi \
    && curl -O https://developer.download.nvidia.com/compute/redist/gdrcopy/CUDA%2013.0/ubuntu24_04/${GDR_REPO_ARCH}/libgdrapi_2.5.1-1_{{ holoscan_deb_arch }}.Ubuntu24_04.deb \
    && dpkg -i libgdrapi_2.5.1-1_{{ holoscan_deb_arch }}.Ubuntu24_04.deb \
    && rm -f libgdrapi_2.5.1-1_{{ holoscan_deb_arch }}.Ubuntu24_04.deb \
    && rm -rf /var/lib/apt/lists/*

{% if custom_holoscan_sdk == True %}

# Use user-specified Holoscan SDK Debian Package
COPY ./{{ holoscan_sdk_filename }} /tmp/{{ holoscan_sdk_filename }}
RUN apt-get update \
    && apt-get install -y --no-install-recommends --no-install-suggests \
        /tmp/{{ holoscan_sdk_filename }} \
    && rm -rf /var/lib/apt/lists/*
{% else %}

# Install Holoscan SDK from NVIDIA APT repository
# Holoscan: available versions (https://pypi.org/project/holoscan/#history)
RUN apt-get install -y --no-install-recommends --no-install-suggests \
        holoscan={{ holoscan_sdk_filename }} \
    # && apt-get remove -y g++ g++-11 gcc gcc-11 gcc-11-base build-essential \
    && apt-get purge -y cuda-keyring \
    && rm -rf /var/lib/apt/lists/*
{% endif %}

{% endif %}


{% if holoscan_deb_arch == "arm64" %}
# Requires libnuma on aarch64
RUN apt update \
    && apt-get install -y --no-install-recommends --no-install-suggests \
        libnuma1="2.0.18-*" \
    && rm -rf /var/lib/apt/lists/*
{% endif %}

RUN if id "ubuntu" >/dev/null 2>&1; then touch /var/mail/ubuntu && chown ubuntu /var/mail/ubuntu && userdel -r ubuntu; fi
RUN groupadd -f -g $GID $UNAME
RUN useradd -rm -d /home/$UNAME -s /bin/bash -g $GID -G sudo -u $UID $UNAME
RUN chown -R holoscan {{ working_dir }} && \
    chown -R holoscan {{ full_input_path }} && \
    chown -R holoscan {{ full_output_path }}

# Set the working directory
WORKDIR {{ working_dir }}

# Copy HAP/MAP tool script
COPY ./tools {{ working_dir }}/tools
RUN chmod +x {{ working_dir }}/tools

# Remove EXTERNALLY-MANAGED directory
RUN rm -rf /usr/lib/python3.12/EXTERNALLY-MANAGED

# Set the working directory
WORKDIR {{ working_dir }}

USER $UNAME

ENV PATH=/home/${UNAME}/.local/bin:/opt/nvidia/holoscan/bin:$PATH
ENV LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/home/${UNAME}/.local/lib/python3.12/site-packages/holoscan/lib

{% if application_type == 'PythonModule' or application_type == 'PythonFile' %}
COPY ./pip/requirements.txt /tmp/requirements.txt

RUN pip install --upgrade pip
RUN pip install --no-cache-dir --user -r /tmp/requirements.txt

{% if sdk_type == 'holoscan' %}
# Install Holoscan SDK

{% if custom_holoscan_sdk == True %}
# Copy user-specified Holoscan SDK wheel file
COPY ./{{ holoscan_sdk_filename }} /tmp/{{ holoscan_sdk_filename }}
RUN pip install /tmp/{{ holoscan_sdk_filename }}

{% else %}
# Install Holoscan SDK wheel from PyPI
RUN pip install holoscan-cu13=={{holoscan_sdk_filename}}
{% endif %}
{% else %}

# Install MONAI Deploy App SDK
{% if custom_monai_deploy_sdk == True %}
# Copy user-specified MONAI Deploy SDK file
COPY ./{{ monai_deploy_sdk_filename }} /tmp/{{ monai_deploy_sdk_filename }}
RUN pip install /tmp/{{ monai_deploy_sdk_filename }}
{% else %}

# Install MONAI Deploy from PyPI org
RUN pip install monai-deploy-app-sdk=={{ monai_deploy_app_sdk_version }}

{% endif %}
{% endif %}
{% endif %}

{% if models is defined %}
COPY ./models  {{ models_dir }}
{% endif %}

{% if docs is defined %}
COPY ./docs  {{ docs_dir }}
{% endif %}

COPY ./map/app.json {{ app_json }}
COPY ./app.config {{ config_file_path }}
COPY ./map/pkg.json {{ pkg_json }}

{% if application_type == 'CppCMake' %}
COPY --from=builder /install {{ app_dir }}
{% else %}
COPY ./app {{ app_dir }}
{% endif %}

{% if additional_lib_paths != '' %}

ENV LD_LIBRARY_PATH=$LD_LIBRARY_PATH:{{ additional_lib_paths }}:{{ lib_dir }}
COPY ./lib {{ lib_dir }}

{% if application_type == 'PythonModule' or application_type == 'PythonFile' %}
ENV PYTHONPATH=$PYTHONPATH:{{ additional_lib_paths }}:{{ lib_dir }}
{% endif %}

{% endif %}

{% if input_data != None %}
COPY ./input $HOLOSCAN_INPUT_PATH
{% endif %}

ENTRYPOINT ["/var/holoscan/tools"]
