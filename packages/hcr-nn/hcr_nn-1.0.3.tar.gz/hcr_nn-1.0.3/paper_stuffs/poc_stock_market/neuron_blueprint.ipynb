{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "68b66aa2",
   "metadata": {
    "id": "68b66aa2"
   },
   "source": [
    "<h2>Implementacja modelu HCRNN do postaci Neurona</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e96a026e",
   "metadata": {
    "id": "e96a026e"
   },
   "source": [
    "Artykuł naukowy:\n",
    "Instniejace, podobne rozwiązania:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ad4c367",
   "metadata": {},
   "source": [
    "<h3>Narzędzia do kontroli jakości kodu:</h3>\n",
    "<ol>\n",
    "<li> isort do sortowania importowanych modułów - https://pycqa.github.io/isort/</li>\n",
    "<li> mypy do konwersji dynamicznych metod w statyczne - https://mypy.readthedocs.io/en/stable/getting_started.html</li>\n",
    "<li> unitest do testowania kodu</li>\n",
    "<li> sphinx do tworzenia dokumentacji - https://www.sphinx-doc.org/en/master/usage/quickstart.html</li>\n",
    "<li> flake8 do kontroli stylu - https://flake8.pycqa.org/en/latest/index.html#quickstart</li>\n",
    "<li> poetry do pakowania i wdrożenia apkietó CI/CD (opcjonalnie) - https://python-poetry.org/</li>\n",
    "<li> Coverage do testowania wadliwego kodu lub pomijanego kodu - https://coverage.readthedocs.io/en/7.10.1/</li>\n",
    "<li> hypothesis do Property-Based testing - https://hypothesis.readthedocs.io/en/latest/</li>\n",
    "<li> cProfile do testowania wydajności kodu - https://www.machinelearningplus.com/python/cprofile-how-to-profile-your-python-code/</li>\n",
    "</ol> "
   ]
  },
  {
   "cell_type": "code",
   "id": "62247169",
   "metadata": {
    "id": "62247169",
    "ExecuteTime": {
     "end_time": "2025-08-19T09:06:23.541121Z",
     "start_time": "2025-08-19T09:06:23.538592Z"
    }
   },
   "source": [
    "import mypy\n",
    "import numpy as np\n",
    "import math, os\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import Tensor\n",
    "import hypothesis"
   ],
   "outputs": [],
   "execution_count": 100
  },
  {
   "cell_type": "code",
   "id": "334bf9ff",
   "metadata": {
    "id": "334bf9ff",
    "ExecuteTime": {
     "end_time": "2025-08-19T09:06:23.547722Z",
     "start_time": "2025-08-19T09:06:23.546120Z"
    }
   },
   "source": [
    "__all__ = [\n",
    "    'HCRNN_Neuron'\n",
    "]"
   ],
   "outputs": [],
   "execution_count": 101
  },
  {
   "cell_type": "code",
   "id": "d1705e5e",
   "metadata": {
    "id": "d1705e5e",
    "ExecuteTime": {
     "end_time": "2025-08-19T09:06:23.552728Z",
     "start_time": "2025-08-19T09:06:23.550384Z"
    }
   },
   "source": [
    "from torch.nn import Module\n",
    "\n",
    "'''\n",
    "Klasa rozszerzająca funkcje torch'a.\n",
    "'''\n",
    "\n",
    "class HCRNN_Neuron(nn.Module):\n",
    "\n",
    "    '''\n",
    "    definicja stałych określająca rozmiar wejścia i wyjścia dla liczb neuronów.\n",
    "    '''\n",
    "\n",
    "    __constants__ = ['in_features', 'out_features']\n",
    "    in_features: int\n",
    "    out_features: int\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        *,\n",
    "        in_features: int,\n",
    "        out_features: int,\n",
    "\n",
    "        #definicja urządzenia, CPU, GPU lub TPU\n",
    "        device = None,\n",
    "        dtype= None,\n",
    "\n",
    "    ) -> None:\n",
    "        factory_kwargs = {\"device\": device, \"dtype\": dtype}\n",
    "        super().__init__()\n",
    "\n",
    "    #Tensor wchodzi i zawsze Tensor wychodzi\n",
    "    def forward(self, input:Tensor) -> Tensor:\n",
    "        pass"
   ],
   "outputs": [],
   "execution_count": 102
  },
  {
   "cell_type": "markdown",
   "id": "9d07ef1a",
   "metadata": {
    "id": "9d07ef1a"
   },
   "source": [
    "<h2>Normalization</h2>"
   ]
  },
  {
   "cell_type": "code",
   "id": "ef073368",
   "metadata": {
    "id": "ef073368",
    "ExecuteTime": {
     "end_time": "2025-08-19T09:06:23.559770Z",
     "start_time": "2025-08-19T09:06:23.555462Z"
    }
   },
   "source": [
    "class CDFNorm(nn.Module):\n",
    "    def __init__(self, method='gaussian', unbiased=True, eps=1e-5, affine=False, track_running_stats=True) -> None:\n",
    "        \"\"\"\n",
    "        Normalizacja CDF (dystrybuanty).\n",
    "\n",
    "        Parametry:\n",
    "            method: metoda normalizacji ('gaussian' lub 'empirical')\n",
    "            unbiased: czy użyć nieobciążonego estymatora wariancji\n",
    "            eps: mała wartość dla stabilności numerycznej\n",
    "            affine: czy zastosować transformację afiniczną\n",
    "            track_running_stats: czy śledzić statystyki podczas uczenia\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.method = method\n",
    "        self.unbiased = unbiased\n",
    "        self.eps = eps\n",
    "        self.affine = affine\n",
    "        self.track_running_stats = track_running_stats\n",
    "\n",
    "        if self.affine:\n",
    "            self.weight = nn.Parameter(torch.ones(1))  # Parametr skalujący\n",
    "            self.bias = nn.Parameter(torch.zeros(1))    # Parametr przesunięcia\n",
    "\n",
    "        if self.track_running_stats:\n",
    "            # Rejestracja buforów dla średniej i wariancji\n",
    "            self.register_buffer('running_mean', torch.zeros(1))\n",
    "            self.register_buffer('running_var', torch.ones(1))\n",
    "            self.register_buffer('num_batches_tracked', torch.tensor(0, dtype=torch.long))\n",
    "\n",
    "    def _gaussian_transform(self, x):\n",
    "        \"\"\"Transformacja Gaussa - normalizacja przy użyciu CDF rozkładu normalnego.\"\"\"\n",
    "        if self.training and self.track_running_stats:\n",
    "            # Obliczanie statystyk podczas uczenia\n",
    "            mean = x.mean()\n",
    "            var = x.var(unbiased=self.unbiased)\n",
    "            with torch.no_grad():\n",
    "                # Aktualizacja średniej kroczącej\n",
    "                self.running_mean = (1 - 0.1) * self.running_mean + 0.1 * mean\n",
    "                # Aktualizacja wariancji kroczącej\n",
    "                self.running_var = (1 - 0.1) * self.running_var + 0.1 * var\n",
    "                self.num_batches_tracked += 1\n",
    "        else:\n",
    "            # Użycie zapisanych statystyk podczas ewaluacji\n",
    "            mean = self.running_mean\n",
    "            var = self.running_var\n",
    "\n",
    "        # Obliczenie CDF przy użyciu funkcji błędu\n",
    "        x_norm = 0.5 * (1 + torch.erf((x - mean) / (torch.sqrt(var + self.eps) * math.sqrt(2))))\n",
    "\n",
    "        if self.affine:\n",
    "            # Transformacja afiniczną\n",
    "            x_norm = x_norm * self.weight + self.bias\n",
    "\n",
    "        return x_norm\n",
    "    \n",
    "    ''' błędna funkcja\n",
    "    def _empirical_transform(self, x):\n",
    "        \"\"\"Empiryczna transformacja CDF na podstawie rang.\"\"\"\n",
    "        x_norm = torch.zeros_like(x)\n",
    "        for i in range(len(x)):\n",
    "            # Obliczenie rangi dla każdego elementu\n",
    "            x_norm[i] = (x < x[i]).float().mean()\n",
    "\n",
    "        if self.affine:\n",
    "            # Transformacja afiniczną\n",
    "            x_norm = x_norm * self.weight + self.bias\n",
    "\n",
    "        return x_norm\n",
    "        '''\n",
    "    def _empirical_transform(self, x):\n",
    "        \"\"\"\n",
    "        Empiryczna CDF po ostatnim wymiarze: U = rank / n\n",
    "        Zwraca wartości w [1/n, 1], zgodnie z testem jednostkowym.\n",
    "        Obsługuje kształty (..., N).\n",
    "        \"\"\"\n",
    "        # argsort(argsort(x)) -> rangi 0..n-1 po ostatnim wymiarze\n",
    "        order = torch.argsort(x, dim=-1, stable=True)\n",
    "        ranks0 = torch.argsort(order, dim=-1).to(torch.float32)\n",
    "        n = x.size(-1)\n",
    "        u = (ranks0 + 1.0) / float(n)  # 1/n .. 1\n",
    "        if self.affine:\n",
    "            u = u * self.weight + self.bias\n",
    "        return u.to(x.dtype)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Przebieg forward normalizacji CDF.\n",
    "\n",
    "        Parametry:\n",
    "            x: tensor wejściowy\n",
    "\n",
    "        Zwraca:\n",
    "            Znormalizowany tensor w przedziale [0,1]\n",
    "        \"\"\"\n",
    "        if self.method == 'gaussian':\n",
    "            return self._gaussian_transform(x)\n",
    "        elif self.method == 'empirical':\n",
    "            return self._empirical_transform(x)\n",
    "        else:\n",
    "            raise ValueError(f\"Niewspierana metoda normalizacji: {self.method}\")"
   ],
   "outputs": [],
   "execution_count": 103
  },
  {
   "cell_type": "markdown",
   "id": "zkFrD-QadCAn",
   "metadata": {
    "id": "zkFrD-QadCAn"
   },
   "source": [
    "Baza ortonormalnych wielomianów Legendre'a"
   ]
  },
  {
   "cell_type": "code",
   "id": "isO9ucRIbMlp",
   "metadata": {
    "id": "isO9ucRIbMlp",
    "ExecuteTime": {
     "end_time": "2025-08-19T09:06:23.565464Z",
     "start_time": "2025-08-19T09:06:23.562381Z"
    }
   },
   "source": [
    "class OrthonormalLegendreBasis(nn.Module):\n",
    "    def __init__(self, max_degree: int) -> None:\n",
    "        \"\"\"\n",
    "        Implementacja ortonormalnych wielomianów Legendre'a na przedziale [0,1].\n",
    "\n",
    "        Parametry:\n",
    "            max_degree: maksymalny stopień wielomianu (0 do 3)\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.max_degree = max_degree\n",
    "\n",
    "        # Współczynniki wielomianów Legendre'a przesuniętych na przedział [0,1]\n",
    "        # Każdy wiersz odpowiada kolejnemu wielomianowi (P0, P1, P2, P3)\n",
    "        self.register_buffer('legendre_coeffs', torch.tensor([\n",
    "            [1, 0, 0, 0],        # P0(x) = 1\n",
    "            [-1, 2, 0, 0],       # P1(x) = 2x - 1\n",
    "            [1, -6, 6, 0],       # P2(x) = 6x² - 6x + 1\n",
    "            [-1, 12, -30, 20]    # P3(x) = 20x³ - 30x² + 12x - 1\n",
    "        ], dtype=torch.float32))\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        x = x.float().clamp(0, 1)\n",
    "        # Usuń zbędny wymiar kanału, np. (B,1) -> (B)\n",
    "        if x.dim() > 0 and x.size(-1) == 1:\n",
    "            x = x.squeeze(-1)\n",
    "        # Wielomiany przesunięte na [0,1] (masz coeffs dla 1, 2x-1, 6x^2-6x+1, 20x^3-30x^2+12x-1)\n",
    "        powers = torch.stack([x**i for i in range(self.legendre_coeffs.size(1))], dim=-1)  # (..., 4)\n",
    "        legendre = torch.einsum('...i,ji->...j', powers, self.legendre_coeffs)             # (..., 4)\n",
    "        # Ortonormalizacja na [0,1]: φ_n(x) = √(2n+1) * \\tilde P_n(x)\n",
    "        n = torch.arange(0, self.max_degree + 1, device=x.device, dtype=legendre.dtype)\n",
    "        scale = torch.sqrt(2.0 * n + 1.0)\n",
    "        return legendre[..., :self.max_degree+1] * scale\n"
   ],
   "outputs": [],
   "execution_count": 104
  },
  {
   "cell_type": "markdown",
   "id": "1de67962",
   "metadata": {
    "id": "1de67962"
   },
   "source": [
    "<h2>Joint Distribution</h2>\n",
    "Uogólniona funkcja dla wymiarów 2 i 3."
   ]
  },
  {
   "cell_type": "code",
   "id": "239ccf8b",
   "metadata": {
    "id": "239ccf8b",
    "ExecuteTime": {
     "end_time": "2025-08-19T09:06:23.570788Z",
     "start_time": "2025-08-19T09:06:23.568024Z"
    }
   },
   "source": [
    "class JointDistribution(nn.Module):\n",
    "    def __init__(self, dim:int, basis_size:int=4):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "        self.basis_size = basis_size\n",
    "        self.coeffs = nn.Parameter(torch.zeros(*(basis_size for _ in range(dim))))\n",
    "        self.basis = OrthonormalLegendreBasis(basis_size - 1)\n",
    "\n",
    "    def forward(self, *inputs: Tensor) -> Tensor:\n",
    "        # Konwersja wszystkich inputów do tensora\n",
    "        processed_inputs = []\n",
    "        for x in inputs:\n",
    "            if not isinstance(x, torch.Tensor):\n",
    "                x = torch.tensor(x, dtype=torch.float32)\n",
    "            if x.dim() == 0:\n",
    "                x = x.unsqueeze(0)\n",
    "            processed_inputs.append(x.float())\n",
    "\n",
    "        basis_values = [self.basis(x) for x in processed_inputs]\n",
    "\n",
    "        if self.dim == 2:\n",
    "            out = torch.einsum('...i,...j,ij->...', basis_values[0], basis_values[1], self.coeffs)\n",
    "        elif self.dim == 3:\n",
    "            out = torch.einsum('...i,...j,...k,ijk->...', basis_values[0], basis_values[1],basis_values[2], self.coeffs)\n",
    "        else:\n",
    "            raise ValueError(f\"Invalid dimensionality: {self.dim}. Supported: 2 or 3.\")\n",
    "\n",
    "        # jeśli input był skalarem, zwróć skalar\n",
    "        return out.squeeze()"
   ],
   "outputs": [],
   "execution_count": 105
  },
  {
   "cell_type": "markdown",
   "id": "6685b455",
   "metadata": {
    "id": "6685b455"
   },
   "source": [
    "<h2>Estymacja średnich</h2>"
   ]
  },
  {
   "cell_type": "code",
   "id": "55d288cf",
   "metadata": {
    "id": "55d288cf",
    "ExecuteTime": {
     "end_time": "2025-08-19T09:06:23.575821Z",
     "start_time": "2025-08-19T09:06:23.573360Z"
    }
   },
   "source": [
    "class MeanEstimation(nn.Module):\n",
    "    def __init__(self,\n",
    "                 *,\n",
    "                 triplets,\n",
    "                 feature_fn,\n",
    "                 feature_dm\n",
    "                 ):\n",
    "        super().__init__()\n",
    "        self.triplets = triplets\n",
    "        self.feature_fn = feature_fn\n",
    "        self.feature_dm = feature_dm\n",
    "\n",
    "    def compute_tensor_mean(self) -> Tensor:\n",
    "        \"\"\"\n",
    "        Parametry:\n",
    "            triplets: array (x, y, z)\n",
    "            feature_fn: funckaj mapująca\n",
    "            feature_dm: wymiary D\n",
    "        \"\"\"\n",
    "        a = np.zeros((self.feature_dm, self.feature_dm, self.feature_dm))\n",
    "\n",
    "        for (x, y, z) in self.triplets:\n",
    "            fx = self.feature_fn(x)\n",
    "            fy = self.feature_fn(y)\n",
    "            fz = self.feature_fn(z)\n",
    "\n",
    "            outer = np.einsum('i,j,k->ijk', fx, fy, fz)\n",
    "\n",
    "            a += outer\n",
    "\n",
    "        a /= len(self.triplets)  # Normalizacja na trójkach\n",
    "        return a"
   ],
   "outputs": [],
   "execution_count": 106
  },
  {
   "cell_type": "markdown",
   "id": "73fa0fa5",
   "metadata": {
    "id": "73fa0fa5"
   },
   "source": [
    "<h2>Estymacja warunkowa</h2>"
   ]
  },
  {
   "cell_type": "code",
   "id": "1e4a4856",
   "metadata": {
    "id": "1e4a4856",
    "ExecuteTime": {
     "end_time": "2025-08-19T09:06:23.581792Z",
     "start_time": "2025-08-19T09:06:23.579240Z"
    }
   },
   "source": [
    "class ConditionalEstimation(nn.Module):\n",
    "    def __init__(self,\n",
    "                 *,\n",
    "                 x_candidates,\n",
    "                 y,\n",
    "                 z,\n",
    "                 a,\n",
    "                 feature_fn) -> None:\n",
    "        super().__init__()\n",
    "        self.x_candidates = x_candidates\n",
    "        self.y = y\n",
    "        self.z = z\n",
    "        self.a = a\n",
    "        self.feature_fn = feature_fn\n",
    "\n",
    "    def conditional_score(self):\n",
    "\n",
    "        D = len(self.a)\n",
    "        fy = self.feature_fn(self.y)\n",
    "        fz = self.feature_fn(self.z)\n",
    "\n",
    "        denominator = 0\n",
    "        for j in range(D):\n",
    "            for k in range(D):\n",
    "                denominator += self.a[0, j, k] * fy[j] * fz[k]\n",
    "\n",
    "        scores = []\n",
    "        for x in self.x_candidates:\n",
    "            fx = self.feature_fn(x)\n",
    "\n",
    "            score = 0\n",
    "            for i in range(D):\n",
    "                context_sum = 0\n",
    "                for j in range(D):\n",
    "                    for k in range(D):\n",
    "                        context_sum += self.a[i, j, k] * fy[j] * fz[k]\n",
    "                score += fx[i] * (context_sum / (denominator + 1e-8)) #uniknięcie dzielenia przez zero\n",
    "\n",
    "            scores.append(score)\n",
    "\n",
    "        return scores"
   ],
   "outputs": [],
   "execution_count": 107
  },
  {
   "cell_type": "markdown",
   "id": "73556b28",
   "metadata": {
    "id": "73556b28"
   },
   "source": [
    "<h2>Propagacja Estymacji</h2>"
   ]
  },
  {
   "cell_type": "code",
   "id": "d0552a2b",
   "metadata": {
    "id": "d0552a2b",
    "ExecuteTime": {
     "end_time": "2025-08-19T09:06:23.587410Z",
     "start_time": "2025-08-19T09:06:23.584539Z"
    }
   },
   "source": [
    "class PropagationEstimation(nn.Module):\n",
    "    def __init__(self,\n",
    "                 *,\n",
    "                 y,\n",
    "                 z,\n",
    "                 a,\n",
    "                 feature_fn):\n",
    "        super().__init__()\n",
    "        self.y = y\n",
    "        self.z = z\n",
    "        self.a = a\n",
    "        self.feature_fn = feature_fn\n",
    "\n",
    "    def propagate_expectation(self):\n",
    "        fy = self.feature_fn(self.y).float().view(-1)\n",
    "        fz = self.feature_fn(self.z).float().view(-1)\n",
    "\n",
    "        numerator = torch.einsum('jk,j,k->', self.a[1], fy, fz)\n",
    "        denominator = torch.einsum('jk,j,k->', self.a[0], fy, fz)\n",
    "\n",
    "        ratio = numerator / (denominator + 1e-8)\n",
    "        \n",
    "        #przesunięcie bazy\n",
    "        centered_ratio = ratio - 1.0\n",
    "\n",
    "        propagated = 0.5 + (1.0 / (2.0 * torch.sqrt(torch.tensor(3.0)))) * centered_ratio\n",
    "        \n",
    "        return propagated"
   ],
   "outputs": [],
   "execution_count": 108
  },
  {
   "cell_type": "markdown",
   "id": "7db695a9",
   "metadata": {
    "id": "7db695a9"
   },
   "source": [
    "<h2>Entropia</h2>"
   ]
  },
  {
   "cell_type": "code",
   "id": "c5228003",
   "metadata": {
    "id": "c5228003",
    "ExecuteTime": {
     "end_time": "2025-08-19T09:06:23.592266Z",
     "start_time": "2025-08-19T09:06:23.590147Z"
    }
   },
   "source": [
    "class EntropyAndMutualInformation(nn.Module):\n",
    "\n",
    "    def approximate_entropy(self, activations):\n",
    "\n",
    "        # Normalizacja prawdopodobieństw funkcji aktywacji\n",
    "        probs = F.softmax(activations, dim=1)\n",
    "        entropy = -torch.sum(probs ** 2, dim=1).mean()\n",
    "        return entropy\n",
    "\n",
    "    def approximate_mutual_information(self, act_X, act_Y):\n",
    "\n",
    "        # Normalizacja funkcji aktywacji\n",
    "        probs_X = F.softmax(act_X, dim=1)\n",
    "        probs_Y = F.softmax(act_Y, dim=1)\n",
    "\n",
    "        joint_probs = torch.bmm(probs_X.unsqueeze(2), probs_Y.unsqueeze(1))\n",
    "\n",
    "        mi = torch.sum(joint_probs ** 2, dim=(1,2)).mean()\n",
    "        return mi"
   ],
   "outputs": [],
   "execution_count": 109
  },
  {
   "cell_type": "markdown",
   "id": "096dff88",
   "metadata": {
    "id": "096dff88"
   },
   "source": [
    "<h2>Dynamicznie modyfikowany model za pomocą EMA</h2>"
   ]
  },
  {
   "cell_type": "code",
   "id": "cace35ed",
   "metadata": {
    "id": "cace35ed",
    "ExecuteTime": {
     "end_time": "2025-08-19T09:06:23.596702Z",
     "start_time": "2025-08-19T09:06:23.594584Z"
    }
   },
   "source": [
    "class DynamicEMA(nn.Module):\n",
    "    def __init__(self, x, y, z, ema_lambda) -> None:\n",
    "        super().__init__()\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.z = z\n",
    "        self.ema_lambda = ema_lambda\n",
    "        self.a = torch.zeros_like(torch.einsum('i,j,k->ijk', x, y, z))  # pusty tensor o rozmiarze sumy einstein'a\n",
    "\n",
    "    def EMAUpdateMethod(self):\n",
    "        def f_i(x): return x\n",
    "        def f_j(y): return y\n",
    "        def f_k(z): return z\n",
    "\n",
    "        update_tensor = torch.einsum('i,j,k->ijk', f_i(self.x), f_j(self.y), f_k(self.z))\n",
    "\n",
    "        self.a = (1 - self.ema_lambda) * self.a + self.ema_lambda * update_tensor\n",
    "\n",
    "        return self.a"
   ],
   "outputs": [],
   "execution_count": 110
  },
  {
   "cell_type": "markdown",
   "id": "51c770ab",
   "metadata": {
    "id": "51c770ab"
   },
   "source": [
    "<h2>Optymizacja bazy</h2>"
   ]
  },
  {
   "cell_type": "code",
   "id": "254d8e2a",
   "metadata": {
    "id": "254d8e2a",
    "ExecuteTime": {
     "end_time": "2025-08-19T09:06:23.601792Z",
     "start_time": "2025-08-19T09:06:23.599367Z"
    }
   },
   "source": [
    "class BaseOptimization(nn.Module):\n",
    "    def __init__(self,\n",
    "                 *,\n",
    "                 a, #tensor do optymalizacji\n",
    "                 ) -> None:\n",
    "        self. a = a\n",
    "\n",
    "    def optimization_early(self) -> Tensor:\n",
    "        M = self.a.reshape(len(self.a[0]), -1)\n",
    "\n",
    "        # Obliczenie SVD\n",
    "        U, S, Vh = torch.linalg.svd(M, full_matrices=False)\n",
    "\n",
    "        # Transformacja Bazy, tu przykładowa funkcja, do wymiany\n",
    "        def f_x(x):\n",
    "            return torch.sin(x * torch.linspace(0, 1, len(self.a[2])))\n",
    "\n",
    "        # nowa baza g_i(x) = sum_j v_ij * f_j(x)\n",
    "        def g_i(x, U):\n",
    "            f = f_x(x)\n",
    "            return torch.matmul(U.T, f)\n",
    "\n",
    "        # Step 4: Transformacja Tensora\n",
    "        new_a = torch.einsum('li,ljk->ijk', U.T, self.a)\n",
    "\n",
    "        return new_a"
   ],
   "outputs": [],
   "execution_count": 111
  },
  {
   "cell_type": "markdown",
   "id": "8j7Cu9GqbT2J",
   "metadata": {
    "id": "8j7Cu9GqbT2J"
   },
   "source": [
    "<h2>Information bottleneck</h2>"
   ]
  },
  {
   "cell_type": "code",
   "id": "LdpFVrT4bWLD",
   "metadata": {
    "id": "LdpFVrT4bWLD",
    "ExecuteTime": {
     "end_time": "2025-08-19T09:06:23.606417Z",
     "start_time": "2025-08-19T09:06:23.604227Z"
    }
   },
   "source": [
    "class InformationBottleneck(nn.Module):\n",
    "    def __init__(self, beta=1.0):\n",
    "        super().__init__()\n",
    "        self.beta = beta\n",
    "\n",
    "    def forward(self, X_features, Y_features):\n",
    "        \"\"\"Implementuje równanie (15) z artykułu\"\"\"\n",
    "        C_X = X_features @ X_features.T\n",
    "        C_Y = Y_features @ Y_features.T\n",
    "        return torch.trace(C_X @ C_Y)\n",
    "\n",
    "    def bottleneck_loss(self, X_features, T_features, Y_features):\n",
    "        \"\"\"Implementuje równanie (10) z artykułu\"\"\"\n",
    "        I_XT = self(X_features, T_features)\n",
    "        I_TY = self(T_features, Y_features)\n",
    "        return I_XT - self.beta * I_TY"
   ],
   "outputs": [],
   "execution_count": 112
  },
  {
   "cell_type": "code",
   "id": "Ohw6cMZYjOG8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ohw6cMZYjOG8",
    "outputId": "56dbac1b-de3e-4f72-9a14-9fc6e0c3fa66",
    "ExecuteTime": {
     "end_time": "2025-08-19T09:06:23.638110Z",
     "start_time": "2025-08-19T09:06:23.614537Z"
    }
   },
   "source": [
    "# === Wszystkie testy zakończyły się sukcesem ===\n",
    "\n",
    "import unittest\n",
    "import torch\n",
    "import math\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# === Testy CDFNorm ===\n",
    "class CDFNormTest(unittest.TestCase):\n",
    "    def test_gaussian_transform(self):\n",
    "        cdf_norm = CDFNorm(method='gaussian')\n",
    "        input_tensor = torch.randn(100) * 2 + 5\n",
    "        output = cdf_norm(input_tensor)\n",
    "\n",
    "        self.assertTrue(torch.all(output >= 0))\n",
    "        self.assertTrue(torch.all(output <= 1))\n",
    "        self.assertAlmostEqual(output.mean().item(), 0.5, delta=0.1)\n",
    "\n",
    "    def test_empirical_transform(self):\n",
    "        cdf_norm = CDFNorm(method='empirical')\n",
    "        input_tensor = torch.tensor([1.0, 2.0, 3.0, 4.0, 5.0])\n",
    "        output = cdf_norm(input_tensor)\n",
    "\n",
    "        expected = torch.tensor([0.2, 0.4, 0.6, 0.8, 1.0])\n",
    "        self.assertTrue(torch.allclose(output, expected, atol=1e-5))\n",
    "\n",
    "# === Testy PropagationEstimation ===\n",
    "class PropagationEstimationTest(unittest.TestCase):\n",
    "    def test_propagate_expectation(self):\n",
    "        a = torch.zeros(2, 2, 2)\n",
    "        a[0,0,0] = 1.0\n",
    "        a[1,0,0] = 1.0\n",
    "        def simple_feature_fn(x): return torch.tensor([1.0, 0.0])\n",
    "        propagator = PropagationEstimation(y=torch.tensor(1.0), z=torch.tensor(1.0), a=a, feature_fn=simple_feature_fn)\n",
    "        propagated = propagator.propagate_expectation()\n",
    "        expected = 0.5\n",
    "        self.assertAlmostEqual(propagated.item(), expected, delta=1e-5)\n",
    "\n",
    "# === Testy OrthonormalLegendreBasis ===\n",
    "class OrthonormalLegendreBasisTest(unittest.TestCase):\n",
    "    def test_basis_functions(self):\n",
    "        basis = OrthonormalLegendreBasis(max_degree=3)\n",
    "        x = torch.linspace(0, 1, 5)\n",
    "        output = basis(x)\n",
    "        self.assertEqual(output.shape, (5, 4))\n",
    "\n",
    "    def test_normalization(self):\n",
    "        basis = OrthonormalLegendreBasis(max_degree=3)\n",
    "        x = torch.linspace(0, 1, 1000)  # więcej punktów dla lepszej dokładności\n",
    "        basis_values = basis(x)\n",
    "        for i in range(4):\n",
    "            integral = torch.trapz(basis_values[:,i] * basis_values[:,i], x)\n",
    "            self.assertAlmostEqual(integral.item(), 1.0, delta=0.05)  # poprawiona tolerancja\n",
    "\n",
    "# === Testy JointDistribution ===\n",
    "class JointDistributionTest(unittest.TestCase):\n",
    "    def test_2d_distribution(self):\n",
    "        joint_dist = JointDistribution(dim=2)\n",
    "        joint_dist.coeffs.data.fill_(0)\n",
    "        joint_dist.coeffs.data[0,0] = 1.0\n",
    "        x = torch.rand(10, 1)\n",
    "        y = torch.rand(10, 1)\n",
    "        output = joint_dist(x, y)\n",
    "        self.assertEqual(output.shape, (10,))\n",
    "        self.assertTrue(torch.all(output >= 0))\n",
    "\n",
    "    def test_3d_distribution(self):\n",
    "        joint_dist = JointDistribution(dim=3)\n",
    "        joint_dist.coeffs.data.fill_(0)\n",
    "        joint_dist.coeffs.data[0,0,0] = 1.0\n",
    "        x = torch.rand(5, 1)\n",
    "        y = torch.rand(5, 1)\n",
    "        z = torch.rand(5, 1)\n",
    "        output = joint_dist(x, y, z)\n",
    "        self.assertEqual(output.shape, (5,))\n",
    "        self.assertTrue(torch.all(output >= 0))\n",
    "\n",
    "# === Testy Estimation ===\n",
    "class EstimationTest(unittest.TestCase):\n",
    "    def test_tensor_mean(self):\n",
    "        triplets = [(torch.tensor([1.0]), torch.tensor([2.0]), torch.tensor([3.0]))] * 10\n",
    "        def simple_feature_fn(x): return torch.tensor([x.item(), x.item()**2])\n",
    "        estimator = MeanEstimation(triplets=triplets, feature_fn=simple_feature_fn, feature_dm=2)\n",
    "        tensor_mean = estimator.compute_tensor_mean()\n",
    "        self.assertEqual(tensor_mean.shape, (2, 2, 2))\n",
    "        self.assertGreater(tensor_mean.sum().item(), 0)\n",
    "\n",
    "# === Testy ConditionalEstimation ===\n",
    "class ConditionalEstimationTest(unittest.TestCase):\n",
    "    def test_conditional_score(self):\n",
    "        a = torch.zeros(2, 2, 2)\n",
    "        a[0,0,0] = 1.0\n",
    "        a[1,1,1] = 2.0\n",
    "        def simple_feature_fn(x): return torch.tensor([x.item(), x.item()**2])\n",
    "        estimator = ConditionalEstimation(\n",
    "            x_candidates=[torch.tensor(1.0), torch.tensor(2.0)],\n",
    "            y=torch.tensor(1.0),\n",
    "            z=torch.tensor(1.0),\n",
    "            a=a,\n",
    "            feature_fn=simple_feature_fn\n",
    "        )\n",
    "        scores = estimator.conditional_score()\n",
    "        self.assertEqual(len(scores), 2)\n",
    "        self.assertNotEqual(scores[0], scores[1])\n",
    "\n",
    "# === Testy DynamicEMA ===\n",
    "class DynamicEMATest(unittest.TestCase):\n",
    "    def test_ema_update(self):\n",
    "        x = torch.tensor([1.0])\n",
    "        y = torch.tensor([1.0])\n",
    "        z = torch.tensor([1.0])\n",
    "        ema = DynamicEMA(x=x, y=y, z=z, ema_lambda=0.1)\n",
    "        updated_a = ema.EMAUpdateMethod()\n",
    "        expected = torch.tensor([[[1.0]]]) * ema.ema_lambda\n",
    "        self.assertTrue(torch.allclose(updated_a, expected, atol=1e-5))\n",
    "\n",
    "# === Testy BaseOptimization ===\n",
    "class BaseOptimizationTest(unittest.TestCase):\n",
    "    def test_basis_optimization(self):\n",
    "        a = torch.eye(2).unsqueeze(0).repeat(2, 1, 1)\n",
    "        optimizer = BaseOptimization(a=a)\n",
    "        new_a = optimizer.optimization_early()\n",
    "        self.assertEqual(new_a.shape, a.shape)\n",
    "        self.assertFalse(torch.allclose(new_a, a, atol=1e-5))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    unittest.main(argv=[''], verbosity=2, exit=False)\n",
    "\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_basis_optimization (__main__.BaseOptimizationTest.test_basis_optimization) ... ok\n",
      "test_empirical_transform (__main__.CDFNormTest.test_empirical_transform) ... ok\n",
      "test_gaussian_transform (__main__.CDFNormTest.test_gaussian_transform) ... ok\n",
      "test_conditional_score (__main__.ConditionalEstimationTest.test_conditional_score) ... ok\n",
      "test_ema_update (__main__.DynamicEMATest.test_ema_update) ... ok\n",
      "test_tensor_mean (__main__.EstimationTest.test_tensor_mean) ... ok\n",
      "test_2d_distribution (__main__.JointDistributionTest.test_2d_distribution) ... ok\n",
      "test_3d_distribution (__main__.JointDistributionTest.test_3d_distribution) ... ok\n",
      "test_basis_functions (__main__.OrthonormalLegendreBasisTest.test_basis_functions) ... ok\n",
      "test_normalization (__main__.OrthonormalLegendreBasisTest.test_normalization) ... ok\n",
      "test_propagate_expectation (__main__.PropagationEstimationTest.test_propagate_expectation) ... ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 11 tests in 0.015s\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "execution_count": 114
  },
  {
   "cell_type": "markdown",
   "id": "pTp7Xp47peCM",
   "metadata": {
    "id": "pTp7Xp47peCM"
   },
   "source": [
    "### ===============================================================\n",
    "### RAPORT TESTÓW JEDNOSTKOWYCH: HCRNN v0.1\n",
    "### STATUS:\n",
    "### - 9/11 testów POPRAWNE\n",
    "### - 1/11 testów NIEUDANE (assert failures)\n",
    "### - 1/11 testów BŁĘDY WYKONANIA (exceptions)\n",
    "### SZCZEGÓŁY:\n",
    "### ------------------------------------------------------------------\n",
    "#### [POPRAWNE]\n",
    "####   BaseOptimization: test_basis_optimization\n",
    "####   CDFNorm: test_gaussian_transform\n",
    "####   OrthonormalLegendreBasis: test_basis_functions\n",
    "###    CDFNorm: test_empirical_transform\n",
    "#### [NIEUDANE]\n",
    "#### 1. OrthonormalLegendreBasis: test_normalization\n",
    "####    - Całka = 0.5 (oczekiwano 1.0 ±0.05)\n",
    "####    - Wymagana weryfikacja:\n",
    "####      * Obliczenia wag\n",
    "####      * Normalizacja funkcji bazowych\n",
    "#### [BŁĘDY]\n",
    "### TODO:\n",
    "### 1. Weryfikacja normalizacji funkcji bazowych\n",
    "### ===============================================================\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
