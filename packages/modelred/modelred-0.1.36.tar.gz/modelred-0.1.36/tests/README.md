# ModelRed SDK Local Testing Suite

Comprehensive test scripts to validate all SDK functionality before publishing.

## ğŸ“‹ Test Coverage

This test suite covers **every feature** documented in the SDK:

### Test 1: Model Registration (`test_1_model_registration.py`)

- âœ… Register OpenAI GPT-4o-mini model
- âœ… Register Anthropic Claude 3.5 Haiku model
- âœ… Register OpenRouter GPT-4o-mini model
- âœ… List all models with pagination
- âœ… Get specific model by ID
- âœ… Handle ConflictError for duplicate models

### Test 2: Probe Discovery (`test_2_probe_discovery.py`)

- âœ… List all available probes
- âœ… Filter probes by severity (critical, high, medium, low)
- âœ… Filter probes by category (prompt_injection, jailbreaks, etc.)
- âœ… Combine category + severity filters
- âœ… Check available categories and severities

### Test 3: Assessment Creation (`test_3_assessment_creation.py`)

- âœ… Create assessment with preset="quick"
- âœ… Create assessment with preset="standard"
- âœ… Create assessment with category filter
- âœ… Create assessment with severity filter
- âœ… Create assessment with category + severity
- âœ… Create assessment with manual test_types
- âœ… Test validation (mixing selection methods should fail)
- âœ… Get assessment by ID
- âœ… List recent assessments

### Test 4: Assessment Waiting & Results (`test_4_assessment_waiting.py`)

- âœ… Wait for completion with built-in progress_tracker
- âœ… Wait for completion with custom progress callback
- âœ… Check detailed report structure (snake_case fields)
- âœ… Get assessment status without waiting
- âœ… Validate report fields (overall_score, risk_level, etc.)

### Test 5: Helper Functions (`test_5_helper_functions.py`)

- âœ… print_header() - Formatted headers
- âœ… print_model_info() - Model details
- âœ… print_assessment_summary() - Assessment overview
- âœ… print_detailed_report() - Full report display
- âœ… print_assessments_list() - List formatting
- âœ… progress_tracker - Progress callback
- âœ… print_full_results() - Complete results display

### Test 6: Context Managers & Async (`test_6_context_managers_async.py`)

- âœ… Sync context manager (with statement)
- âœ… Async context manager (async with)
- âœ… All async methods (list_models, list_probes, create_assessment, etc.)
- âœ… Async wait_for_completion with callbacks
- âœ… Async model registration
- âœ… Automatic client.close() on context exit

## ğŸš€ Quick Start

### 1. Setup Environment

First, create a `.env` file in the `tests/` directory:

```bash
cd packages/python/tests
cp .env.example .env  # or create .env from scratch
```

Edit `.env` and add your API keys:

```env
# ModelRed API Key (Required)
MODELRED_API_KEY=mr_your_api_key_here

# OpenAI API Key (for GPT-4o-mini)
OPENAI_API_KEY=sk-your_openai_key_here

# Anthropic API Key (for Claude 3.5 Haiku)
ANTHROPIC_API_KEY=sk-ant-your_anthropic_key_here

# OpenRouter API Key (for GPT-4o-mini via OpenRouter)
OPENROUTER_API_KEY=sk-or-your_openrouter_key_here
```

### 2. Install Dependencies

Install python-dotenv for loading .env files:

```bash
pip install python-dotenv
```

Or use uv:

```bash
uv pip install python-dotenv
```

### 3. Run All Tests

Run the master test script:

```bash
python tests/run_all_tests.py
```

This will run all 6 test scripts in sequence and provide a summary.

### 4. Run Individual Tests

You can also run tests individually:

```bash
# Test model registration
python tests/test_1_model_registration.py

# Test probe discovery
python tests/test_2_probe_discovery.py

# Test assessment creation
python tests/test_3_assessment_creation.py

# Test assessment waiting
python tests/test_4_assessment_waiting.py

# Test helper functions
python tests/test_5_helper_functions.py

# Test async & context managers
python tests/test_6_context_managers_async.py
```

## ğŸ“Š Expected Output

### Successful Test Run

```
================================================================================
  ModelRed SDK - Comprehensive Test Suite
================================================================================

This will test all SDK functionality:
  1. Model Registration (OpenAI, Anthropic, OpenRouter)
  2. Probe Discovery (filtering by category/severity)
  3. Assessment Creation (presets, filters, manual)
  4. Assessment Waiting & Results
  5. Helper Functions
  6. Context Managers & Async

Press Enter to start...

================================================================================
  Running: Test 1 Model Registration
================================================================================

âœ… API Key loaded: mr_abc123...
âœ… ModelRed client initialized
âœ… OpenAI model registered: test-gpt4o-mini
âœ… Anthropic model registered: test-claude-haiku
âœ… OpenRouter model registered: test-openrouter-gpt4o
...
âœ… ALL MODEL REGISTRATION TESTS PASSED

================================================================================
  TEST SUMMARY
================================================================================

Total Tests: 6
âœ… Passed: 6
âŒ Failed: 0

Success Rate: 100.0%

================================================================================
  ğŸ‰ ALL TESTS PASSED! ğŸ‰
================================================================================
```

## ğŸ” What Each Test Validates

### Documentation Accuracy

- âœ… All code examples from docs work correctly
- âœ… All parameter names match documentation
- âœ… All return types match documentation
- âœ… All helper functions exist and work

### API Correctness

- âœ… All endpoints respond correctly
- âœ… Error handling works as expected
- âœ… Validation prevents invalid usage
- âœ… Context managers close resources properly

### Feature Completeness

- âœ… All three selection methods work (preset, category/severity, manual)
- âœ… All providers can be registered (OpenAI, Anthropic, OpenRouter)
- âœ… All filtering options work (category, severity, combined)
- âœ… Both sync and async clients work identically

## ğŸ› Troubleshooting

### "MODELRED_API_KEY not found"

- Make sure `.env` file exists in `tests/` directory
- Check that `MODELRED_API_KEY=...` line is uncommented
- Get your API key from https://app.modelred.ai/api-keys

### "Import dotenv could not be resolved"

```bash
pip install python-dotenv
```

### "Model already exists" warnings

This is normal! The tests use try/except with ConflictError to handle existing models gracefully.

### Assessment timeouts

Assessments can take 5-30 minutes depending on:

- Number of probes selected
- Queue priority (HIGH = faster)
- Server load

The tests use 30-minute timeouts by default.

### "No probes found for category"

- Check your subscription tier - some categories require Pro/Enterprise
- Verify the category name is correct (use test_2 to see available categories)

## ğŸ“ Modifying Tests

### Test Different Models

Edit the model configurations in test files:

```python
# In test_1_model_registration.py
model_name="gpt-4o"  # Change from gpt-4o-mini
```

### Test Different Probes

Change the probe selection in test files:

```python
# In test_3_assessment_creation.py
category="medical_ethics"  # Test Pro+ category
severity="high"  # Test high severity
```

### Adjust Timeouts

For longer/shorter timeouts:

```python
# In test_4_assessment_waiting.py
timeout_minutes=60  # Change from 30
```

## âœ… Success Criteria

All tests should pass before publishing:

- âœ… No import errors
- âœ… No API connection errors
- âœ… All assertions pass
- âœ… No unexpected exceptions
- âœ… Helper functions display correctly
- âœ… Async methods work identically to sync

## ğŸ¯ Next Steps

After all tests pass:

1. Update version in `pyproject.toml`
2. Update `CHANGELOG.md`
3. Build package: `python -m build`
4. Publish to PyPI: `python -m twine upload dist/*`

## ğŸ“š Additional Resources

- [SDK Documentation](../SDK_DOCUMENTATION.md)
- [ModelRed Dashboard](https://app.modelred.ai)
- [API Documentation](https://docs.modelred.ai)
