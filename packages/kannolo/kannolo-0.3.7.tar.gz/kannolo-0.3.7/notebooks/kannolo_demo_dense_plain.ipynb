{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from kannolo import DensePlainHNSW"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MS MARCO DRAGON (dense)\n",
    "query_path = os.path.expanduser('~/base_path/datasets_numpy/queries/dragon_queries.npy')\n",
    "index_path = os.path.expanduser('~/base_path/indexes/kannolo/kannolo_dragon_efc_200_m_32_metric_ip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "index = DensePlainHNSW.load(index_path) # Index\n",
    "queries = np.load(query_path) # Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose a query\n",
    "query_id_1 = 1500\n",
    "query_id_2 = 5000\n",
    "query_1 = queries[query_id_1]\n",
    "query_2 = queries[query_id_2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Search Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set search parameters\n",
    "k = 10\n",
    "efSearch = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dists_1, ids_1 = index.search(query_1, 10, 200)\n",
    "dists_2, ids_2 = index.search(query_2, 10, 200)\n",
    "dists_1 = dists_1.reshape(-1, 10)\n",
    "ids_1 = ids_1.reshape(-1, 10)\n",
    "dists_2 = dists_2.reshape(-1, 10)\n",
    "ids_2 = ids_2.reshape(-1, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collect Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ir_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add your ir_dataset dataset string id\n",
    "ir_dataset_string = \"msmarco-passage/dev/small\"\n",
    "# Load the dataset\n",
    "dataset = ir_datasets.load(\"msmarco-passage/dev/small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_passage_1 = [query for query in dataset.queries_iter()][query_id_1].text\n",
    "query_passage_2 = [query for query in dataset.queries_iter()][query_id_2].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents_passages = dataset.docs_iter()[:]\n",
    "results_1 = [documents_passages[int(i)].text for i in ids_1[0]]\n",
    "results_2 = [documents_passages[int(i)].text for i in ids_2[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ir_measures\n",
    "ir_measure = ir_measures.parse_measure(\"MRR@10\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remapping the query ids for metric evaluation\n",
    "real_query_id_1 = [query for query in dataset.queries_iter()][query_id_1].query_id\n",
    "real_query_id_2 = [query for query in dataset.queries_iter()][query_id_2].query_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parsing the results for metric evaluation\n",
    "results_for_metric_1 = []\n",
    "for dd, ii in zip(dists_1[0], ids_1[0]):\n",
    "    results_for_metric_1.append(ir_measures.ScoredDoc(real_query_id_1, str(ii), dd))\n",
    "\n",
    "results_for_metric_2 = []\n",
    "for dd, ii in zip(dists_2[0], ids_2[0]):\n",
    "    results_for_metric_2.append(ir_measures.ScoredDoc(real_query_id_2, str(ii), dd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the qrels (relevance judgments) for the dataset\n",
    "qrels = dataset.qrels\n",
    "qrel_1 = [q for q in qrels if q.query_id == real_query_id_1]\n",
    "qrel_2 = [q for q in qrels if q.query_id == real_query_id_2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the MRR@10 metric\n",
    "print(\"Metric evaluation for query 1\", ir_measures.calc_aggregate([ir_measure], qrel_1, results_for_metric_1))\n",
    "print(\"Metric evaluation for query 2\", ir_measures.calc_aggregate([ir_measure], qrel_2, results_for_metric_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_passage_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Dense representations fail in capturing the relevance of all the words. PER MONTH means that the query asks information about all the months in a year. Dense representations focus more on the more general topic, giving as results passages about average temperatures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_passage_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Dense representations catch the more generic meaning of definition for kid, unlike sparse representations that get fooled by the word \"kid\", matching it even if the context is different."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
