[databand]

[config]
validate_no_extra_params = warn

[core]
tracker = ['api']

tracker_api = web
tracker_version = 2

databand_url =
# credentials to connect to the databand webserver
dbnd_user = databand
dbnd_password = databand

[tracking]
log_histograms = False
flatten_operator_fields = {"PythonOperator": ["op_kwargs", "op_args"]}
track_source_code = False


[tracking_spark]
_type = dbnd_airflow.tracking.config.TrackingSparkConfig


[airflow_monitor]
interval = 5

# For 'fetcher = db' mode
local_dag_folder = /usr/local/airflow/dags
; sql_alchemy_conn = sqlite:////usr/local/airflow/airflow.db

# For rbac mode
rbac_username = databand
rbac_password = databand

# For 'fetcher = file' mode
;json_file_path =
;prometheus_port = 8000

[histogram]
;spark_parquet_cache_dir = "hdfs://tmp/"
spark_cache_dataframe = False
spark_cache_dataframe_column = True


[log]
formatter = [%%(asctime)s] {%%(filename)s:%%(lineno)d} %%(levelname)s - %%(message)s
console_value_preview_size = 1500
