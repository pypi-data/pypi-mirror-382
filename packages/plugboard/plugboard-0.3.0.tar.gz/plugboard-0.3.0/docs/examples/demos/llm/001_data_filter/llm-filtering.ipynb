{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LLM for data filtering\n",
    "\n",
    "[![Open in GitHub Codespaces](https://github.com/codespaces/badge.svg)](https://codespaces.new/plugboard-dev/plugboard)\n",
    "\n",
    "This model is a simple demonstration of how to use an LLM in a Plugboard model. In this case, we're going to use it to filter noisy data. The `input.csv` contains a sample of some temperature data that has been corrupted by various errors. We use the LLM to make corrections to the data where necessary.\n",
    "\n",
    "To run this model you will need to set the `OPENAI_API_KEY` environment variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from getpass import getpass\n",
    "\n",
    "import pandas as pd\n",
    "from pydantic import BaseModel\n",
    "\n",
    "from plugboard.connector import AsyncioConnector\n",
    "from plugboard.schemas import ConnectorSpec\n",
    "from plugboard.process import LocalProcess\n",
    "from plugboard.library import FileReader, FileWriter, LLMChat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"OPENAI_API_KEY\" not in os.environ:\n",
    "    os.environ[\"OPENAI_API_KEY\"] = getpass(\"Enter your OpenAI API key: \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `FileReader` and `FileWriter` components are provided by plugboard: set the up to load the input CSV file and save the model result to `output.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = FileReader(name=\"input_data\", path=\"input.csv\", field_names=[\"temperature\"])\n",
    "output_data = FileWriter(\n",
    "    name=\"output_data\",\n",
    "    path=\"output.csv\",\n",
    "    field_names=[\"raw_temperature\", \"corrected_temperature\", \"was_corrected\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the noise filter, we need to set up an `LLMChat` component to correct the temperature readings. To do this we need:\n",
    "\n",
    "1. A Pydantic response model to specify the format we would like the output in;\n",
    "2. A system prompt that provides instructions to the LLM about how we would like the data corrected;\n",
    "3. Configuration on `LLMChat` to keep context in the chat history, so that the model knows about previous values of the temperature that it has seen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CleanTemperature(BaseModel):\n",
    "    temperature: float\n",
    "    was_corrected: bool\n",
    "\n",
    "\n",
    "system_prompt = \"\"\"\n",
    "You are going to receive temperature values read from a sensor. These frequently contain errors that need to be corrected.\n",
    "Example errors are: missing decimal point, missing digit, decimal point in the wrong place, etc.\n",
    "You need to correct the temperature values and indicate whether they were corrected or not.\n",
    "For context, the temperature values are in Celsius and are not expected to change more than 2 degrees between readings.\n",
    "If you cannot tell what the correct value should be you should output the last known correct value.\n",
    "\"\"\"\n",
    "\n",
    "llm = LLMChat(\n",
    "    name=\"llm\",\n",
    "    system_prompt=system_prompt,\n",
    "    # This needs GPT-4o or similar to work well\n",
    "    llm_kwargs={\"model\": \"gpt-4o\"},\n",
    "    response_model=CleanTemperature,\n",
    "    # Expand the response into separate fields: llm.temperature and llm.was_corrected\n",
    "    expand_response=True,\n",
    "    # Include context so that the model can use the last known correct value\n",
    "    context_window=5,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now connect the components together in a `LocalProcess`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process = LocalProcess(\n",
    "    components=[input_data, llm, output_data],\n",
    "    connectors=[\n",
    "        # Connect input_data to LLM\n",
    "        AsyncioConnector(\n",
    "            spec=ConnectorSpec(source=\"input_data.temperature\", target=\"llm.prompt\"),\n",
    "        ),\n",
    "        # Connect both the raw input and LLM output to the output_data\n",
    "        AsyncioConnector(\n",
    "            spec=ConnectorSpec(\n",
    "                source=\"input_data.temperature\", target=\"output_data.raw_temperature\"\n",
    "            )\n",
    "        ),\n",
    "        AsyncioConnector(\n",
    "            spec=ConnectorSpec(source=\"llm.temperature\", target=\"output_data.corrected_temperature\")\n",
    "        ),\n",
    "        AsyncioConnector(\n",
    "            spec=ConnectorSpec(source=\"llm.was_corrected\", target=\"output_data.was_corrected\")\n",
    "        ),\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can initialise and run the simulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async with process:\n",
    "    await process.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now take a look at the data in `output.csv` and see how the model did."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv(\"output.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
