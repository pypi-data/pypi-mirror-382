# Copyright © 2025 Oracle and/or its affiliates.
#
# This software is under the Universal Permissive License
# (UPL) 1.0 (LICENSE-UPL or https://oss.oracle.com/licenses/upl) or Apache License
# 2.0 (LICENSE-APACHE or http://www.apache.org/licenses/LICENSE-2.0), at your option.

from dataclasses import dataclass
from typing import Any, ClassVar

from typing_extensions import Self

from wayflowcore.serialization.serializer import SerializableDataclassMixin, SerializableObject


@dataclass
class TokenUsage(SerializableDataclassMixin, SerializableObject):
    """
    Gathers all token usage information.

    Parameters
    ----------
    input_tokens:
        Number of tokens used as input/context.
    cached_tokens:
        Number of tokens in prompt that were cached.
    output_tokens:
        Number of tokens generated by the model.
    exact_count:
        Whether these numbers are exact or were estimated using the 1 token ≈ 3/4 word rule
    """

    input_tokens: int = 0
    output_tokens: int = 0
    cached_tokens: int = 0
    total_tokens: int = 0
    exact_count: bool = False
    _can_be_referenced: ClassVar[bool] = False

    def __add__(self, other: Any) -> "TokenUsage":
        if not isinstance(other, TokenUsage):
            raise ValueError("Cannot sum a non-TokenUsage object to a TokenUsage object")

        return TokenUsage(
            input_tokens=self.input_tokens + other.input_tokens,
            output_tokens=self.output_tokens + other.output_tokens,
            cached_tokens=self.cached_tokens + other.cached_tokens,
            total_tokens=self.total_tokens + other.total_tokens,
            exact_count=self.exact_count and other.exact_count,
        )

    def __iadd__(self, other: Any) -> Self:
        if not isinstance(other, TokenUsage):
            raise ValueError("Cannot sum a non-TokenUsage object to a TokenUsage object")

        self.input_tokens += other.input_tokens
        self.output_tokens += other.output_tokens
        self.cached_tokens += other.cached_tokens
        self.total_tokens += other.total_tokens
        self.exact_count = self.exact_count and other.exact_count

        return self
