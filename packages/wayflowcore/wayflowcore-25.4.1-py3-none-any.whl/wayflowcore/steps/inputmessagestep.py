# Copyright Â© 2025 Oracle and/or its affiliates.
#
# This software is under the Universal Permissive License
# (UPL) 1.0 (LICENSE-UPL or https://oss.oracle.com/licenses/upl) or Apache License
# 2.0 (LICENSE-APACHE or http://www.apache.org/licenses/LICENSE-2.0), at your option.

import logging
from typing import TYPE_CHECKING, Any, Dict, List, Optional

from wayflowcore._metadata import MetadataType
from wayflowcore._utils._templating_helpers import check_template_validity, render_template
from wayflowcore.messagelist import Message, MessageType
from wayflowcore.models.llmgenerationconfig import LlmGenerationConfig
from wayflowcore.models.llmmodel import LlmModel, Prompt
from wayflowcore.property import Property, StringProperty
from wayflowcore.steps.step import Step, StepExecutionStatus, StepResult
from wayflowcore.steps.templaterenderingstep import TemplateRenderingStep

if TYPE_CHECKING:
    from wayflowcore.executors._flowconversation import FlowConversation

logger = logging.getLogger(__name__)

REWRITING_SYSTEM_PROMPT = """\
Rewrite the following message.
Important: do not change the tone of the provided message or use overly formal language.
Provide the rewritten output and nothing else.

{{input_message}}
"""


async def _rephrase_message_and_stream_if_possible(
    message: str, conversation: "FlowConversation", llm: LlmModel
) -> None:
    prompt = [
        Message(
            content=render_template(
                template=REWRITING_SYSTEM_PROMPT, inputs=dict(input_message=message)
            ),
            message_type=MessageType.SYSTEM,
        ),
    ]
    llm_prompt = Prompt(
        messages=prompt,
        generation_config=LlmGenerationConfig(temperature=1.3),
    )
    stream = llm.stream_generate_async(
        prompt=llm_prompt,
        _conversation=conversation,
    )
    txt_output = await conversation._append_streaming_message(stream)
    logger.info("Successfully rephrased %s into %s", message, txt_output)


class InputMessageStep(Step):
    """Step to get an input from the conversation with the user.

    The input step prints a message to the user, asks for an answer and returns it as
    an output of the step. It places both messages in the messages list so that it is
    possible to visualize the conversation, but also returns the user input as an output.
    """

    USER_PROVIDED_INPUT = "user_provided_input"
    """str: Output key for the input text provided by the user."""

    def __init__(
        self,
        message_template: Optional[str],
        rephrase: bool = False,
        llm: Optional[LlmModel] = None,
        input_descriptors: Optional[List[Property]] = None,
        output_descriptors: Optional[List[Property]] = None,
        input_mapping: Optional[Dict[str, str]] = None,
        output_mapping: Optional[Dict[str, str]] = None,
        name: Optional[str] = None,
        __metadata_info__: Optional[MetadataType] = None,
    ):
        """
        Note
        ----

        A step has input and output descriptors, describing what values the step requires to run and what values it produces.

        **Input descriptors**

        By default, when ``input_descriptors`` is set to ``None``, the input_descriptors will be automatically inferred
        from the ``message_template``, with one input descriptor per variable in the template,
        trying to detect the type of the variable based on how it is used in the template.
        See :ref:`TemplateRenderingStep <TemplateRenderingStep>` for concrete examples on how descriptors are
        extracted from text prompts.

        If you provide a list of input descriptors, each provided descriptor will automatically override the detected one,
        in particular using the new type instead of the detected one.
        If some of them are missing, an error will be thrown at instantiation of the step.

        If you provide input descriptors for non-autodetected variables, a warning will be emitted, and
        they won't be used during the execution of the step.

        **Output descriptors**

        By default, this step has one single output descriptor named ``InputMessageStep.USER_PROVIDED_INPUT``, of type
        ``StringProperty()``, which will be the message generated by the step.

        Parameters
        ----------
        message_template:
            The message template to use to ask for more information to the user, in jinja format.
            See docstring/documentation of the ``TemplateRenderingStep``
            for concrete examples of how to work with jinja prompts in WayFlow.
            If None, no message is sent to the user.
        rephrase:
            Whether to rephrase the message. Requires ``llm`` to be set.
        llm:
            LLM to use to rephrase the message. Only required if ``rephrase=True``.
        input_descriptors:
            Input descriptors of the step. ``None`` means the step will resolve them automatically
        output_descriptors:
            Output descriptors of the step. ``None`` means the step will resolve them automatically
        name:
            Name of the step.

        input_mapping:
            Mapping between the name of the inputs this step expects and the name to get it from in the conversation input/output dictionary.
        output_mapping:
            Mapping between the name of the outputs this step expects and the name to get it from in the conversation input/output dictionary.

        See Also
        --------
        :class:`~wayflowcore.steps.OutputMessageStep` : Step to output a message to the chat history.

        Examples
        --------
        >>> from wayflowcore.flowhelpers import create_single_step_flow
        >>> from wayflowcore.steps import InputMessageStep
        >>> step = InputMessageStep(message_template="Please enter a message")
        >>> assistant = create_single_step_flow(step)
        >>> conversation = assistant.start_conversation()
        >>> status = conversation.execute() # Yielding back to the user
        >>> conversation.append_user_message("This is a user message.")
        >>> status = conversation.execute()
        >>> status.output_values
        {'user_provided_input': 'This is a user message.'}

        """
        super().__init__(
            llm=llm,
            input_mapping=input_mapping,
            output_mapping=output_mapping,
            step_static_configuration=dict(
                message_template=message_template, rephrase=rephrase, llm=llm
            ),
            input_descriptors=input_descriptors,
            output_descriptors=output_descriptors,
            name=name,
            __metadata_info__=__metadata_info__,
        )

        self.rephrase = rephrase
        self.message_template = message_template
        if self.message_template is not None:
            check_template_validity(self.message_template)

    @classmethod
    def _get_step_specific_static_configuration_descriptors(
        cls,
    ) -> Dict[str, type]:
        """
        Returns a dictionary in which the keys are the names of the configuration items
        and the values are a descriptor for the expected type
        """
        return {
            "message_template": Optional[str],  # type: ignore
            "rephrase": bool,
            "llm": Optional[LlmModel],  # type: ignore
        }

    @classmethod
    def _compute_step_specific_input_descriptors_from_static_config(
        cls,
        message_template: Optional[str],
        rephrase: bool,
        llm: Optional[LlmModel],
    ) -> List[Property]:
        return (
            TemplateRenderingStep._compute_step_specific_input_descriptors_from_static_config(
                template=message_template
            )
            if message_template
            else []
        )

    @classmethod
    def _compute_step_specific_output_descriptors_from_static_config(
        cls,
        message_template: Optional[str],
        rephrase: bool,
        llm: Optional[LlmModel],
    ) -> List[Property]:
        return [
            StringProperty(
                name=InputMessageStep.USER_PROVIDED_INPUT,
                description="the input value provided by the user",
            )
        ]

    # override
    @property
    def might_yield(self) -> bool:
        """
        Indicates that this step might yield (it always does).
        """
        return True

    async def _invoke_step_async(
        self, inputs: Dict[str, Any], conversation: "FlowConversation"
    ) -> StepResult:
        # two cases:
        #  1) first time we are invoked: we need output the message and yield
        #     so that the user can reply
        #  2) second time we are invoked: we need to place the user provided message
        #     as output, go to the next step (passthrough)
        asked_user = conversation._get_internal_context_value_for_step(self, "asked_user")

        if asked_user is None or (not asked_user):
            if self.message_template is not None:
                # append our message to the messages to ask user
                input_message = render_template(template=self.message_template, inputs=inputs)
                if self.rephrase and self.llm is not None:
                    await _rephrase_message_and_stream_if_possible(
                        input_message, conversation, self.llm
                    )
                else:
                    conversation.append_message(
                        Message(content=input_message, message_type=MessageType.AGENT)
                    )

            conversation._put_internal_context_key_value_for_step(self, "asked_user", True)

            # Yield and come back
            return StepResult(
                outputs={
                    self.USER_PROVIDED_INPUT: None
                },  # Placeholder not to cause type checking issues
                # come back to ourselves after obtaining the value from the user
                branch_name=self.BRANCH_SELF,
                step_type=StepExecutionStatus.YIELDING,
            )
        else:
            last_message = conversation.get_last_message()
            if last_message is None or not last_message.message_type == MessageType.USER:
                raise ValueError(
                    "Execution of flow was triggered before appending the required user message"
                )
            # next time we come here means we need to ask again, so set the flag to say we have
            # not asked
            conversation._put_internal_context_key_value_for_step(self, "asked_user", False)
            return StepResult(outputs={self.USER_PROVIDED_INPUT: last_message.content})
