# Acknowledgments

This project makes use of several excellent open-source libraries. We extend our gratitude to the maintainers and contributors of these projects:

## Core Dependencies

### Configuration and Type Validation
- **[Pydantic](https://github.com/pydantic/pydantic)** - Data validation and settings management using Python type annotations
- **[typing-extensions](https://github.com/python/typing_extensions)** - Enhanced typing support for Python

### Schema Validation
- **[jsonschema](https://github.com/python-jsonschema/jsonschema)** - JSON Schema validation for Python

### Documentation Parsing
- **[docstring-parser](https://github.com/rr-/docstring_parser)** - Python docstring parsing library

## Provider-Specific Dependencies

### OpenAI Integration
- **[OpenAI Python](https://github.com/openai/openai-python)** - Official OpenAI Python API library

### Anthropic Integration
- **[Anthropic Python](https://github.com/anthropics/anthropic-sdk-python)** - Official Anthropic Python SDK

### Hugging Face Integration
- **[Transformers](https://github.com/huggingface/transformers)** - State-of-the-art Machine Learning for PyTorch, TensorFlow, and JAX
- **[PyTorch](https://github.com/pytorch/pytorch)** - Tensors and Dynamic neural networks in Python
- **[Hugging Face Hub](https://github.com/huggingface/huggingface_hub)** - Official Python client for the Hugging Face Hub

### MLX (Apple Silicon) Integration
- **[MLX](https://github.com/ml-explore/mlx)** - Apple's array framework for machine learning on Apple silicon
- **[MLX-LM](https://github.com/ml-explore/mlx-examples)** - Language model examples and utilities for MLX
- **[MLX-VLM](https://github.com/Blaizzy/mlx-vlm)** - Vision-Language Models for MLX

### Ollama Integration
- **[Requests](https://github.com/psf/requests)** - HTTP library for Python (synchronous API calls)
- **[aiohttp](https://github.com/aio-libs/aiohttp)** - Asynchronous HTTP client/server framework

### LM Studio Integration
- **[LM Studio](https://github.com/lmstudio-ai/lms)** - Local LLM server with OpenAI-compatible API for running models locally

## Utility Libraries

### Image Processing
- **[Pillow (PIL)](https://github.com/python-pillow/Pillow)** - Python Imaging Library for image processing

### Numerical Computing
- **[NumPy](https://github.com/numpy/numpy)** - Fundamental package for scientific computing with Python

### Web Scraping and HTTP
- **[BeautifulSoup4](https://github.com/waylan/beautifulsoup)** - HTML/XML parsing library for web scraping
- **[Requests](https://github.com/psf/requests)** - HTTP library for Python

### Search Services
- **[DuckDuckGo API](https://duckduckgo.com/api)** - Privacy-focused search engine API (used for internet search functionality)

## Development Dependencies

### Testing and Code Quality
- **[pytest](https://github.com/pytest-dev/pytest)** - Testing framework for Python
- **[pytest-cov](https://github.com/pytest-dev/pytest-cov)** - Coverage plugin for pytest
- **[black](https://github.com/psf/black)** - Code formatter for Python
- **[isort](https://github.com/PyCQA/isort)** - Import sorting utility for Python

## Build Tools
- **[Hatchling](https://github.com/pypa/hatch)** - Modern Python build backend

---

We are grateful to all the developers and maintainers who have contributed to these projects. Their work makes AbstractLLM possible and enables developers to build powerful AI applications with ease.

If you notice any missing acknowledgments or have suggestions for improvements, please open an issue or submit a pull request. 