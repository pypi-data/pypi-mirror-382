import torch
import math
import torch.nn as nn
from timm.layers import trunc_normal_
from .Embedding import timestep_embedding, unified_pos_embedding
import numpy as np
import torch.nn.functional as F


################################################################
# Patchify and Neural Spectral Block 1D
################################################################
class NeuralSpectralBlock1D(nn.Module):
    def __init__(self, width, num_basis, patch_size=[3, 3], num_token=4, n_heads=8):
        super(NeuralSpectralBlock1D, self).__init__()
        self.patch_size = patch_size
        self.width = width
        self.num_basis = num_basis

        # basis
        self.modes_list = (1.0 / float(num_basis)) * torch.tensor(
            [i for i in range(num_basis)], dtype=torch.float
        )
        self.weights = nn.Parameter(
            (1 / (width)) * torch.rand(width, self.num_basis * 2, dtype=torch.float)
        )
        # latent
        self.head = n_heads
        self.num_token = num_token
        self.latent = nn.Parameter(
            (1 / (width))
            * torch.rand(
                self.head, self.num_token, width // self.head, dtype=torch.float
            )
        )
        self.encoder_attn = nn.Conv1d(
            self.width, self.width * 2, kernel_size=1, stride=1
        )
        self.decoder_attn = nn.Conv1d(self.width, self.width, kernel_size=1, stride=1)
        self.softmax = nn.Softmax(dim=-1)

    def self_attn(self, q, k, v):
        # q,k,v: B H L C/H
        attn = self.softmax(torch.einsum("bhlc,bhsc->bhls", q, k))
        return torch.einsum("bhls,bhsc->bhlc", attn, v)

    def latent_encoder_attn(self, x):
        # x: B C H W
        B, C, L = x.shape
        latent_token = self.latent[None, :, :, :].repeat(B, 1, 1, 1)
        x_tmp = (
            self.encoder_attn(x)
            .view(B, C * 2, -1)
            .permute(0, 2, 1)
            .contiguous()
            .view(B, L, self.head, C // self.head, 2)
            .permute(4, 0, 2, 1, 3)
            .contiguous()
        )
        latent_token = self.self_attn(latent_token, x_tmp[0], x_tmp[1]) + latent_token
        latent_token = (
            latent_token.permute(0, 1, 3, 2).contiguous().view(B, C, self.num_token)
        )
        return latent_token

    def latent_decoder_attn(self, x, latent_token):
        # x: B C L
        x_init = x
        B, C, L = x.shape
        latent_token = (
            latent_token.view(B, self.head, C // self.head, self.num_token)
            .permute(0, 1, 3, 2)
            .contiguous()
        )
        x_tmp = (
            self.decoder_attn(x)
            .view(B, C, -1)
            .permute(0, 2, 1)
            .contiguous()
            .view(B, L, self.head, C // self.head)
            .permute(0, 2, 1, 3)
            .contiguous()
        )
        x = self.self_attn(x_tmp, latent_token, latent_token)
        x = x.permute(0, 1, 3, 2).contiguous().view(B, C, L) + x_init  # B H L C/H
        return x

    def get_basis(self, x):
        # x: B C N
        x_sin = torch.sin(
            self.modes_list[None, None, None, :] * x[:, :, :, None] * math.pi
        )
        x_cos = torch.cos(
            self.modes_list[None, None, None, :] * x[:, :, :, None] * math.pi
        )
        return torch.cat([x_sin, x_cos], dim=-1)

    def compl_mul2d(self, input, weights):
        return torch.einsum("bilm,im->bil", input, weights)

    def forward(self, x):
        B, C, L = x.shape
        # patchify
        x = (
            x.view(
                x.shape[0],
                x.shape[1],
                x.shape[2] // self.patch_size[0],
                self.patch_size[0],
            )
            .contiguous()
            .permute(0, 2, 1, 3)
            .contiguous()
            .view(
                x.shape[0] * (x.shape[2] // self.patch_size[0]),
                x.shape[1],
                self.patch_size[0],
            )
        )
        # Neural Spectral
        # (1) encoder
        latent_token = self.latent_encoder_attn(x)
        # (2) transition
        latent_token_modes = self.get_basis(latent_token)
        latent_token = self.compl_mul2d(latent_token_modes, self.weights) + latent_token
        # (3) decoder
        x = self.latent_decoder_attn(x, latent_token)
        # de-patchify
        x = (
            x.view(B, (L // self.patch_size[0]), C, self.patch_size[0])
            .permute(0, 2, 1, 3)
            .contiguous()
            .view(B, C, L)
            .contiguous()
        )
        return x


################################################################
# Patchify and Neural Spectral Block 2D
################################################################
class NeuralSpectralBlock2D(nn.Module):
    def __init__(self, width, num_basis, patch_size=[3, 3], num_token=4, n_heads=8):
        super(NeuralSpectralBlock2D, self).__init__()
        self.patch_size = patch_size
        self.width = width
        self.num_basis = num_basis

        # basis
        self.modes_list = (1.0 / float(num_basis)) * torch.tensor(
            [i for i in range(num_basis)], dtype=torch.float
        )
        self.weights = nn.Parameter(
            (1 / (width)) * torch.rand(width, self.num_basis * 2, dtype=torch.float)
        )
        # latent
        self.head = n_heads
        self.num_token = num_token
        self.latent = nn.Parameter(
            (1 / (width))
            * torch.rand(
                self.head, self.num_token, width // self.head, dtype=torch.float
            )
        )
        self.encoder_attn = nn.Conv2d(
            self.width, self.width * 2, kernel_size=1, stride=1
        )
        self.decoder_attn = nn.Conv2d(self.width, self.width, kernel_size=1, stride=1)
        self.softmax = nn.Softmax(dim=-1)

    def self_attn(self, q, k, v):
        # q,k,v: B H L C/H
        attn = self.softmax(torch.einsum("bhlc,bhsc->bhls", q, k))
        return torch.einsum("bhls,bhsc->bhlc", attn, v)

    def latent_encoder_attn(self, x):
        # x: B C H W
        B, C, H, W = x.shape
        L = H * W
        latent_token = self.latent[None, :, :, :].repeat(B, 1, 1, 1)
        x_tmp = (
            self.encoder_attn(x)
            .view(B, C * 2, -1)
            .permute(0, 2, 1)
            .contiguous()
            .view(B, L, self.head, C // self.head, 2)
            .permute(4, 0, 2, 1, 3)
            .contiguous()
        )
        latent_token = self.self_attn(latent_token, x_tmp[0], x_tmp[1]) + latent_token
        latent_token = (
            latent_token.permute(0, 1, 3, 2).contiguous().view(B, C, self.num_token)
        )
        return latent_token

    def latent_decoder_attn(self, x, latent_token):
        # x: B C L
        x_init = x
        B, C, H, W = x.shape
        L = H * W
        latent_token = (
            latent_token.view(B, self.head, C // self.head, self.num_token)
            .permute(0, 1, 3, 2)
            .contiguous()
        )
        x_tmp = (
            self.decoder_attn(x)
            .view(B, C, -1)
            .permute(0, 2, 1)
            .contiguous()
            .view(B, L, self.head, C // self.head)
            .permute(0, 2, 1, 3)
            .contiguous()
        )
        x = self.self_attn(x_tmp, latent_token, latent_token)
        x = x.permute(0, 1, 3, 2).contiguous().view(B, C, H, W) + x_init  # B H L C/H
        return x

    def get_basis(self, x):
        # x: B C N
        x_sin = torch.sin(
            self.modes_list[None, None, None, :] * x[:, :, :, None] * math.pi
        )
        x_cos = torch.cos(
            self.modes_list[None, None, None, :] * x[:, :, :, None] * math.pi
        )
        return torch.cat([x_sin, x_cos], dim=-1)

    def compl_mul2d(self, input, weights):
        return torch.einsum("bilm,im->bil", input, weights)

    def forward(self, x):
        B, C, H, W = x.shape
        # patchify
        x = (
            x.view(
                x.shape[0],
                x.shape[1],
                x.shape[2] // self.patch_size[0],
                self.patch_size[0],
                x.shape[3] // self.patch_size[1],
                self.patch_size[1],
            )
            .contiguous()
            .permute(0, 2, 4, 1, 3, 5)
            .contiguous()
            .view(
                x.shape[0]
                * (x.shape[2] // self.patch_size[0])
                * (x.shape[3] // self.patch_size[1]),
                x.shape[1],
                self.patch_size[0],
                self.patch_size[1],
            )
        )
        # Neural Spectral
        # (1) encoder
        latent_token = self.latent_encoder_attn(x)
        # (2) transition
        latent_token_modes = self.get_basis(latent_token)
        latent_token = self.compl_mul2d(latent_token_modes, self.weights) + latent_token
        # (3) decoder
        x = self.latent_decoder_attn(x, latent_token)
        # de-patchify
        x = (
            x.view(
                B,
                (H // self.patch_size[0]),
                (W // self.patch_size[1]),
                C,
                self.patch_size[0],
                self.patch_size[1],
            )
            .permute(0, 3, 1, 4, 2, 5)
            .contiguous()
            .view(B, C, H, W)
            .contiguous()
        )
        return x


################################################################
# Patchify and Neural Spectral Block 3D
################################################################
class NeuralSpectralBlock3D(nn.Module):
    def __init__(self, width, num_basis, patch_size=[8, 8, 4], num_token=4, n_heads=8):
        super(NeuralSpectralBlock3D, self).__init__()
        self.patch_size = patch_size
        self.width = width
        self.num_basis = num_basis

        # basis
        self.modes_list = (1.0 / float(num_basis)) * torch.tensor(
            [i for i in range(num_basis)], dtype=torch.float
        )
        self.weights = nn.Parameter(
            (1 / (width)) * torch.rand(width, self.num_basis * 2, dtype=torch.float)
        )
        # latent
        self.head = n_heads
        self.num_token = num_token
        self.latent = nn.Parameter(
            (1 / (width))
            * torch.rand(
                self.head, self.num_token, width // self.head, dtype=torch.float
            )
        )
        self.encoder_attn = nn.Conv3d(
            self.width, self.width * 2, kernel_size=1, stride=1
        )
        self.decoder_attn = nn.Conv3d(self.width, self.width, kernel_size=1, stride=1)
        self.softmax = nn.Softmax(dim=-1)

    def self_attn(self, q, k, v):
        # q,k,v: B H L C/H
        attn = self.softmax(torch.einsum("bhlc,bhsc->bhls", q, k))
        return torch.einsum("bhls,bhsc->bhlc", attn, v)

    def latent_encoder_attn(self, x):
        # x: B C H W
        B, C, H, W, T = x.shape
        L = H * W * T
        latent_token = self.latent[None, :, :, :].repeat(B, 1, 1, 1)
        x_tmp = (
            self.encoder_attn(x)
            .view(B, C * 2, -1)
            .permute(0, 2, 1)
            .contiguous()
            .view(B, L, self.head, C // self.head, 2)
            .permute(4, 0, 2, 1, 3)
            .contiguous()
        )
        latent_token = self.self_attn(latent_token, x_tmp[0], x_tmp[1]) + latent_token
        latent_token = (
            latent_token.permute(0, 1, 3, 2).contiguous().view(B, C, self.num_token)
        )
        return latent_token

    def latent_decoder_attn(self, x, latent_token):
        # x: B C L
        x_init = x
        B, C, H, W, T = x.shape
        L = H * W * T
        latent_token = (
            latent_token.view(B, self.head, C // self.head, self.num_token)
            .permute(0, 1, 3, 2)
            .contiguous()
        )
        x_tmp = (
            self.decoder_attn(x)
            .view(B, C, -1)
            .permute(0, 2, 1)
            .contiguous()
            .view(B, L, self.head, C // self.head)
            .permute(0, 2, 1, 3)
            .contiguous()
        )
        x = self.self_attn(x_tmp, latent_token, latent_token)
        x = x.permute(0, 1, 3, 2).contiguous().view(B, C, H, W, T) + x_init  # B H L C/H
        return x

    def get_basis(self, x):
        # x: B C N
        x_sin = torch.sin(
            self.modes_list[None, None, None, :] * x[:, :, :, None] * math.pi
        )
        x_cos = torch.cos(
            self.modes_list[None, None, None, :] * x[:, :, :, None] * math.pi
        )
        return torch.cat([x_sin, x_cos], dim=-1)

    def compl_mul2d(self, input, weights):
        return torch.einsum("bilm,im->bil", input, weights)

    def forward(self, x):
        B, C, H, W, T = x.shape
        # patchify
        x = (
            x.view(
                x.shape[0],
                x.shape[1],
                x.shape[2] // self.patch_size[0],
                self.patch_size[0],
                x.shape[3] // self.patch_size[1],
                self.patch_size[1],
                x.shape[4] // self.patch_size[2],
                self.patch_size[2],
            )
            .contiguous()
            .permute(0, 2, 4, 6, 1, 3, 5, 7)
            .contiguous()
            .view(
                x.shape[0]
                * (x.shape[2] // self.patch_size[0])
                * (x.shape[3] // self.patch_size[1])
                * (x.shape[4] // self.patch_size[2]),
                x.shape[1],
                self.patch_size[0],
                self.patch_size[1],
                self.patch_size[2],
            )
        )
        # Neural Spectral
        # (1) encoder
        latent_token = self.latent_encoder_attn(x)
        # (2) transition
        latent_token_modes = self.get_basis(latent_token)
        latent_token = self.compl_mul2d(latent_token_modes, self.weights) + latent_token
        # (3) decoder
        x = self.latent_decoder_attn(x, latent_token)
        # de-patchify
        x = (
            x.view(
                B,
                (H // self.patch_size[0]),
                (W // self.patch_size[1]),
                (T // self.patch_size[2]),
                C,
                self.patch_size[0],
                self.patch_size[1],
                self.patch_size[2],
            )
            .permute(0, 4, 1, 5, 2, 6, 3, 7)
            .contiguous()
            .view(B, C, H, W, T)
            .contiguous()
        )
        return x
