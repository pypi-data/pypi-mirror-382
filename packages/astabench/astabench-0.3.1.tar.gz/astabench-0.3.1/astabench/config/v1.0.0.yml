name: asta-bench
version: "1.0.0"

splits:
  - name: validation
    tasks:
      - name: ArxivDIGESTables_Clean_validation
        path: astabench/arxivdigestables_validation
        primary_metric: 'score_tables/mean'
        tags:
          - lit
      - name: ScholarQA_CS2_validation
        path: astabench/sqa_dev
        primary_metric: 'global_avg/mean'
        tags:
          - lit
      - name: LitQA2_FullText_validation
        path: astabench/litqa2_validation
        primary_metric: 'is_correct/accuracy'
        tags:
          - lit
      - name: PaperFindingBench_validation
        path: astabench/paper_finder_validation
        primary_metric: 'score_paper_finder/adjusted_f1_micro_avg'
        tags:
          - lit
      - name: LitQA2_FullText_Search_validation
        path: astabench/paper_finder_litqa2_validation
        primary_metric: 'score_paper_finder/recall_at_30'
        tags:
          - lit
      - name: DiscoveryBench_validation
        path: astabench/discoverybench_validation
        primary_metric: 'score_discoverybench/mean'
        tags:
          - data
      - name: CORE_Bench_Hard_validation
        path: astabench/core_bench_validation
        primary_metric: 'score_with_stderr/accuracy'
        tags:
          - code
      - name: DS_1000_validation
        path: astabench/ds1000_validation
        primary_metric: 'ds1000_scorer/accuracy'
        tags:
          - code
      - name: E2E_Bench_validation
        path: astabench/e2e_discovery_validation
        primary_metric: 'score_rubric/accuracy'
        tags:
          - discovery
      - name: E2E_Bench_Hard_validation
        path: astabench/e2e_discovery_hard_validation
        primary_metric: 'score_rubric/accuracy'
        tags:
          - discovery
      - name: SUPER_Expert_validation
        path: astabench/super_validation
        primary_metric: 'entrypoint/mean'
        tags:
          - code
    macro_average_weight_adjustments:
      - tag: lit
        task: LitQA2_FullText_validation
        weight: 0.5
      - tag: lit
        task: LitQA2_FullText_Search_validation
        weight: 0.5

  - name: test
    tasks:
      - name: PaperFindingBench_test
        path: astabench/paper_finder_test
        primary_metric: 'score_paper_finder/adjusted_f1_micro_avg'
        tags:
          - lit
      - name: LitQA2_FullText_Search_test
        path: astabench/paper_finder_litqa2_test
        primary_metric: 'score_paper_finder/recall_at_30'
        tags:
          - lit
      - name: ScholarQA_CS2_test
        path: astabench/sqa_test
        primary_metric: 'global_avg/mean'
        tags:
          - lit
      - name: ArxivDIGESTables_Clean_test
        path: astabench/arxivdigestables_test
        primary_metric: 'score_tables/mean'
        tags:
          - lit
      - name: LitQA2_FullText_test
        path: astabench/litqa2_test
        primary_metric: 'is_correct/accuracy'
        tags:
          - lit
      - name: DiscoveryBench_test
        path: astabench/discoverybench_test
        primary_metric: 'score_discoverybench/mean'
        tags:
          - data
      - name: CORE_Bench_Hard_test
        path: astabench/core_bench_test
        primary_metric: 'score_with_stderr/accuracy'
        tags:
          - code
      - name: DS_1000_test
        path: astabench/ds1000_test
        primary_metric: 'ds1000_scorer/accuracy'
        tags:
          - code
      - name: E2E_Bench_test
        path: astabench/e2e_discovery_test
        primary_metric: 'score_rubric/accuracy'
        tags:
          - discovery
      - name: E2E_Bench_Hard_test
        path: astabench/e2e_discovery_hard_test
        primary_metric: 'score_rubric/accuracy'
        tags:
          - discovery
      - name: SUPER_Expert_test
        path: astabench/super_test
        primary_metric: 'output_match/mean'
        tags:
          - code
    macro_average_weight_adjustments:
      - tag: lit
        task: LitQA2_FullText_test
        weight: 0.5
      - tag: lit
        task: LitQA2_FullText_Search_test
        weight: 0.5
