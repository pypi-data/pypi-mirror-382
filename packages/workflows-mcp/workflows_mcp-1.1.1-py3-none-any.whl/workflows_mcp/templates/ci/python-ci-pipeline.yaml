name: python-ci-pipeline
description: Complete Python CI pipeline with environment setup, linting, and testing
version: "1.0"
author: Workflows MCP Team
tags: [test, ci, python, pipeline, testing, linting, quality]
inputs:
  project_path:
    type: string
    description: Project directory path
    default: "."

  python_version:
    type: string
    description: Python version to use
    default: "3.12"

  skip_setup:
    type: boolean
    description: Skip environment setup (assume already set up)
    default: false

  coverage_threshold:
    type: integer
    description: Minimum test coverage percentage
    default: 80

  strict_linting:
    type: boolean
    description: Enable strict mode for mypy
    default: false

blocks:
  # Stage 1: Setup Python environment
  - id: setup_env
    type: ExecuteWorkflow
    inputs:
      workflow: "setup-python-env"
      inputs:
        python_version: "${python_version}"
        project_path: "${project_path}"
        requirements_file: "requirements.txt"
        upgrade_pip: true
    condition: "not ${skip_setup}"

  # Stage 2: Run linting (parallel with setup verification)
  - id: run_linting
    type: ExecuteWorkflow
    inputs:
      workflow: "lint-python"
      inputs:
        working_dir: "${project_path}"
        src_path: "src/"
        strict_mode: "${strict_linting}"
        fix_issues: false
        skip_mypy: false
        venv_path: "${project_path}/.venv"
    depends_on:
      - setup_env

  # Stage 3: Run tests (parallel with linting)
  - id: run_tests
    type: ExecuteWorkflow
    inputs:
      workflow: "run-pytest"
      inputs:
        working_dir: "${project_path}"
        test_path: "tests/"
        coverage_threshold: "${coverage_threshold}"
        verbose: true
        generate_html_report: true
        venv_path: "${project_path}/.venv"
    depends_on:
      - setup_env

  # Get setup status display
  - id: get_setup_display_skipped
    type: BashCommand
    inputs:
      command: "echo 'Setup: SKIPPED'"
      timeout: 5
      check_returncode: false
    condition: "${skip_setup}"

  - id: get_setup_display_passed
    type: BashCommand
    inputs:
      command: "echo 'Setup: ✓ PASSED'"
      timeout: 5
      check_returncode: false
    condition: "not ${skip_setup} and ${setup_env.success}"
    depends_on:
      - setup_env

  - id: get_setup_display_failed
    type: BashCommand
    inputs:
      command: "echo 'Setup: ✗ FAILED'"
      timeout: 5
      check_returncode: false
    condition: "not ${skip_setup} and not ${setup_env.success}"
    depends_on:
      - setup_env

  - id: get_setup_display
    type: BashCommand
    inputs:
      command: |
        STATUS_SKIPPED="${get_setup_display_skipped.stdout}"
        STATUS_PASSED="${get_setup_display_passed.stdout}"
        STATUS_FAILED="${get_setup_display_failed.stdout}"
        if [ -n "$STATUS_SKIPPED" ]; then
          echo "$STATUS_SKIPPED"
        elif [ -n "$STATUS_PASSED" ]; then
          echo "$STATUS_PASSED"
        else
          echo "$STATUS_FAILED"
        fi
      timeout: 5
      check_returncode: false
    depends_on:
      - get_setup_display_skipped
      - get_setup_display_passed
      - get_setup_display_failed

  - id: get_linting_display
    type: BashCommand
    inputs:
      command: "test '${run_linting.all_passed}' = 'true' && echo '✓ PASSED' || echo '✗ FAILED'"
      timeout: 5
      check_returncode: false
    depends_on:
      - run_linting

  - id: get_testing_display
    type: BashCommand
    inputs:
      command: "test '${run_tests.success}' = 'true' && echo '✓ PASSED' || echo '✗ FAILED'"
      timeout: 5
      check_returncode: false
    depends_on:
      - run_tests

  - id: get_overall_display_success
    type: BashCommand
    inputs:
      command: "echo '✓ ALL CHECKS PASSED'"
      timeout: 5
      check_returncode: false
    condition: "(${skip_setup} or ${setup_env.success}) and ${run_linting.all_passed} and ${run_tests.success}"
    depends_on:
      - get_setup_display
      - get_linting_display
      - get_testing_display

  - id: get_overall_display_failed
    type: BashCommand
    inputs:
      command: "echo '✗ PIPELINE FAILED'"
      timeout: 5
      check_returncode: false
    condition: "not ((${skip_setup} or ${setup_env.success}) and ${run_linting.all_passed} and ${run_tests.success})"
    depends_on:
      - get_setup_display
      - get_linting_display
      - get_testing_display

  - id: get_overall_display
    type: BashCommand
    inputs:
      command: |
        STATUS_SUCCESS="${get_overall_display_success.stdout}"
        STATUS_FAILED="${get_overall_display_failed.stdout}"
        if [ -n "$STATUS_SUCCESS" ]; then
          echo "$STATUS_SUCCESS"
        else
          echo "$STATUS_FAILED"
        fi
      timeout: 5
      check_returncode: false
    depends_on:
      - get_overall_display_success
      - get_overall_display_failed

  # Stage 4: Validate results
  - id: validate_pipeline
    type: EchoBlock
    inputs:
      message: |
        ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
        Python CI Pipeline Results
        ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
        ${get_setup_display.stdout}
        Linting: ${get_linting_display.stdout}
        Testing: ${get_testing_display.stdout}
        ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
        Overall Status: ${get_overall_display.stdout}
        ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
    depends_on:
      - get_overall_display

outputs:
  # Overall status
  success: "${(${skip_setup} or ${setup_env.success}) and ${run_linting.all_passed} and ${run_tests.success}}"

  # Environment setup results
  env_setup_success: "${skip_setup} or ${setup_env.success}"
  python_version: "${python_version}"

  # Linting results
  linting_passed: "${run_linting.all_passed}"
  ruff_passed: "${run_linting.ruff_passed}"
  mypy_passed: "${run_linting.mypy_passed}"
  format_passed: "${run_linting.format_passed}"

  # Testing results
  tests_passed: "${run_tests.success}"
  test_exit_code: "${run_tests.exit_code}"

  # Summary
  pipeline_summary: "${validate_pipeline.echoed}"
  execution_time_ms: "${validate_pipeline.execution_time_ms}"
